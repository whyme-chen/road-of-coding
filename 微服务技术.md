# 	微服务技术

## 微服务简介

### 微服务技术栈

1. 服务网关
2. 注册中心
3. 配置中心
4. 服务集群
5. 分布式缓存
6. 分布式搜索
7. 分布式日志框架
8. 统一部署平台

![image-20220616221642790](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206162216086.png)

![image-20220616221927980](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206162257980.png)

![image-20220616222141070](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206162258405.png)

学习课程：[SpringCloud+RabbitMQ+Docker+Redis+搜索+分布式，系统详解springcloud微服务技术栈课程|黑马程序员Java微服务](https://www.bilibili.com/video/BV1LQ4y127n4/?p=1&vd_source=fabefd3fabfadb9324761989b55c26ea)

![image-20230311183945358](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303111839545.png)

### 微服务架构演变

1. 单体架构：将业务所有功能集中在一个项目中开发，生成一个包进行部署

   * 优点：架构简单、部署成本低
   * 缺点：耦合度高

2. 分布式架构：根据业务功能对系统拆分，每个业务模块作为一个独立项目开发，称为一个服务。

   * 优点：降低服务耦合度，有利于服务升级扩展
   * 服务治理（分布式架构的要考虑的问题）
     * 服务拆分粒度如何?
     * 服务集群地址如何维护?
     * 服务之间如何实现远程调用?
     * 服务健康状态如何感知?

3. 微服务：**微服务是一种经过良好架构设计的分布式架构方案**

   * 微服务架构特征:

     * 单一职责:微服务拆分粒度更小，每-一个服务都对应唯一的业务能力，做到单一职责,避免重复业务开发
     * 面向服务：微服务对外暴露业务接口
     * 自治：团队独立、技术独立、数据独立、部署独立
     * 隔离性强：服务调用做好隔离、容错、降级,避免出现级联问题

   * 结构：在国内最知名的微服务技术框架就是SpringCloud和阿里巴巴Dubbo。

   * 技术对比

     ![image-20220616225122343](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206162258252.png)
     
   * 微服务功能组件
   
     * 服务注册发现：Eureka、Nacos、Consul
     * 统一配置管理：SpringCloudCofing, Nacos
     * 服务远程调用：openFeign, Dubbo
     * 统一网关路由：SpringCloudGateway,zuul
     * 服务链路监控：Zipkin,Sleuth
     * 流控、降级、保护：Hystix、Sentinel

## Spring Cloud & SpringCloudAlibaba

官网：https://spring.io/projects/spring-cloud/

1. 简介：目前国内使用最广泛的微服务框架

2. SpringCloud和SpringBoot的版本兼容性

   ![image-20220616225638824](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181721335.png)

### 服务拆分及远程调用

1. 服务拆分注意事项：

   * 不同微服务，不重复开发相同业务
   * 微服务数据独立，不访问其他微服务的数据库
   * 微服务可以将自己的业务暴露为接口，供其他服务使用

2. 服务远程调用

   > 1. 注册RestTemplate，注入容器
   >
   >    ![image-20220617224745750](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181721514.png)
   >
   > 2. 服务远程调用RestTemplate
   >
   >    ![image-20220617225833140](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181721414.png)

   > * 基于RestTemplate发起的http请求实现远程调用
   > * http请求做远程调用是与语言无关的调用，只要知道对方的ip、端口、接口路径、请求参数即可。

3. 提供者与消费者

   * 服务提供者与消费者是相对的

### EureKa注册中心

1. 服务调用中的问题

   * 服务消费者该如何获取服务提供者的地址信息?(服务启动时注册自己的信息到eureka，消费者根据服务名向Eureka拉取提供者信息)
   * 如果有多个服务提供者,消费者该如何选择?（利用负载均衡算法）
   * 消费者如何得知服务提供者的健康状态? （服务这每30秒向Eureka发送心跳请求，报告健康状态）

2. eureka的作用

   * EurekaServer：服务端，注册中心
     * 记录服务信息
     * 心跳监控
   * EruekaClient：客户端
     * Provider：服务提供者，将自身信息注册到注册中心，每隔30秒向注册中心发送心跳
     * consumer：服务消费者，根据服务名称从注册中心拉取服务列表，基于服务列表做负载均衡，选中一个微服务后发起远程调用

   ![image-20220618171448837](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181721711.png)

3. 快速入门

   * 搭建注册中心

     ![image-20220618172353099](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181723946.png)

   * 服务注册

     ![image-20220618175957800](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181800933.png)

     模拟多实例部署：

     ![image-20220618215953095](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206182200358.png)

   * 服务发现

     ![image-20220618220255386](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206182202134.png)

### Ribbon负载均衡

#### 相关概念理解（开发角度）

**集群**：可以将其理解为由多个计算节点（称为"节点"）组成的分布式系统。这些节点通过网络连接在一起，共同协作完成某项任务。在集群中，每个节点都运行相同的应用程序或服务，并且可以独立地处理请求和执行任务。通过将工作负载分布到多个节点上，集群能够提高系统的可靠性、性能和扩展能力。

以下是一些从开发角度理解"集群"的关键概念：

1. 分布式计算：集群中的节点可以并行执行任务，通过将工作负载分散到多个节点上，可以提高计算速度和吞吐量。开发人员需要设计和实现分布式算法、任务调度和数据共享等机制。
2. 负载均衡：集群中的负载均衡器负责将请求分发到不同的节点上，以确保每个节点负载均衡和避免单点故障。开发人员需要了解负载均衡算法和配置，以确保请求在集群中被正确路由。
3. 高可用性：通过在集群中运行多个节点，可以提供高可用性。如果一个节点故障，其他节点可以自动接管工作，保证系统的连续性。开发人员需要设计容错和故障恢复机制，以确保系统的可用性和稳定性。
4. 数据一致性：在分布式集群中处理数据时，要考虑如何保持数据的一致性。开发人员需要使用合适的同步或异步机制来确保数据在节点之间的同步和复制。
5. 集群管理：开发人员需要了解如何配置、监视和管理集群中的节点。这包括节点的启动和停止、部署应用程序、监控集群性能和资源使用情况等。

**负载**：以将其理解为指在系统中产生的工作量或任务数量。负载可以是一段时间内进入系统的请求数量、并发用户数量、CPU利用率、内存使用量以及网络流量等。

以下是一些常见的负载类型：

1. 网络负载：指进入和离开系统的网络流量，包括传入和传出的数据包数量、带宽利用率等。网络负载通常出现在需要处理大量网络请求或传输大量数据的应用程序中。
2. 计算负载：指CPU的使用情况，包括计算密集型任务（如大规模数据处理、复杂算法计算）对CPU资源的需求以及CPU的利用率。开发人员需要考虑如何优化算法、并发处理以及任务调度，以提高计算负载的效率。
3. 存储负载：指对存储系统的访问和使用情况，包括读取和写入的数据量、I/O操作的延迟等。存储负载常常出现在需要频繁读写大量数据的应用程序中，例如数据库、文件服务器等。
4. 内存负载：指系统中正在使用的内存量和内存管理的情况，包括内存使用率、内存泄漏、内存交换等。开发人员需要注意内存资源的管理和优化，确保系统在处理大量数据时不会出现内存不足的问题。
5. 并发负载：指同时处理的请求数量或并发用户数量。开发人员需要考虑如何设计并发安全的代码、使用合适的线程池和调度机制，以应对高并发场景下的负载压力。

理解负载可以帮助开发人员了解应用程序的性能瓶颈以及系统资源的使用情况。通过监测和分析负载，开发人员可以进行性能调优、优化资源分配、实现负载均衡等措施，以提高系统的可靠性、性能和可扩展性。

**负载均衡**：可以将其理解为一种分发工作负载的技术，用于在分布式系统中平衡各个节点之间的负载，以提高系统的性能、可靠性和可扩展性。

负载均衡的主要目标是将请求合理地分发到集群中的不同节点上，避免某些节点过载而导致性能下降或服务不可用的情况。通过均衡负载，可以实现以下好处：

1. 提高系统性能：负载均衡可将请求分散到多个节点上，从而减轻单个节点的压力，提高请求的处理速度和响应时间。
2. 增强系统可靠性：当某个节点发生故障或下线时，负载均衡器可以自动将请求路由到其他健康的节点，确保系统的连续性和可用性。
3. 扩展系统容量：通过添加更多的节点，并使用负载均衡技术将请求均匀地分布到这些节点上，可以实现系统的横向扩展，提供更大的容量和处理能力。
4. 简化系统管理：负载均衡器可以通过监控、检测节点的状态和负载情况来自动调整请求的路由，降低管理和维护的复杂性。

常见的负载均衡策略包括：

1. 轮询（Round Robin）：按顺序将请求依次分发到每个节点。
2. 最小连接数（Least Connections）：将请求发送到当前连接数最少的节点，以实现负载均衡。
3. 响应时间（Response Time）：根据节点的响应时间来选择负载均衡的节点，将请求分发到最快的节点上。
4. IP散列（IP Hash）：根据客户端的IP地址进行散列计算，将同一客户端的请求始终发送到同一个节点上。
5. 内容散列（Content Hash）：根据请求的内容进行散列计算，确保相同内容的请求始终由同一个节点处理。

开发人员需要根据具体的应用场景和需求选择适合的负载均衡策略，并配置负载均衡器以实现系统的负载均衡。同时还需要考虑负载均衡器的高可用性、性能监控和故障恢复等方面，以确保负载均衡的有效运行。

#### Ribbon

1. 负载均衡流程

   ![image-20230505181246896](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305051812821.png)

   ![image-20220619111733756](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191119756.png)

2. 负载均衡策略

   ![image-20220619111906061](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191124670.png)

   ![image-20220619111926430](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191124252.png)

   ![image-20220619112416337](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191124665.png)

   > 注意：第一种方式针对全局，第二种方式只针对指定服务

3. 饥饿加载

   ![image-20220619113011093](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191130698.png)

### Nacos

GitHub主页：https://github.com/alibaba/nacos

GitHub的Release：https://github.com/alibaba/nacos/releases

网站：https://nacos.io/zh-cn/index.html

1. 安装nacos

   * 下载：在Nacos的GitHub页面，提供有下载链接，可以下载编译好的Nacos服务端或者源代码。
   * 配置：Nacos的默认端口是8848，若电脑上的其它进程占用了8848端口，请先尝试关闭该进程。**如果无法关闭占用8848端口的进程**，也可以进入nacos的conf目录中的配置文件application.properties修改的端口。
   * 启动
     * 双击bin目录中的startup.cmd
     * 执行命令startup.cmd -m standalone
   * 访问：在浏览器输入地址：http://127.0.0.1:8848/nacos即可，登录默认的账号和密码都是nacos进入。
   
2. 使用第三方数据库存储nacos数据（mysql为例）

   Nacos在存储数据时既可以使用内置数据库存储，也可以通过第三方指定的数据库存储。可以通过修改配置文件指定使用MySQL数据库来存储Nacos的相关数据，

   ~~~
   spring.datasource.platform=mysql
   db.num=1
   db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true
   db.user=root
   db.password=4112
   ~~~

   > 配置文件位置：NACOS_HOME/conf/application.properties

   修改完配置文件后，在配置的对应数据库中创建数据库。

   ~~~sql
   CREATE DATABASE `nacos` CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;
   ~~~

   数据库创建完成后，执行NACOS_HOME/conf/nacos-mysql.sql数据库脚本文件。

#### 服务注册发现

2. nacos的依赖（客户端）

   父工程：

   ```xml
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-alibaba-dependencies</artifactId>
       <version>2.2.5.RELEASE</version>
       <type>pom</type>
       <scope>import</scope>
   </dependency>
   ```

   客户端：

   ```xml
   <!-- nacos客户端依赖包 -->
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
   </dependency>
   ```

3. 客户端注册

   ![image-20220621222022415](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206232155659.png)

   ![image-20220621222249577](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206232155264.png)

4. nacos服务分级存储模型

   * 分级存储模型
     * 一级是服务
     * 二级是集群
     * 三级是实例

   ![image-20220623215211993](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206232155127.png)

   * 服务跨集群调用的问题

     * 服务调用尽可能选择本地集群服务，跨集群调用延迟较高。只有本地集群不可访问时，再去访问其他集群。

   * 配置服务集群属性

     ![image-20220623215446583](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206232155960.png)

   * 根据集群负载均衡

     ~~~yaml
     userservice:
       ribbon:
         NFLoadBalancerRuleCalssName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则
     ~~~

     > NacosRule负载均衡策略
     >
     > * 优先选择同集群服务实例列表
     > * 本地集群找不到提供者，才去其它集群寻找，并且会
     >   报警告
     > * 确定了可用实例列表后，再采用随机负载均衡挑选实

   * 根据权重负载均衡

     * 实际部署场景：
       * 服务器设备性能存在差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求
     * 通过nacos控制台配置权重：0~1之间同集群内的多个实例，权重越高被访问的频率越高，权重设置为0则完全不会被访问

5. 临时实例和非临时实例

   ![image-20230505211240620](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305052112776.png)

6. 环境隔离-namespace：Nacos中服务存储和数据存储的最外层都是一个名为namespace的东西，用来做最外层隔离

   * 在Nacos控制台创建namespace，用来隔离不同环境

   * 在服务的配置文件中配置命名空间

     ![image-20230505205906511](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305052059197.png)

   > namespace用来做环境隔离，每个namespace都有唯一id，**不同namespace下的服务不可见**

7. Nacos和Eureka对比

   * 共同点
     * 都支持服务注册和服务拉取
     * 都支持服务提供者心跳方式做健康检测
   * 不同点
     * Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式
     * 临时实例心跳不正常会被剔除，非临时实例则不会被剔除
     * Nacos支持服务列表变更的消息推送模式，服务列表更新更及时
     * Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式

#### 配置管理

##### 统一配置管理

> * 在Nacos中添加配置文件
> * 在微服务中引入nacos的config依赖
> * 在微服务中添加bootstrap.yml，配置nacos地址、当前环境、服务名称、文件后缀名。这些决定了程序
>   启动时去nacos读取哪个文件

1. 在nacos中创建配置文件

   ![image-20230505222635283](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305052226057.png)

2. 配置获取

   ![image-20230505225825641](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305052258264.png)

   ~~~yaml
   spring:
     application:
       name: userservice # 服务名称
     profiles:
       active: dev # 开发环境
     cloud:
       nacos:
         config:
           file-extension: yaml # 文件后缀名
         server-addr: localhost:8848 # Nacos地址
   ~~~

##### 配置热更新

1. 方式一：

   ![image-20230506171558427](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061716283.png)

2. 方式二：

   ![image-20230506172743217](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061727103.png)

##### 配置共享

1. 创建多配置文件

   ![image-20230506173120433](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061745737.png)

2. 多配置文件优先级：[服务名]-[环境].yaml>[服务名].yaml>本地配置

##### 搭建Nacos集群

1. 步骤
   * 搭建MySQL集群并初始化数据库表
   * 下载解压nacos
   * 修改集群配置(节点信息)数据库配置
   * 分别启动多个nacos节点
   * nginx反向代理

### OpenFeign

#### RestTemplate的问题

![image-20230506175657177](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061756412.png)

#### OpenFeign

> 说明：此处指的feign都是OpenFeign，由Spring提供，而非Netfix提供的feign

官网：https://github.com/OpenFeign/feign

SpringCloudOpenFeign：https://spring.io/projects/spring-cloud-openfeign#overview

1. feign：一个声明式、模板化的http客户端，实现优雅的http请求发送。

2. feign客户端的使用

   * 引入依赖

     ~~~xml
     <dependency>            
         <groupId>org.springframework.cloud</groupId>
         <artifactId>spring-cloud-starter-openfeign</artifactId>
     </dependency>
     ~~~

   * 启动类中添加注解开启Feign功能

     ![image-20230506180353483](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061803740.png)

   * 编写Feign客户端

     ![image-20230506180828135](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061808526.png)

3. 自定义feign配置

   ![image-20230506213938619](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062139929.png)

   日志自定义方式一：配置文件

   ![image-20230506222903876](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062229450.png)

   日志自定义方式二：java代码

   ![image-20230506223002338](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062230717.png)

4. Feign的性能优化

   ![image-20230506223822399](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062238506.png)

   * 连接池配置

     ![image-20230506224047084](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062240233.png)

5. 最佳实践

   * 方式一：

     ![image-20230506224848056](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062248178.png)

   * 方式二：

     ![image-20230506225107978](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062251195.png)

     > 实现步骤：
     >
     > * 创建一个module，命名为feign-api，引入feign相关依赖
     > * 将order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中
     > * 在order-service中引入feign-api的依赖
     > * 修改order-service中的所有与上述三个组件有关的import部分，改成导入feign-api中的包
     >
     > ![image-20230506231053347](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062310886.png)

### 统一网关Gateway

#### 简介

1. 网关功能
   * 身份认证和权限校验
   * 服务路由和负责均衡
   * 请求限流
2. SpringCloud的网关实现
   * gateway：基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。
   * zuul：基于Servlet的实现，属于阻塞式编程。

#### 搭建网关服务

1. 步骤：

   * 创建新的module，引入SpringCloudGateway的依赖和nacos的服务发现依赖

     ![image-20230506231549166](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062315923.png)

   * 编写路由配置及nacos地址

     > 网关路由可以配置的内容包括
     >
     > * 路由id:路由唯一标示
     > * uri: 路由目的地，支持lb和http两种
     > * predicates: 路由断言，判断请求是否符合要求，符合则转发到路由目的地址
     > * filters:路由过滤器，处理请求或响应

     ~~~xml
     server:
       port: 10086
     spring:
       application:
         name: gateway
       cloud:
         nacos:
           server-addr: localhost:8848
         gateway:
           routes: # 网关路由配置
             - id: user-service # 路由id，自定义，只要唯一即可
               uri: lb://userservice # 路由的目标地址，lb就是负载均衡，后面跟服务名称，还可以使用http://127.0.0.1:8081的方式配置
               predicates: # 路由断言，即判断路由是否符合规则
                 - Path=/user/** # 按照路由路径匹配，只要以/user/开头就匹配
             - id: order-service
               uri: lb://orderservice
               predicates:
                 - Path=/order/**
     ~~~

2. 网关流程

   ![image-20230507115109352](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305071151354.png)

3. 路由断言工厂

   > 在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件
   > 例如Path=/user/**是按照路径匹配，这个规则是由orq.springframework.cloud.qateway.handler.predicatePathRoutePredicateFactory类来处理的

   ![image-20230507115523705](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305071155592.png)
   
4. 路由过滤器（GatewayFilter）：网关中提供的一种过滤器，可以对进入网关的**请求**和微服务返回的**响应**做处理。

   ![image-20230508225305428](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082253251.png)

   * 局部过滤器：配置在路由下

   ~~~xml
         routes:
           - id: user-service # 路由标示，必须唯一
             uri: lb://userservice # 路由的目标地址
             predicates: # 路由断言，判断请求是否符合规则
               - Path=/user/** # 路径断言，判断路径是否是以/user开头，如果是则符合
             filter:
               - AddRequestHeader=Trueth,Come on whyme-chen!
   ~~~

   * 默认过滤器

   ![image-20230508225828849](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082258640.png)

5. 全局过滤器（GlobalFilter）

   全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的。而GlobalFilter的逻辑需要自己写代码实现。

   ![image-20230508230421859](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082304761.png)

6. 过滤器执行顺序

   ![image-20230508231853814](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082318558.png)

   > * 每一个过滤器都必须指定一个int类型的order值，order值越小，优先级越高，执行顺序越靠前.
   > * GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。
   > * 当过滤器的order值一样时，会按照 defaultFilter > 路由过滤器>GlobalFilter的顺序执行。

7. 跨域问题处理

   ![image-20230508232228486](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082322188.png)

   ![image-20230508232245310](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082322067.png)

### 服务器容错Sentinel

### 分布式事务Seata

# 消息中间件

## MQ基本概念

1. MQ：全称Message Queue (消息队列)，是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信。

2. 优势

   * 应用解耦

   * 削峰填谷：应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了消息队列可以将大量请求缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。

   * 异步提速

     ![image-20230313225333941](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132253511.png)

3. 劣势

   * 系统可用性降低：系统引入的外部依赖越多，系统稳定性越差。一旦MQ宕机，就会对业务造成影响。
   * 系统复杂性提高
   * 一致性问题

4. MQ应用条件

   * 生产者不需要从消费者处获得反馈
   * 容许短暂的不一致性

5. 常见的MQ产品

   * RabbitMQ
   * RocketMQ
   *  ActiveMQ
   * Kafka
   *  ZeroMQ
   * MetaMq

   ![image-20230313230133285](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132301585.png)

6. AMQP：AMQP，即Advanced Message Queuing Protocol (高级消息队列协议) ,是一个网络协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。2006年， AMQP规范发布。类比HTTP。

## RabbitMQ

### RabbitMQ简介

![image-20230313232906539](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132329639.png)

![image-20230313232947012](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132329894.png)

![image-20230313233040344](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132330009.png)

![image-20230313233121119](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132331854.png)

### 快速使用

官网：https://www.rabbitmq.com/

1. 下载安装和管控台的使用

   > 使用docker安装rabbitmq：https://blog.csdn.net/weixin_44666439/article/details/127265712?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-127265712-blog-124470698.235^v27^pc_relevant_3mothn_strategy_recovery&spm=1001.2101.3001.4242.1&utm_relevant_index=3

2. 使用**简单模式**完成消息传递

   * 创建工程（生产者、消费者）
   * 分别添加依赖
   
   ~~~xml
    <dependency>
         <groupId>com.rabbitmq</groupId>
         <artifactId>amqp-client</artifactId>
         <version>5.16.0</version>
       </dependency>
   ~~~
   
   * 编写生产者发送消息、编写消费者接收消息
   
   ~~~java
   package org.example.producer;
   
   import com.rabbitmq.client.AMQP;
   import com.rabbitmq.client.Channel;
   import com.rabbitmq.client.Connection;
   import com.rabbitmq.client.ConnectionFactory;
   
   import java.io.IOException;
   import java.nio.charset.StandardCharsets;
   import java.util.concurrent.TimeoutException;
   
   /**
    * 简单模式
    * @Author chen
    * @Date 2023/3/25
    * @Version 1.0
    **/
   public class Producer_HelloWorld {
       public static void main(String[] args) throws IOException, TimeoutException {
           //创建连接工厂
           ConnectionFactory connectionFactory = new ConnectionFactory();
           //设置参数
           connectionFactory.setHost("47.120.2.57");
           connectionFactory.setPort(5672);
           connectionFactory.setVirtualHost("demo");
           connectionFactory.setUsername("admin");
           connectionFactory.setPassword("admin");
           //创建连接
           Connection connection = connectionFactory.newConnection();
           //创建Channel
           Channel channel = connection.createChannel();
           //创建队列Quene
           /*
            * queueDeclare方法参数说明
            * String queue,队列名称
         * boolean durable,是否持久化
            * boolean exclusive,是否独占，只能有一个消费者监听该队列。当Connection关闭时，是否删除队列
            * boolean autoDelete,是否自动删除，当该队列没有消费者时，自动删除
            * Map<String, Object> arguments,参数
            */
           AMQP.Queue.DeclareOk declareOk = channel.queueDeclare("hello",true,false,false,null);
           //发送消息
           String body = "hello rabbitmq!";
           /*
            *basicPublish方法参数说明
            * String exchange,交换机名称，简单模式下交换机默认使用“
            * String routingKey,路由名称
            * BasicProperties props,配置信息
            * byte[] body,发送消息数据
            */
           channel.basicPublish("","hello",null,body.getBytes(StandardCharsets.UTF_8));
   
           channel.close();
           connection.close();
       }
   }
   ~~~
   
   ~~~java
   package org.example.consumer;
   
   import com.rabbitmq.client.*;
   
   import java.io.IOException;
   import java.nio.charset.StandardCharsets;
   import java.util.concurrent.TimeoutException;
   
   /**
    * 消费者
    * @Author chen
    * @Date 2023/3/25
    * @Version 1.0
    **/
   public class ConsumerDemo1 {
       public static void main(String[] args) throws IOException, TimeoutException {
           //创建连接工厂
           ConnectionFactory connectionFactory = new ConnectionFactory();
           //设置参数
           connectionFactory.setHost("47.120.2.57");
           connectionFactory.setPort(5672);
           connectionFactory.setVirtualHost("demo");
           connectionFactory.setUsername("admin");
           connectionFactory.setPassword("admin");
           //创建连接
           Connection connection = connectionFactory.newConnection();
           //创建Channel
           Channel channel = connection.createChannel();
           //创建队列Quene
           AMQP.Queue.DeclareOk declareOk = channel.queueDeclare("hello",true,false,false,null);
           //消费消息
           Consumer consumer = new DefaultConsumer(channel){
               /**
                * 这是一个回调方法，当收到消息后会自动执行该方法
                * @param consumerTag 标识
                * @param envelope 获取信息，包括：交换机、路由key
                * @param properties 配置信息
                * @param body 数据
                * @throws IOException
                */
               @Override
               public void handleDelivery(String consumerTag,
                                          Envelope envelope,
                                          AMQP.BasicProperties properties,
                                          byte[] body) throws IOException {
                   System.out.println("consumerTag:"+consumerTag);
                   System.out.println("envelope:"+envelope.getExchange());
                   System.out.println("envelope:"+envelope.getRoutingKey());
                   System.out.println("properties:"+properties);
                   System.out.println("body:"+new String(body));
               }
           };
           channel.basicConsume("hello",true,consumer);
   
       }
   }
   
   ~~~
   
3. 工作队列模式（Work Queues）

   * 特点：与简单模式相比有多个消费者
   * 应用场景：对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度
   * 在一个队列中如果有多个消费者，那么消费者之间对于同一个消息的关系是竞争的关系
   * Work Queues 对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。例如: 短信服务部署多个只需要有一个节点成功发送即可。

4. Pub/Sub订阅模式

   ![image-20230510215142430](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305102151306.png)

5. 路由模式

   ![image-20230511115213003](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305111152263.png)

### Spring整合RabbitMQ

## RocketMQ

官网：https://rocketmq.apache.org/zh/

### 简介

RocketMQ是由阿里捐赠给Apache的一款低延迟、高并发、高可用、高可靠的分布式消息中间件。

1. 核心概念
   - **Topic**：消息传输和存储的顶层容器，用于标识同一类业务逻辑的消息。主题通过TopicName来做唯一标识和区分。
   - **Message**：生产者向Topic发送并最终传送给消费者的数据消息的载体。按照消息传输特性的不同而定义的分类，用于类型管理和安全校验。 Apache RocketMQ 支持的消息类型有
     - 普通消息
     - 顺序消息
     - 事务消息
     - 定时/延时消息
   - **消息属性**：生产者可以为消息定义的属性，包含Message Key和Tag。
   - **Message Key**：消息的业务标识，由消息生产者（Producer）设置，唯一标识某个业务逻辑。
   - **Message ID**：消息的全局唯一标识，由消息队列RocketMQ系统自动生成，唯一标识某条消息。
   - **Tag**：消息标签，二级消息类型，用来进一步区分某个Topic下的消息分类
   - **Producer**：也称为消息发布者，负责生产并发送消息至Topic。
   - **Consumer**：也称为消息订阅者，负责从Topic接收并消费消息。
   - **Broker**：暂存和传输消息
   - **NameServer**：管理Broker
   - **分区**：即Topic Partition，物理上的概念。每个Topic包含一个或多个分区。
   - **消费位点**：每个Topic会有多个分区，每个分区会统计当前消息的总条数，这个称为最大位点MaxOffset；分区的起始位置对应的位置叫做起始位点MinOffset。
   - **Group**：一类生产者或消费者，这类生产者或消费者通常生产或消费同一类消息，且消息发布或订阅的逻辑一致。
   - **Group ID**：Group的标识。
   - **队列**：个Topic下会由一到多个队列来存储消息。
   - **Exactly-Once投递语义**：Exactly-Once投递语义是指发送到消息系统的消息只能被Consumer处理且仅处理一次，即使Producer重试消息发送导致某消息重复投递，该消息在Consumer也只被消费一次。
   - **集群消费**：一个Group ID所标识的所有Consumer平均分摊消费消息。例如某个Topic有9条消息，一个Group ID有3个Consumer实例，那么在集群消费模式下每个实例平均分摊，只消费其中的3条消息。
   - **广播消费**：一个Group ID所标识的所有Consumer都会各自消费某条消息一次。例如某个Topic有9条消息，一个Group ID有3个Consumer实例，那么在广播消费模式下每个实例都会各自消费9条消息。
   - **定时消息**：Producer将消息发送到消息队列RocketMQ服务端，但并不期望这条消息立马投递，而是推迟到在当前时间点之后的某一个时间投递到Consumer进行消费，该消息即定时消息。
   - **延时消息**：Producer将消息发送到消息队列RocketMQ服务端，但并不期望这条消息立马投递，而是延迟一定时间后才投递到Consumer进行消费，该消息即延时消息。
   - **事务消息**：RocketMQ提供类似X/Open XA的分布事务功能，通过消息队列RocketMQ的事务消息能达到分布式事务的最终一致。
   - **顺序消息**：RocketMQ提供的一种按照顺序进行发布和消费的消息类型，分为全局顺序消息和分区顺序消息。
   - **全局顺序消息**：对于指定的一个Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。
   - **分区顺序消息**：对于指定的一个Topic，所有消息根据Sharding Key进行区块分区。同一个分区内的消息按照严格的FIFO顺序进行发布和消费。Sharding Key是顺序消息中用来区分不同分区的关键字段，和普通消息的Message Key是完全不同的概念。
   - **消息堆积**：Producer已经将消息发送到消息队列RocketMQ的服务端，但由于Consumer消费能力有限，未能在短时间内将所有消息正确消费掉，此时在消息队列RocketMQ的服务端保存着未被消费的消息，该状态即消息堆积。
   - **消息过滤**：Consumer可以根据消息标签（Tag）对消息进行过滤，确保Consumer最终只接收被过滤后的消息类型。消息过滤在消息队列RocketMQ的服务端完成。
   - **消息轨迹**：在一条消息从Producer发出到Consumer消费处理过程中，由各个相关节点的时间、地点等数据汇聚而成的完整链路信息。通过消息轨迹，您能清晰定位消息从Producer发出，经由消息队列RocketMQ服务端，投递给Consumer的完整链路，方便定位排查问题。
   - **重置消费位点**：以时间轴为坐标，在消息持久化存储的时间范围内（默认3天），重新设置Consumer对已订阅的Topic的消费进度，设置完成后Consumer将接收设定时间点之后由Producer发送到消息队列RocketMQ服务端的消息。
   - **死信队列**：死信队列用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列RocketMQ会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明Consumer在正常情况下无法正确地消费该消息。此时，消息队列RocketMQ不会立刻将消息丢弃，而是将这条消息发送到该Consumer对应的特殊队列中。  消息队列RocketMQ将这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），将存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。

### 快速入门

[快速开始](https://rocketmq.apache.org/zh/docs/quickStart/01quickstart)

### 集群搭建

![RocketMQ角色](微服务技术.assets/RocketMQ角色-1690212428594.jpg)

1. 特点
   * NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。
   * Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。
   * Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。
   * Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。
2. 集群模式
   * 单Master模式：这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。
   * 多Master模式：一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优点是配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高；缺点是单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。
   * 多Master多Slave模式（异步）：每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优点是即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样；缺点是Master宕机，磁盘损坏情况下会丢失少量消息。
   * 多Master多Slave模式（同步）：每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优点是数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；缺点是性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。

### 消息

1. 构成
   * **topic**，表示要发送的消息的主题。
   * **body** 表示消息的存储内容
   * **properties** 表示消息属性
   * **transactionId** 会在事务消息中使用。

普通消息

顺序消息

事务消息

定时/延时消息

### Java客户端

官网示例：https://rocketmq.apache.org/zh/docs/sdk/02java

#### 发送普通消息

同步消息

~~~java
package com.whymechen.demorocket.common;

import org.apache.rocketmq.client.exception.MQBrokerException;
import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.client.producer.SendResult;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.exception.RemotingException;

import java.nio.charset.StandardCharsets;

/**
 * @author： chenwenjian
 * @date： 2023/7/26 11:01
 * @description： 同步发送普通消息
 * @modifiedBy：
 * @version: 1.0
 */
public class SyncCommonMessage {
    public static void main(String[] args) {
        // 创建生产者并设置生产组
        DefaultMQProducer commonMessage = new DefaultMQProducer("COMMON_MESSAGE");
        // 设置nameserver地址
        commonMessage.setNamesrvAddr("localhost:9876");
        try {
            // 启动producer
            commonMessage.start();
        } catch (MQClientException e) {
            throw new RuntimeException(e);
        }
        // 构建消息，指定topic、tag、body等信息
        for (int i = 0; i < 10; i++) {
            String msg = "msg"+i+"：Hello Rocket";
            Message message = new Message("commonMsg", "tag1", msg.getBytes(StandardCharsets.UTF_8));
            SendResult send;
            try {
                // 发送消息
                send = commonMessage.send(message);
            } catch (MQClientException | RemotingException | MQBrokerException | InterruptedException e) {
                throw new RuntimeException(e);
            }
            System.out.println("msg"+i+"：发送成功！msgId为"+send.getMsgId());
        }
        // 关闭producer
        commonMessage.shutdown();
    }
}

~~~

异步消息

~~~java
package com.whymechen.demorocket.common;

import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.client.producer.SendCallback;
import org.apache.rocketmq.client.producer.SendResult;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.exception.RemotingException;

import java.nio.charset.StandardCharsets;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * @author： chenwenjian
 * @date： 2023/7/26 12:53
 * @description： 异步发送普通消息，异步发送一般用于链路耗时较长，对响应时间较为敏感的业务场景。例如，视频上传后通知启动转码服务，转码完成后通知推送转码结果等。
 * @modifiedBy：
 * @version: 1.0
 */
public class AsyncCommonMessage {
    public static void main(String[] args) throws InterruptedException {
        DefaultMQProducer commonMessage = new DefaultMQProducer("COMMON_MESSAGE");
        commonMessage.setNamesrvAddr("localhost:9876");
        try {
            commonMessage.start();
            commonMessage.setRetryTimesWhenSendAsyncFailed(0);
        } catch (MQClientException e) {
            throw new RuntimeException(e);
        }
        int count = 10;
        final CountDownLatch countDownLatch = new CountDownLatch(count);
        for (int i = 0; i < count; i++) {
            String msg = "async msg"+i+"hello RocketMQ";
            Message message = new Message("commonMsg", "tag2", msg.getBytes(StandardCharsets.UTF_8));
            try {
                commonMessage.send(message, new SendCallback() {
                    @Override
                    public void onSuccess(SendResult sendResult) {
                        System.out.println("消息发送成功!msgId为"+sendResult.getMsgId());
                        countDownLatch.countDown();

                    }

                    @Override
                    public void onException(Throwable throwable) {
                        System.out.println("消息发送失败!失败原因为"+throwable.getMessage());
                        countDownLatch.countDown();
                    }
                });
            } catch (MQClientException | RemotingException | InterruptedException e) {
                throw new RuntimeException(e);
            }
        }
        //异步发送，如果要求可靠传输，必须要等回调接口返回明确结果后才能结束逻辑，否则立即关闭Producer可能导致部分消息尚未传输成功
        countDownLatch.await(5, TimeUnit.SECONDS);
        commonMessage.shutdown();
    }
}

~~~

单向模式

```java
package com.whymechen.demorocket.common;

import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.exception.RemotingException;

import java.nio.charset.StandardCharsets;

/**
 * @author： chenwenjian
 * @date： 2023/7/26 13:53
 * @description： 单向模式发送普通消息，此方式发送消息的过程耗时非常短，一般在微秒级别。适用于某些耗时非常短，但对可靠性要求并不高的场景，例如日志收集。
 * @modifiedBy：
 * @version: 1.0
 */
public class OneWayCommonMessage {
    public static void main(String[] args) throws MQClientException, RemotingException, InterruptedException {
        DefaultMQProducer commonMessage = new DefaultMQProducer("COMMON_MESSAGE");
        commonMessage.setNamesrvAddr("localhost:9876");
        commonMessage.start();
        for (int i = 0; i < 5; i++) {
            Message message = new Message("commonMsg", "tag3", ("one wag message" + i).getBytes(StandardCharsets.UTF_8));
            commonMessage.sendOneway(message);
        }

        commonMessage.shutdown();
    }
}
```

#### 发送顺序消息

```java
package com.whymechen.demorocket.sequence;

import org.apache.rocketmq.client.exception.MQBrokerException;
import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.client.producer.SendResult;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.common.RemotingHelper;
import org.apache.rocketmq.remoting.exception.RemotingException;

import java.io.UnsupportedEncodingException;

/**
 * @author： chenwenjian
 * @date： 2023/7/26 14:13
 * @description：
 * @modifiedBy：
 * @version: 1.0
 */
public class SequenceMessage {
    public static void main(String[] args) throws UnsupportedEncodingException {
        DefaultMQProducer producer = null;
        try {
            producer = new DefaultMQProducer("SEQUENCE_MESSAGE");
            producer.setNamesrvAddr("localhost:9876");
            producer.start();

            String[] tags = new String[]{"TagA", "TagB", "TagC", "TagD", "TagE"};
            for (int i = 0; i < 50; i++) {
                int orderId = i % 10;
                Message msg = new Message("secquenceMsg", tags[i % tags.length], "KEY" + i,
                                ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
                SendResult sendResult = producer.send(msg, (mqs, msg1, arg) -> {
                    Integer id = (Integer) arg;
                    int index = id % mqs.size();
                    return mqs.get(index);
                }, orderId);

                System.out.printf("%s%n", sendResult);
            }
        } catch (MQClientException | RemotingException | MQBrokerException | InterruptedException e) {
            e.printStackTrace();
        }finally {
           if (producer!=null){
               producer.shutdown();
           }
        }
    }
}
```

MessageQueueSelector的接口如下：

```java
public interface MessageQueueSelector {
    MessageQueue select(final List<MessageQueue> mqs, final Message msg, final Object arg);
}
```

其中 mqs 是可以发送的队列，msg是消息，arg是上述send接口中传入的Object对象，返回的是该消息需要发送到的队列。上述例子里，是以orderId作为分区分类标准，对所有队列个数取余，来对将相同orderId的消息发送到同一个队列中。

生产环境中建议选择最细粒度的分区键进行拆分，例如，将订单ID、用户ID作为分区键关键字，可实现同一终端用户的消息按照顺序处理，不同用户的消息无需保证顺序。

# 缓存中间件

> Redis参考Redis.md

# 容器化和部署

## Docker

视频：https://www.bilibili.com/video/BV1CJ411T7BK?p=1

文档：

* https://pdai.tech/md/devops/docker/docker-00-overview.html

### 简介

1. 容器：

   * **解决软件跨环境迁移问题**
   * 完全使用沙箱机制，相互隔离
   * 性能开销极低

2. Docker：一个开源的应用容器引擎

   * 官网：https://www.docker.com
   * 诞生于2013年初,基于Go语言实现，dotCloud 公司出品(后改名为Docker Inc)
   * Docker可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的Linux机器上。
   * Docker从17.03版本之后分为CE (Community Edition:社区版)和EE (Enterprise Edition:企业版)

3. docker架构

   ![image-20230311195708638](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303111957973.png)

4. 配置镜像加速器

   阿里云：https://cr.console.aliyun.com/cn-heyuan/instances/mirrors

   网易加速器：http://hub-mirror.c.163.com

   Docker官方中国加速器：https://registry.docker-cn.com

   ustc 的镜像：https://docker.mirrors.ustc.edu.cn

   daocloud：https://www.daocloud.io/mirror#accelerator-doc（注册后使用）

5. docker容器虚拟化和传统虚拟机虚拟化的比较

   ![image-20230311230728514](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112307226.png)
   
6. 重要概念

   * images
   * container

### 常用命令

1. 服务相关

   > 启动docker服务：system start docker
   >
   > 停止docker服务：system stop docker
   >
   > 重启docker服务：system restart docker
   >
   > 查看docker服务状态：system status docker
   >
   > 开机启动docker服务：system enable docker

2. 镜像相关命令

   镜像地址：https://hub.docker.com/

   > 查看镜像：docker images
   >
   > 搜索镜像：docker search
   >
   > 拉取镜像：docker pull
   >
   > 删除镜像：docker rmi

3. 容器相关命令

   > 查看正在运行的容器：docker ps
   >
   > ​	-a：表示查看所有容器
   >
   > 创建容器：docker run 
   >
   > ​	-i：保持容器运行。通常与-t同时使用。加入it这两个参数后,容器创建后自动进入容器中，退出容器后，容器自动关闭。
   >
   > ​	-t: 为容器重新分配一个伪输入终端，通常与-i同时使用。
   > ​	-d:以守护(后台)模式运行容器。创建一个容器在后台运行， 需要使用dockerexec进入容器。退出后，容器不会关闭。
   > ​	-it创建的容器-般称为交互式容器， -id 创建的容器一般称为守护式容器
   > ​	--name:为创建的容器命名。
   >
   > 进入容器：docker exec
   > 启动容器：docker start
   > 停止容器：docker stop
   > 删除容器：docker rm
   > 查看容器信息：docker inspect

### 容器数据卷

1. 数据卷：数据卷是宿主机中的一个目录或文件

   * 当容器目录和数据卷目录绑定后，对方的修改会立即同步
   * 一个数据卷可以被多个容器同时挂载
   * 一个容器也可以被挂载多个数据卷

2. 作用

   * 容器数据持久化
   * 外部机器和容器间接通信
   * 容器之间数据交换

3. 配置数据卷

   > docker run ... -v 宿主机目录(文件) :容器内目录(文件)
   >
   > 注意事项：
   >
   > * 目录必须是绝对路径
   > * 如果目录不存在,会自动创建
   > * 可以挂载多个数据卷

4. 数据卷容器

   ![image-20230311213730377](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112137385.png)

### Dockerfile

#### 镜像原理

docker镜像原理：**docker镜像的本质是一个分层文件系统**

![image-20230311215746393](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112157213.png)

#### 镜像制作

##### 基于容器制作

![image-20230311220359398](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112204252.png)

##### 基于dockerfile文件制作

1. 简介

   * Dockerfile是一个文本文件
   * 包含了一条条的指令，每一条指令构建一层,基于基础镜像，最终构建出一一个新的镜像
   * 对于开发人员:可以为开发团队提供一个完全一致的开发环境
   * 对于测试人员:可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作
   * 对于运维人员:在部署时，可以实现应用的无缝移植

2. 常见关键字

   | 关键字      | 作用                     | 备注                                                         |
   | ----------- | ------------------------ | ------------------------------------------------------------ |
   | FROM        | 指定父镜像               | 指定dockerfile基于那个image构建                              |
   | MAINTAINER  | 作者信息                 | 用来标明这个dockerfile谁写的                                 |
   | LABEL       | 标签                     | 用来标明dockerfile的标签 可以使用Label代替Maintainer 最终都是在docker image基本信息中可以查看 |
   | RUN         | 执行命令                 | 执行一段命令 默认是/bin/sh 格式: RUN command 或者 RUN ["command" , "param1","param2"] |
   | CMD         | 容器启动命令             | 提供启动容器时候的默认命令 和ENTRYPOINT配合使用.格式 CMD command param1 param2 或者 CMD ["command" , "param1","param2"] |
   | ENTRYPOINT  | 入口                     | 一般在制作一些执行就关闭的容器中会使用                       |
   | COPY        | 复制文件                 | build的时候复制文件到image中                                 |
   | ADD         | 添加文件                 | build的时候添加文件到image中 不仅仅局限于当前build上下文 可以来源于远程服务 |
   | ENV         | 环境变量                 | 指定build时候的环境变量 可以在启动的容器的时候 通过-e覆盖 格式ENV name=value |
   | ARG         | 构建参数                 | 构建参数 只在构建的时候使用的参数 如果有ENV 那么ENV的相同名字的值始终覆盖arg的参数 |
   | VOLUME      | 定义外部可以挂载的数据卷 | 指定build的image那些目录可以启动的时候挂载到文件系统中 启动容器的时候使用 -v 绑定 格式 VOLUME ["目录"] |
   | EXPOSE      | 暴露端口                 | 定义容器运行的时候监听的端口 启动容器的使用-p来绑定暴露端口 格式: EXPOSE 8080 或者 EXPOSE 8080/udp |
   | WORKDIR     | 工作目录                 | 指定容器内部的工作目录 如果没有创建则自动创建 如果指定/ 使用的是绝对地址 如果不是/开头那么是在上一条workdir的路径的相对路径 |
   | USER        | 指定执行用户             | 指定build或者启动的时候 用户 在RUN CMD ENTRYPONT执行的时候的用户 |
   | HEALTHCHECK | 健康检查                 | 指定监测当前容器的健康监测的命令 基本上没用 因为很多时候 应用本身有健康监测机制 |
   | ONBUILD     | 触发器                   | 当存在ONBUILD关键字的镜像作为基础镜像的时候 当执行FROM完成之后 会执行 ONBUILD的命令 但是不影响当前镜像 用处也不怎么大 |
   | STOPSIGNAL  | 发送信号量到宿主机       | 该STOPSIGNAL指令设置将发送到容器的系统调用信号以退出。       |
   | SHELL       | 指定执行脚本的shell      | 指定RUN CMD ENTRYPOINT 执行命令的时候 使用的shell            |

### Docker Compose

Docker Compose是一个编排多容器分布式部署的工具，提供命令集管理容器化应用的完整开发周期，包括服务构建启动和停止。使用步骤:

* 利用 Dockerfile定义运行环境镜像
* 使用docker-compose.yml定义组成应用的各服务
* 运行 docker-composeup 启动应用

![image-20230311230230122](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112302382.png)

### Docker 私有仓库

## kubernetes

# 分布式系统基础

负载均衡、高可用性、容错机制

# 分布式搜索

数据类型：

* 结构化数据：可以用二维表存储的数据
* 非结构化数据：音视频，图表，日志等
* 半结构化数据：html，xml等

## ElasticSearch简介

官网：https://www.elastic.co/cn/

学习参考：

* https://www.bilibili.com/video/BV1hh411D7sb?p=1
* https://www.bilibili.com/video/BV1Nt4y1m7qL?p=1

### Elastic Stack简介

The Elastic Stack，也称为ELK Stack，是一个免费开源的日志分析架构技术栈总称。包括Logstash（数据抽取），ElasticseaIch（搜索分析）、Kibana（数据展示）、Beats等基础组件。

ELK能够安全可靠地获取任何来源、任何格式的数据，然后实时地对数据进行搜索、分析和可视化。

ELK不仅仅适用于日志分析，它还可以支持其它任何数据搜索、分析和收集的场景，日志分析和收集只是更具有代表性。并非唯一性。 下面是ELK简单架构示意图 :

![image-20230912232631464](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202309122326772.png)

Elaticsearch，简称ES，是一个开源的高扩展的分布式全文搜索引擎，是整个Elastic Stack技术栈的核心。它可以近乎实时的存储、检索数据，本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。

1. 特点

   * 处理方式灵活：elasticsearch是目前最流行的准实时全文检索引擎,具有高速检索大数据的能力。
   * 配置简单：安装elk的每个组件,仅需配置每个组件的一个配置文件即可。修改处不多,因为大量参数已经默认配在系统中,修改想要修改的选项即可。
   * 接口简单：采用json形式RESTFUL API接受数据并响应,无关语言。
     性能高效: elasticsearch基于优秀的全文搜索技术Lucene ,采用倒排索引,可以轻易地在百亿级别数据量下,搜索出想要的内容,并且是秒级响应。
   * 灵活扩展：elasticsearch和logstash都可以根据集群规模线性拓展，elasticsearch内部自动实现集群协作。
   * 数据展现华丽：kibana作为前端展现工具,图表华丽,配置简单。

2. 组件

   * Logstash

     Logstash基于java开发,是一个数据抽取转化工具。一般工作方式为c/s架构, client端安装在需要收集信息的主机上, server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch或其他组件上。

   * Elasticsearch

     Elasticsearch是使用java开发,基于Lucene、分布式、通过Restful方式进行交互的近实时搜索平台框架。它的特点有: 分布式,零配置，自动发现,索引自动分片,索弓副本机制, restful风格接口,多数据源,自动搜索负载等。

   * Kibana

     Kibana基于nodejs ,也是一个开源和免费的可视化工具。Kibana可以为Logstash和ElasticSearch提供的日志分析友好的Web界面，可以汇总、分析和搜索重要数据日志。

   * Beats

     Beats 平台集合了多种单一用途数据采集器。它们从成百上千或成千上万台机器和系统向 Logstash 或 Elasticsearch 发送数据。

     Beats由如下组成:

      Packetbeat：轻量型网络数据采集器，用于深挖网线上传输的数据，了解应用程序动态。Packetbeat 是一款轻量型网络数据包分析器，能够将数据发送至 Logstash 或 Elasticsearch。其支 持ICMP (v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache等协议。

      Filebeat：轻量型日志采集器。当您要面对成百上千、甚至成千上万的服务器、虚拟机和容器生成的日志时，请告别 SSH 吧。Filebeat 将为您提供一种轻量型方法，用于转发和汇总日志与文件，让简单的事情不再繁杂。

      Metricbeat ：轻量型指标采集器。Metricbeat 能够以一种轻量型的方式，输送各种系统和服务统计数据，从 CPU 到内存，从 Redis 到 Nginx，不一而足。可定期获取外部系统的监控指标信息，其可以监控、收集 Apache http、HAProxy、MongoDB、MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务。

      Winlogbeat：轻量型 Windows 事件日志采集器。用于密切监控基于 Windows 的基础设施上发生的事件。Winlogbeat 能够以一种轻量型的方式，将 Windows 事件日志实时地流式传输至 Elasticsearch 和 Logstash。

      Auditbeat：轻量型审计日志采集器。收集您 Linux 审计框架的数据，监控文件完整性。Auditbeat 实时采集这些事件，然后发送到 Elastic Stack 其他部分做进一步分析。

      Heartbeat：面向运行状态监测的轻量型采集器。通过主动探测来监测服务的可用性。通过给定 URL 列表，Heartbeat 仅仅询问：网站运行正常吗？Heartbeat 会将此信息和响应时间发送至 Elastic 的其他部分，以进行进一步分析。

      Functionbeat：面向云端数据的无服务器采集器。在作为一项功能部署在云服务提供商的功能即服务 (FaaS) 平台上后，Functionbeat 即能收集、传送并监测来自您的云服务的相关数据。

   * ELastic cloud

     基于 Elasticsearch 的软件即服务(SaaS)解决方案。通过 Elastic 的官方合作伙伴使用托管的 Elasticsearch 服务。

3. 基础概念

   * 搜索：根据关键词返回含有该关键词的所有信息。
   * 全文检索
   * 倒排索引：倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。带有倒排索引的文件我们称为倒排[索引文件](https://baike.baidu.com/item/索引文件)，简称[倒排文件](https://baike.baidu.com/item/倒排文件/4137688)(inverted file)。

   > Lucene：一个封装了全文检索的引擎、搜索算法代码的jar包。可以通过该包中的API开发搜索相关业务，底层会在磁盘建立索引库。

#### ELasticsearch

官网：https://www.elastic.co/cn/products/elasticsearch

lucene官网：https://lucene.apache.org/

一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文**搜索引擎**，基于RESTful web接口。

1. 功能：

   * 分布式的搜索引擎和数据分析引擎
   * 全文检索，结构化检索，数据分析
   * 对海量数据进行近实时的处理

2. 使用场景：

   * 维基百科，类似百度百科，“网络七层协议”的维基百科，全文检索，高亮，搜索推荐
   * Stack Overflow（国外的程序讨论论坛），相当于程序员的贴吧。遇到it问题去上面发帖，热心网友下面回帖解答。
   * GitHub（开源代码管理），搜索上千亿行代码。
   * 电商网站，检索商品
   * 日志数据分析，logstash采集日志，ES进行复杂的数据分析（ELK技术，elasticsearch+logstash+kibana）
   * 商品价格监控网站，用户设定某商品的价格阈值，当低于该阈值的时候，发送通知消息给用户，比如说订阅《java编程思想》的监控，如果价格低于27块钱，就通知我，我就去买。
   * BI系统，商业智能（Business Intelligence）。大型连锁超市，分析全国网点传回的数据，分析各个商品在什么季节的销售量最好、利润最高。成本管理，店面租金、员工工资、负债等信息进行分析。从而部署下一个阶段的战略目标。
   * 百度搜索，第一次查询，使用es。
   * OA、ERP系统站内搜索。

3. **核心概念**

   * 近实时：写入数据时需要1秒后才可被搜索，搜索时需要秒级才能出结果

   * 集群

   * 节点

   * **文档**：

     * es中的最小数据单元，一个document就像数据库中的一条记录，通常以json格式显示。
     * 多个document存储于一个索引（Index）中。
     * 每个文档都有一个唯一的标识符（ID），用于在索引中标识和检索文档。

   * **索引**：包含一堆有相似结构的文档数据。

     * 索引是存储数据的逻辑空间，类似于关系型数据库中的数据库。
     * 索引包含多个文档，并且可以在索引中执行搜索、聚合和分析操作。

   * 映射

     * 映射定义了索引中文档的结构和字段的类型。
     * 映射规定了每个字段的数据类型，如文本、数字、日期等，以及字段的索引方式、分词器等。

   * 字段

   * 类型

     * 在较早的版本中，Elasticsearch 中的文档会根据类型进行分类。但在最新版本中，类型被废弃，建议将所有文档存储在单个索引中。
     * 在新版本中，可以通过字段来对文档进行分类和过滤。

     > **注意**：6.0之前的版本有type（类型）概念，type相当于关系数据库的表，ES官方将在ES9.0版本中彻底删除type。

   * 分片（shared）

     * 为了实现水平扩展和高可用性，Elasticsearch 将索引划分为多个分片。
     * 每个分片是一个独立的索引单元，包含部分文档和索引结构。

   * 副本（replica）

     * 为了提高搜索性能和可用性，Elasticsearch 允许创建索引的副本。

     * 副本是分片的完全复制，可以在集群中的其他节点上进行复制，提供冗余和负载均衡。


| MySQL  | Elasticsearch | 说明                                                         |
| ------ | ------------- | ------------------------------------------------------------ |
| Table  | Index         |                                                              |
| ROW    | Document      |                                                              |
| column | Field         |                                                              |
| Schema | Mapping       |                                                              |
| SQL    | DSL           | DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD |

   > 虽然MySQL和ELasticsearch的概念在实质上有一定区别，但是可以根据上述类比来帮助理解。**Mysql擅长事务类型操作，可以确保数据的安全和一致性。Elasticsearch擅长海量数据的搜索、分析、计算。**

4. 安装

   * 安装jdk
   * 解压ELasticsearch安装包

5. 分词器

   es在创建倒排索引时需要对文档分词；在搜索时，需要对用户输入内容分词。常见的分词器有以下几种：

   * Standard Analyzer：一个基于 Unicode Text Segmentation 算法的分词器，可以将文本分解成单词，并去除一些停用词，如“a”、“the”等。因为它是 Elasticsearch 的默认分词器，所以任何字段如果没有指定别的分词器，都会使用该分词器。
   * Simple Analyzer：只能根据非字母字符对文本进行分解，并将得到的单词转化为小写形式。不支持词干化或停用词过滤，适合简单的短语匹配。
   * Whitespace Analyzer：仅仅是将输入的字符串根据空格分隔成单词序列，适合处理不需要进一步处理的文本，如标识符或者序列号。
   * Keyword Analyzer：将输入的内容当成一个整体，不会进行分词，但是会进行大小写转换等规范化操作。主要用于需要精确匹配的场景，如身份证号、电话号码等。
   * Stop Analyzer：对文本进行分词，并去除其中一些常用词汇，如“a”、“the”等。这是一个较为基础和常用的分词器。
   * Pattern Analyzer：这个分词器使用正则表达式对文本进行分词和规则化。通过灵活的正则表达式来定义分词规则，可以很好地适应各种特殊场景。
   * Language Analyzers：Elasticsearch 还提供了多个针对不同语言的分词器，如中文、日本语、韩语、法语、德语、西班牙语等。

   默认的分词规则对中文处理并不友好。处理中文分词，一般会使用IK分词器（https://github.com/medcl/elasticsearch-analysis-ik）。ik分词器包含两种模式：

   * ik_smart：最少切分，粗粒度
   * ik_max_word：最细切分，细粒度

   同时只需要修改一个ik分词器目录中的config目录中的IkAnalyzer.cfg.xml文件就可以实现拓展词库和停用词库。

## ES快速入门

### 集群管理

~~~
# 集群管理：es提供了一套api，叫做cat api，可以查看es中各种各样的数剧
# 了解集群的健康状况
GET /_cat/health?v

# 查看集群中所有索引
GET /_cat/indices?v
~~~

### Index操作

mapping是对索引库中文档的约束，常见的mapping属性包括：

* type：字段数据类型，常见的简单类型有：
  * 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）
  * 数值：long、integer、short、byte、double、float、
  * 布尔：boolean
  * 日期：date
  * 对象：object
  * ES中支持两种地理坐标数据类型：
    * geo_point：由纬度（latitude）和经度（longitude）确定的一个点。例如："32.8752345, 120.2981576"
    * geo_shape：有多个geo_point组成的复杂几何图形。例如一条直线，"LINESTRING (-77.03653 38.897676, -77.009051 38.889939)"
* index：是否创建索引，默认为true
* analyzer：使用哪种分词器
* properties：该字段的子字段
* copy_to：字段拷贝可以使用copy_to属性将当前字段拷贝到指定字段。

~~~
# 创建索引
PUT /demo?pretty

PUT /user
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "index": true
      },
      "age": {
        "type": "integer"
      },
      "email":{
        "type": "text"
      },
      "title":{
        "type": "text"
        , "analyzer": "ik_smart"
      }
    }
  }  
}

# 查看索引
GET /user

# 删除索引
DELETE /demo?pretty

# 修改索引
# 索引库和mapping一旦创建无法修改，但是可以添加新的字段
PUT /user/_mapping
{
  "properties": {
    "address": {
      "type": "text",
      "analyzer": "ik_smart"
    }
  }
}
~~~

> 在 Elasticsearch 中，使用 PUT 方法创建索引是因为 PUT 方法在 HTTP 协议中被定义为幂等的，而创建索引是一个幂等的操作。即可以多次执行相同的 PUT 请求，但只会创建一个索引。
>
> 在计算机科学中，幂等是一个重要的概念，用于描述一个操作或者函数的特性。**具体来说，幂等指的是对同一个操作进行多次执行的结果与仅执行一次的结果相同。**
>
> 换句话说，无论对一个幂等操作执行多少次，其最终的状态都是一致的。这样的特性对于设计和实现系统和算法非常重要，尤其在分布式系统、网络通信和数据存储等领域。
>
> 下面通过几个例子来说明幂等的概念：
>
> 1. GET 请求：HTTP 的 GET 请求是幂等的，即对同一资源的多次 GET 请求将始终返回相同的结果，并不会对服务器端产生影响或副作用。因此，可以放心地发送多个相同的 GET 请求，而不用担心结果会有变化。
> 2. 数据库的 INSERT 操作：在数据库中，如果执行一条 INSERT 语句多次，实际上只会插入一条记录，因为主键冲突了。所以 INSERT 操作可以看作是幂等的，多次执行也不会改变数据库的状态。
> 3. 去重操作：在处理消息、日志或者其他类型的数据时，往往需要进行去重操作，以避免重复处理相同的数据。去重操作是幂等的，因为无论对同一条数据进行多少次去重，最终结果都只会保留一条。

### Document操作

1. CRUD操作

   ~~~
   # 创建索引
   PUT /book?pretty
   
   # 插入数据
   # 语法：PUT /index/type/id
   PUT /book/_doc/1
   {
   "name": "Bootstrap开发",
   "description": "Bootstrap是由Twitter推出的一个前台页面开发css框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长css页面开发的程序人员）轻松的实现一个css，不受浏览器限制的精美界面css效果。",
   "studymodel": "201002",
   "price":38.6,
   "timestamp":"2019-08-25 19:11:35",
   "pic":"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg",
   "tags": [ "bootstrap", "dev"]
   }
   
   PUT /book/_doc/2
   {
   "name": "java编程思想",
   "description": "java语言是世界第一编程语言，在软件开发领域使用人数最多。",
   "studymodel": "201001",
   "price":68.6,
   "timestamp":"2019-08-25 19:11:35",
   "pic":"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg",
   "tags": [ "java", "dev"]
   }
   PUT /book/_doc/3
   {
   "name": "spring开发基础",
   "description": "spring 在java领域非常流行，java程序员都在用。",
   "studymodel": "201001",
   "price":88.6,
   "timestamp":"2019-08-24 19:11:35",
   "pic":"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg",
   "tags": [ "spring", "java"]
   }
   
   # 查询操作
   # 语法：GET /index/type/id
   GET /book/_doc/1
   
   # 更新（修改）操作
   # 方式一：全局替换，即整体覆盖，要带上所有信息。
   PUT /book/_doc/1
   {
       "name": "Bootstrap开发教程",
       "description": "Bootstrap是由Twitter推出的一个前台页面开发css框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长css页面开发的程序人员）轻松的实现一个css，不受浏览器限制的精美界面css效果。",
       "studymodel": "201002",
       "price":38.6,
       "timestamp":"2019-08-25 19:11:35",
       "pic":"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg",
       "tags": [ "bootstrap", "开发","web"]
   }
   # 方式二：部分
   # 语法：POST /{index}/type /{id}/_update 或者 POST /{index}/_update/{id}
   POST /book/_update/1
   {
     "doc": {
      "name": " Bootstrap开发教程高级"
     }
   }
   
   # 删除操作
   DELETE /book/_doc/1
   ~~~
   

在进行id相同时的两次更新操作，旧文档的内容不会立即删除，只是标记为deleted。适当的时机，集群会将这些文档删除，但版本号（_version）字段不断上升。当然为防止覆盖原有数据，我们在新增时，可以通过下面的语法设置为强制创建，不会覆盖原有文档。

~~~
   PUT /index/ _doc/id/_create
~~~

同样的在进行删除操作时，也不会立即删除，而是标记为删除状态，在合适的时机进行统一删除。

2. 默认自带字段

   * _index：此文档属于哪个索引

     - 原则：类似数据放在一个索引中。数据库中表的定义规则。如图书信息放在book索引中，员工信息放在employee索引中。各个索引存储和搜索时互不影响。
     - 定义规则：英文小写。尽量不要使用特殊字符。

   * _type：类别

     > 以后的es9将彻底删除此字段，所以当前版本在不断弱化type，不需要关注。

   * _id：文档的唯一标识。就像表的id主键。结合索引可以标识和定义一个文档。

     * 手动生成：使用场景通常是数据从其他系统导入时，本身有唯一主键。如数据库中的图书、员工信息等。
     * 自动生成：自动id的特点是长度为20个字符，URL安全，base64编码，GUID，分布式生成不冲突

3. _source字段

   * 插入数据时的所有字段和值。在get获取数据时，在_source字段中原样返回。

   * 可以通过类型下面的语法操作来指定返回_source字段中的指定值

     ~~~
     GET /book/_doc/1?__source_includes=name,price
     ~~~

4. 使用脚本更新

   官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-using.html

   es可以内置脚本执行复杂操作。例如painless脚本。

   > 注意：groovy脚本在es6以后就不支持了。原因是耗内存，不安全远程注入漏洞。

5. es基于_version乐观锁的控制

   **es对于文档的增删改都是基于版本号。**

6. es内部并发控制

   **es内部主从同步时，是多线程异步。乐观锁机制。**

### DSL

Elasticsearch提供了基于JSON的DSL（[Domain Specific Language](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)）来定义查询。常见的查询类型包括：

* 查询所有：查询出所有数据，一般测试用。例如：match_all

* 全文检索（full text）查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：match_query、multi_match_query

* 精确查询：根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如：ids、range、term

* 地理（geo）查询：根据经纬度查询。例如：geo_distance、geo_bounding_box

* 复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：bool、function_score。

  * fuction score：算分函数查询，可以控制文档相关性算分，控制文档排名。当我们利用match查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。
    $$
    TF(词条频率)=\frac{词条出现次数}{文档中词条总数}
    $$

    $$
    IDF(逆文档频率)=Log(\frac{文档总数}{包含词条的文档总数})\\
    score=\sum_i^n TF(词条频率)*IDF(逆文档频率) \tag{TF-IDF算法}
    $$

    $$
    Score(Q,d) = ∑_𝑖^𝑛log⁡(1+ (𝑁 −𝑛+0.5)/(𝑛+0.5))*  (𝑓_𝑖  )/(𝑓_𝑖+ 𝑘_(1 )  * (1 −𝑏+  𝑏 * 𝑑𝑙/𝑎𝑣𝑔𝑑𝑙)) \tag{DM25算法}
    $$

![image-20231006222255180](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202310062223895.png)

通过查询获取到数据后，需要对搜索结果进行处理，es支持一下操作：

1. 排序

   elasticsearch支持对搜索[结果排序](https://www.elastic.co/guide/en/elasticsearch/reference/current/sort-search-results.html)，默认是根据相关度算分（_score）来排序。可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等。

2. 分页

   elasticsearch 默认情况下只返回top10的数据。而如果要查询更多数据就需要修改分页参数了。elasticsearch中通过修改from、size参数来控制要返回的分页结果。

   ES是分布式的，所以会面临**深度分页**问题。如果搜索页数过深，或者结果集（from + size）越大，对内存和CPU的消耗也越高。因此ES设定结果集查询的上限是10000。针对深度分页，ES提供了两种解决方案，[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html)：

   * search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。
   * scroll：原理将排序数据形成快照，保存在内存。官方已经不推荐使用。

3. 高亮：即在搜索结果中把搜索关键字突出显示。

   高亮的原理是将搜索结果中的关键字用标签标记出来，在页面中给标签添加css样式。默认情况下，ES搜索字段必须与高亮字段一致。

DSL查询示例：

~~~
// 基本语法
GET /indexName/_search
{
  "query": {
    "查询类型": {
      "查询条件": "条件值"
    }
  }
}

# 查询所有
GET /hotel/_search
{
  "query": {
    "match_all": {}
  }
}

# match
GET /hotel/_search
{
  "query": {
    "match": {
      "name": "连锁"
    }
  }
}

# multi_match
GET /hotel/_search
{
  "query": {
    "multi_match": {
      "query": "7天连锁",
      "fields": ["brand","name","business"]
    }
  }
}

# match：根据一个字段查询，multi_match：根据多个字段查询，参与查询字段越多，查询性能越差

// 语法：term查询
GET /indexName/_search
{
  "query": {
    "term": {
      "FIELD": {
        "value": "VALUE"
      }
    }
  }
}

// range查询
GET /indexName/_search
{
  "query": {
    "range": {
      "FIELD": {
        "gte": 10,
        "lte": 20
      }
    }
  }
}

# term查询
GET /hotel/_search
{
  "query": {
    "term": {
      "city": {
        "value": "上海"
      }
    }
  }
}

# range查询,gte为大于等于，gt为大于
GET /hotel/_search
{
  "query": {
    "range": {
      "price": {
        "gte": 200,
        "lte": 500
      }
    }
  }
}

# distance查询
GET /hotel/_search
{
  "query": {
    "geo_distance":{
      "distance":"15km",
      "location":"31.21, 121.5"
    }
  }
}

# boolean query
# must：必须匹配每个子查询，类似“与”
# should：选择性匹配子查询，类似“或”
# must_not：必须不匹配，不参与算分，类似“非”
# filter：必须匹配，不参与算分
# boolean query
GET /hotel/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "term": {
            "city": "上海"
          }
        }
      ],
      "should": [
        {
          "term": {
            "brand": "皇冠假日"
          }
        },
        {
          "term": {
            "brand": "华美达"
          }
        }
      ],
      "must_not": [
        {
          "range": {
            "price": {
              "lte": 500
            }
          }
        }
      ],
      "filter": [
        {
          "range": {
            "score": {
              "gte": 45
            }
          }
        }
      ]
    }
  },
  "sort": [
    {
      "score": {
        "order": "desc"
      }
    }
  ],
  "from": 5,
  "size": 20
}

# 高亮显示
GET /hotel/_search
{
  "query": {
    "match": {
      "name": "上海"
    }
  },
  "highlight": {
    "fields":{ 
      "name": {
        "require_field_match": "true", 
        "pre_tags": "<em>",
        "post_tags": "</em>"
      }
    }
  }
}
~~~

## ES客户端

官方文档：https://www.elastic.co/guide/en/elasticsearch/client/index.html

ES官方提供了各种不同语言的客户端，用来操作ES。这些客户端的本质就是组装DSL语句，通过http请求发送给ES.

### java客户端

JavaAPI文档：https://www.elastic.co/guide/en/elasticsearch/client/java-rest/7.3/java-rest-overview.html

导入依赖：

~~~xml
    <dependency>
      <groupId>org.elasticsearch.client</groupId>
      <artifactId>elasticsearch-rest-high-level-client</artifactId>
      <version>7.10.1</version>
      <exclusions>
        <exclusion>
          <groupId>org.elasticsearch</groupId>
          <artifactId>elasticsearch</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.elasticsearch</groupId>
      <artifactId>elasticsearch</artifactId>
      <version>7.10.1</version>
    </dependency>
~~~

初始化RestHighLevelClient：

```java
RestHighLevelClient client = new RestHighLevelClient(RestClient.builder(
        HttpHost.create("https://es-imv6dsro.public.tencentelasticsearch.com:9200"))
);
```

操作索引库：

```java
@Test
void testCreateHotelIndex() throws IOException {
    // 创建请求
    CreateIndexRequest indexRequest = new CreateIndexRequest("hotel");
    // 组织请求参数
    indexRequest.source(HotelConstants.MAPPING_TEMPLATE, XContentType.JSON);
    // 发起请求
    client.indices()
          .create(indexRequest, RequestOptions.DEFAULT);
}
/**
     * 删除索引库
     */
    @Test
    void testDeleteHotelIndex() throws IOException {
        DeleteIndexRequest indexRequest = new DeleteIndexRequest("hotel");
        AcknowledgedResponse acknowledgedResponse = client.indices()
                                                          .delete(indexRequest, RequestOptions.DEFAULT);
        log.info(JSON.toJSONString(acknowledgedResponse));
    }

    /**
     * 判断索引库是否存在
     * @throws IOException
     */
    @Test
    void testExistHotelIndex() throws IOException {
        GetIndexRequest indexRequest = new GetIndexRequest("hotel");
        GetIndexResponse getIndexResponse = client.indices()
                                                  .get(indexRequest, RequestOptions.DEFAULT);
        log.info(JSON.toJSONString(getIndexResponse));
    }
```

操作Document：

```java
/**
 * 创建Document
 */
@Test
void testCreateDocument() {
    // 获取数据库数据
    List<Hotel> hotelList = hotelService.list();
    hotelList.forEach(hotel -> {
        // 创建请求
        IndexRequest indexRequest = new IndexRequest("hotel").id(hotel.getId().toString());
        // 准备json数据
        Map<String, Object> source = BeanUtil.beanToMap(new HotelDoc(hotel));
        indexRequest.source(source,XContentType.JSON);
        // 发起请求
        IndexResponse response = null;
        try {
            response = client.index(indexRequest, RequestOptions.DEFAULT);
        } catch (IOException e) {
            e.printStackTrace();
        }
        log.info(JSON.toJSONString(response));
    });
}

    /**
     * 批量导入数据到es
     */
    @Test
    void testBulk() throws IOException {
        List<Hotel> hotelList = hotelService.list();
        BulkRequest bulkRequest = new BulkRequest();
        hotelList.forEach(hotel -> {
            bulkRequest.add(new IndexRequest().index("hotel").source(BeanUtil.beanToMap(new HotelDoc(hotel))).id(hotel.getId().toString()));
        });
        client.bulk(bulkRequest,RequestOptions.DEFAULT);
    }

/**
 * 查询Document
 */
@Test
void testGetDocument() throws IOException {
    GetRequest getRequest = new GetRequest("hotel", "47066");
    GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT);
    log.info(JSON.toJSONString(getResponse));
    String source = getResponse.getSourceAsString();
    log.info("{}",JSON.parseObject(source));
}

/**
 * 更新Document
 */
@Test
void testUpdateDocument() throws IOException {
    UpdateRequest updateRequest = new UpdateRequest("hotel", "47066");
    updateRequest.doc("price",500);
    client.update(updateRequest,RequestOptions.DEFAULT);
}

/**
 * 删除Document
 */
@Test
void testDeleteDocument() throws IOException {
    DeleteRequest deleteRequest = new DeleteRequest("hotel", "47066");
    client.delete(deleteRequest,RequestOptions.DEFAULT);
}
```

查询Document：



### Python客户端

# 分布式缓存

# 分布式事务

# 分布式任务调度

## xxl-job

xxl社区：[XXL开源社区 | 首页 (xuxueli.com)](https://www.xuxueli.com/index.html)

xxl-job：[分布式任务调度平台XXL-JOB (xuxueli.com)](https://www.xuxueli.com/xxl-job/#《分布式任务调度平台XXL-JOB》)

gitee：[xxl-job: 一个分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。 (gitee.com)](https://gitee.com/xuxueli0323/xxl-job)

github：[GitHub - xuxueli/xxl-job: A distributed task scheduling framework.（分布式任务调度平台XXL-JOB）](https://github.com/xuxueli/xxl-job)

### 快速入门

* [Spring Boot 集成 XXL-JOB 任务调度平台]([Spring Boot 集成 XXL-JOB 任务调度平台 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/349195503))

# 监控和日志

# RPC

参考：https://www.bilibili.com/video/BV11i4y1N7LQ/?spm_id_from=333.337.search-card.all.click&vd_source=fabefd3fabfadb9324761989b55c26ea

## Remoting协议

Remoting协议是一种用于分布式系统中的远程过程调用（RPC）的通信协议。它允许不同计算机之间的应用程序通过网络进行通信，以便调用和执行远程计算机上的方法或函数。

Remoting协议的主要目标是使远程调用的过程像本地调用一样简单和透明。它隐藏了底层网络通信的细节，使开发者能够以类似于本地方法调用的方式编写代码。

1. 主要特点：
   * 远程调用透明性：Remoting协议使得远程调用过程对开发者来说是透明的。开发者可以像调用本地方法一样调用远程方法，不需要关注底层的网络通信和序列化过程。
   * 语言无关性：Remoting协议不依赖于特定的编程语言。它可以用于支持多种编程语言之间的远程通信，例如Java、C#、Python等。
   * 传输方式灵活性：Remoting协议支持多种传输方式，如TCP、HTTP等。开发者可以根据需求选择合适的传输方式。
   * 序列化和反序列化支持：Remoting协议提供了序列化和反序列化的支持，用于将方法参数和返回值在不同计算机之间进行传输和还原。这使得对象的跨网络传输变得简单和高效。
   * 异常处理：Remoting协议能够处理远程调用中的异常情况，并将异常信息传递给调用方。这样，开发者可以在远程调用过程中处理异常，确保系统的稳定性和可靠性。
   * Remoting协议通常需要使用专门的框架或库来实现，如Java的RMI（Remote Method Invocation）和.NET的Remoting框架。

## gRPC协议

文档： https://grpc.io/

gRPC（全称为Google Remote Procedure Call）是一种远程过程调用协议，由Google开发并于2015年对外发布。它基于HTTP/2协议，并使用Protocol Buffers作为数据序列化和接口定义语言。

gRPC旨在简化分布式系统间的通信，它支持多种编程语言（如C++, Java, Python等），并提供了强大的功能和性能优势。

1. 主要特点：
   * 高性能：gRPC使用二进制数据格式（Protocol Buffers）和基于HTTP/2的传输协议，具有较低的序列化和网络开销，以及高效的多路复用和流控制机制。这使得gRPC在性能方面比传统的文本协议（如JSON或XML）更加高效。
   * 强大的接口定义和代码生成：gRPC使用基于IDL（Interface Definition Language）的Protocol Buffers来定义服务接口和消息格式。通过定义清晰的接口规范，它能够自动生成跨多种编程语言的客户端和服务器端代码，简化了开发者的工作量。
   * 支持多种通信模式：gRPC支持四种类型的RPC（Remote Procedure Call）方法调用，包括简单的单向调用、服务端流式调用、客户端流式调用和双向流式调用。这使得开发者能够根据具体的需求选择适当的通信模式，实现灵活的数据交互。
   * 提供拦截器和中间件：gRPC支持拦截器和中间件机制，使开发者能够在请求和响应的处理过程中进行自定义操作。这让开发者可以方便地实现认证、日志记录、错误处理等功能，提高代码的可重用性和可维护性。
   * 可扩展性：gRPC提供了扩展能力，允许开发者根据需要添加新的功能和协议扩展。例如，可以通过自定义插件扩展其认证和授权机制，或者添加基于底层传输协议的自定义功能。

# apisix

官网：https://apisix.apache.org/zh/

参考：

* [【云原生网关】apisix使用详解](http://www.rply.cn/news/71253.html)

# 认证授权

## 基本概念

一般指根据系统设置的安全规则或者安全策略，用户可以访问而且只能访问自己被授权的资源。权限管理几乎出现在任何系统里面，前提是需要有用户和密码认证的系统。

1. 重要概念

   * 认证：通过用户名和密码成功登陆系统后，让系统得到当前用户的角色身份。认证是为了保护系统的隐私数据与资源,户的身份合法访可访问该系统的资源。目前常见的用户身份认证方式有：**用户名密码登录**，**二维码登录**，**手机短信登录**，**指纹认证**等方式。

   * 授权：系统根据当前用户的角色，给其授予对应可以操作的权限资源。**如何授权即如何控制用户对资源的访问进行控制**。授权的数据模型：

     Who ,即主体( Subject) , 主体一般是指用户, 也可以是程序,需要访问系统中的资源。
     What ,即资源( Resource) , 如系统菜单、页面、 按钮、代码方法、系统商品信息、系统订单信息等。系统菜单、页面、按钮、代码方法都属于系统功能资源,对于web系统每个功能资源通常对应一个URL ;系统商品信息、系统订单信息都属于实体资源(数据资源) , 实体资源由资源类型和资源实例组成,比如商品信息为资源类型,商品编号为001的商品为资源实例。
     How ,权限/许可( Permission) , 规定了用户对资源的操作许可,权限离开资源没有意义,如用户查询权限、用户添加权限、某个代码方法的调用权限、编号为001的用户的修改权限等,通过权限可知用户对哪些资源都有哪此操作许可。

   * 会话：在Web开发中，会话是指在客户端和服务器之间跟踪和存储用户信息的机制，用于跟踪和存储用户的状态信息。在一个会话中，服务器会为每个用户分配一个唯一的会话标识符（Session ID），该标识符通常通过Cookie或URL参数传递给客户端。通过会话，用户可以在不同页面间保持状态，并在登录状态下访问受限资源。

   认证是为了保证用户身份的合法性，授权则是为了更细粒度的对隐私数据进行划分，授权是在认证通过后发生的，控制不同的用户能够访问不同的资源。

   ![image-20230827223459026](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308272235454.png)

2. 权限管理三要素

   * 用户：主要包含用户名，密码和当前用户的角色信息，可实现认证操作。
   * 角色：主要包含角色名称，角色描述和当前角色拥有的权限信息，可实现授权操作。
   * 权限：权限也可以称为菜单，主要包含当前权限名称，url地址等信息，可实现动态展示菜单。

   > 用户与角色是多对多的关系，角色与权限是多对多的关系，用户与权限没有直接关系，二者是通过角色来建立关联关系的。
   
3. 授权实现：RBAC

   * RBAC基于角色授权（Role-Based Access Control）

   * RBAC基于资源授权（Resoure-Based Access Control）

## 会话技术

用户认证通过后,为了避免用户的每次操作都进行认证可将用户的信息保存在会话中。会话就是系统为了保持当前用户的登录状态所提供的机制，常见的有**基于session方式**、**基于token方式**等。

会话技术的存在有以下几个主要原因：

1. 跨请求的状态管理：Web是一种无状态的协议，每个HTTP请求都是独立的，服务器无法直接识别两个不同请求之间的关联。为了跟踪用户的状态，需要使用会话技术来存储和管理用户的信息，以便在不同请求之间保持状态的连续性。
2. 用户认证和权限控制：会话技术可以用于验证用户的身份并管理用户的访问权限。通过会话，用户可以在登录后访问受限资源，并且只需要进行一次登录验证，而不需要在每次请求中重新验证用户的身份。
3. 数据共享：会话技术允许在多个页面或请求之间共享数据。通过会话，应用程序可以在不同页面间传递数据，从而实现用户操作的连续性和数据的一致性。

会话技术的实现：

1. 会话标识符（Session ID）的生成和传递：当用户登录到Web应用程序时，服务器为该用户创建一个唯一的会话标识符（通常是一个长随机字符串），并将其发送给客户端。这通常通过在Cookie中设置会话ID或将其作为URL参数附加到链接中来实现。
2. 服务器端的会话存储：服务器接收到带有会话ID的请求后，会根据该ID检索或创建一个与该会话相关联的数据存储区域（通常是内存或数据库）。服务器使用会话ID来识别客户端，并在会话存储中保存和更新与该标识符相关的状态和数据。
3. 会话数据的读写和管理：在会话期间，服务器和应用程序可以向会话存储中读取和写入数据。例如，可以将用户的身份验证状态、所选语言、购物车内容等信息存储在会话数据中。应用程序可以根据需要从会话存储中读取数据，也可以更新或删除数据。
4. 会话过期和销毁：会话通常具有一定的生命周期，可以根据需求进行配置。当会话过期或用户注销时，服务器会将会话从存储中删除，清除与该用户相关的状态信息。

会话安全性问题：

- 会话劫持（Session Hijacking）：攻击者获取合法用户的会话ID并冒充用户。
- 会话固定（Session Fixation）：攻击者通过在用户会话之前操纵会话ID，使得用户登录后的会话被攻击者控制。
- 会话泄露（Session Leakage）：会话ID被无意间泄露给其他人，使得其他人可以冒充用户。

为了避免这些安全问题，应该使用安全的会话管理技术，如使用加密的会话ID、定期更换会话ID、确保会话存储区域的安全等。

### 基于session的认证机制

基于Session的认证机制由Servlet规范定制, Servlet容器已实现,用户通过HttpSession的操作方法即可实现，如下是HttpSession相关的操作API。

### 基于token的认证机制

## Spring Security

参考：http://www.imooc.com/wiki/securitylesson/springsecurityintro.html

### 简介

Spring Security 是 Spring 家族的中提供**认证**、**授权**和**攻击防护**功能的一套安全框架。Spring Security 支持命令式和响应式两种开发模式，它也是 Spring 应用在安全框架方面的公认标准。Spring Security 的前身是 Acegi security。Acegi security 在 1.0.7 版本之后便不再跟新，转而以 Spring Security 2.0 的身份出现在 Spring 大家庭中。**常规攻击防范**在 Spring Security 安全框架中是默认开启的，常见的威胁抵御方式有：

- 防止伪造跨站请求（CSRF）
- 安全响应头（HTTP Response headers）
- HTTP 通讯安全

#### 功能模块

Spring Security 包含的功能模块如下：

- **Core**

  核心模块，包含认证、访问控制、集成支持、配置接口等，所有 Spring Security 项目都需要依赖它。

  对应的 Jar 文件：spring-security-core.jar。

- **Remoting**

  Spring security 中的 Remoting 模块提供了与 Spring Remoting 集成的能力。当我们要开发远程客户端的时候需要用到此模块。

  对应的 Jar 文件：spring-security-remoting.jar。

- **Web**

  Spring security 中的 Web 模块，提供了接口过滤器和 Web 安全的基础代码。例如 Servlet 应用接口。如果我们开发的是基于 Web 认证的服务，或者是基于 URL 的访问控制时，将需要用到此模块。

  对应的 Jar 文件：spring-security-web.jar

- **Config**

  Spring security 中的 Config 模块，包含了安全框架命名空间的解析功能与提供了 Java 配置代码。当我们需要使用 XML 方式或者 Java 配置方式时，需要用到此模块。

  对应的 Jar 文件：spring-security-config.jar

- **LDAP**

  Spring security 中的 Ldap 模块，提供了对 Ldap 认证的支持，当我们使用 Ldap 认证时，需要用到此模块。

  对应的 Jar 文件：spring-security-ldap.jar

- **OAuth 2.0 相关模块**

  Spring security 提供了对 OAuth 2.0 的支持，具体分为以下几个模块。

  - **OAuth 2.0 Core**

    OAuth 2.0 Core 模块是 Spring security 安全框架中，对 OAuth 2.0 支持的核心模块，包含了认证功能与 OpenID 的基本支持。

    对应的 Jar 文件：spring-security-oauth2-core.jar

  - **OAuth 2.0 Client**

    OAuth 2.0 Client 模块是 OAuth 2.0 客户端认证授权基础，当我们需要在客户端实现 OAuth 2.0 登录功能时，需要添加此模块。

    对应的 Jar 文件：spring-security-oauth2-client.jar

  - **OAuth 2.0 JOSE**

    OAuth 2.0 JOSE （Javascript Object Signing and Encryption）模块，提供了基于 JS 对象的认证与加解密功能，核心目标是实现 JS 安全传输能力。主要功能有：JWT、 JWS、JWE、JWK。

    对应的 Jar 文件：spring-security-oauth2-jose.jar

  - **OAuth 2.0 Resource Server**

    OAuth 2.0 resource server 模块，提供了 OAuth 2.0 资源服务的基本功能，也就是对资源的访问控制。

    对应的 Jar 文件：spring-security-oauth2-resource-server.jar

- **ACL**

  ACL 模块提供了基于域对象的访问控制。

  对应的 Jar 文件：spring-security-acl.jar

- **CAS**

  CAS 模块适用于需要使用 CAS 单点登录的系统，可以用于单点登录客户端的集成。

  对应的 Jar 文件：spring-security-cas.jar

- **OpenID**

  OpenID 模块适用于需要集成外部 OpenID 的认证系统。使用该模块功能同时还需要依赖 OpenID4Java 。

  对应的 Jar 文件：spring-security-openid.jar

- **Test**

  Test 模块提供了对 Spring security 进行单元测试的能力。

  对应的 Jar 文件：spring-security-test.jar

### 快速入门

> 以springboot项目为示例

1. 依赖导入

   spring项目

   ~~~xml
           <dependency>
               <groupId>org.springframework.security</groupId>
               <artifactId>spring-security-web</artifactId>
               <version>5.5.8</version>
           </dependency>
           <dependency>
               <groupId>org.springframework.security</groupId>
               <artifactId>spring-security-config</artifactId>
               <version>5.5.8</version>
           </dependency>
   ~~~

   spingboot项目

   ~~~xml
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-starter-security</artifactId>
               <version>2.5.14</version>
           </dependency>
   ~~~

2. 启动项目并测试（不进行自定义配置，全部使用默认配置）

   在未进行任何的配置默认情况下所有请求都会被拦截，且会跳转到Spring Security默认提供的登录页。 项目在默认配置下，会自动生成一个名为「user」的用户，并在控制台的日志信息中打印生成一个随机密码用于登录该账户。SpringSecurity默认开启一系列基于 springSecurityFilterChain 的 Servlet 过滤器，包含了几乎所有的安全功能，例如：保护系统 URL、验证用户名、密码表单、重定向到登录界面等；创建 UserDetailsService 实例，并生成随机密码，用于获取登录用户的信息详情；将安全过滤器应用到每一个请求上。

### 原理解析

#### 架构设计

**SpringSecurity主要是通过Servlet 的过滤器机制来实现安全逻辑的。**

* `DelegatingFilterProxy`：这个过滤器的作用是连接 Servlet 项目中 Servlet 容器和 Spring 项目的核心上下文对象（ApplicationContext）。Servlet 容器允许对其过滤器做自定义的扩展，DelegatingFilterProxy 将 Spring 的 Bean 过滤器（Bean Filter）插入到 Servlet 的过滤器链中执行。

* `FilterChainProxy`：核心过滤器，负责管理和调度一系列子过滤器

* `SecurityFilterChain`：在 Spring Security 各个模块中，内置已实现了一系列的「安全过滤器」，可以满足常见的认证、鉴权等功能需求。

  通过`HttpSecurity`类可以使用SecurityFilterChain和在该链中增减过滤器。然后链中的过滤器顺序由`org.springframework.security.config.annotation.web.builders.FilterComparator`类来实现。在 Spring Security 5.3.2 中，共内置了 33 个安全过滤器，如下表所示：

  | 顺序号 | 过滤器名称                               | 简述                                                       |
  | :----- | :--------------------------------------- | :--------------------------------------------------------- |
  | 1      | ChannelProcessingFilter                  | 检查 web 请求通道，如：http、https                         |
  | 2      | ConcurrentSessionFilter                  | 检查 Session 状态，更新 Session 最后访问时间               |
  | 3      | WebAsyncManagerIntegrationFilter         | 关联 Spring Web 上下文和 Spring Security 上下文            |
  | 4      | SecurityContextPersistenceFilter         | 从 Session 构建 SecurityContext                            |
  | 5      | HeaderWriterFilter                       | 往请求头或响应头里写入信息                                 |
  | 6      | CorsFilter                               | 跨域请求头                                                 |
  | 7      | CsrfFilter                               | 跨站请求伪造                                               |
  | 8      | LogoutFilter                             | 注销过滤器                                                 |
  | 9      | OAuth2AuthorizationRequestRedirectFilter | OAuth2 请求重定向                                          |
  | 10     | Saml2WebSsoAuthenticationRequestFilter   | SAML2 单点登录认证请求过滤器                               |
  | 11     | X509AuthenticationFilter                 | X509 认证过滤器                                            |
  | 12     | AbstractPreAuthenticatedProcessingFilter | 预认证处理                                                 |
  | 13     | CasAuthenticationFilter                  | 单点认证过滤器                                             |
  | 14     | OAuth2LoginAuthenticationFilter          | OAuth2 认证过滤器                                          |
  | 15     | Saml2WebSsoAuthenticationFilter          | SAML2 单点登录认证过滤器                                   |
  | 16     | UsernamePasswordAuthenticationFilter     | 用户名密码认证过滤器                                       |
  | 17     | ConcurrentSessionFilter                  | 检查 Session 状态，更新 Session 最后访问时间。第二次出现。 |
  | 18     | OpenIDAuthenticationFilter               | Open ID 认证过滤器                                         |
  | 19     | DefaultLoginPageGeneratingFilter         | 生成 `/login` 页面                                         |
  | 20     | DefaultLogoutPageGeneratingFilter        | 生成 `/logout` 页面                                        |
  | 21     | DigestAuthenticationFilter               | 数字签名认证过滤器                                         |
  | 22     | BearerTokenAuthenticationFilter          | Bearer Token 认证过滤器                                    |
  | 23     | BasicAuthenticationFilter                | 基本身份认证过滤器                                         |
  | 24     | RequestCacheAwareFilter                  | 缓存请求状态过滤器                                         |
  | 25     | SecurityContextHolderAwareRequestFilter  | 安全上下文请求辅助过滤器                                   |
  | 26     | JaasApiIntegrationFilter                 | JAAS 认证授权过滤器                                        |
  | 27     | RememberMeAuthenticationFilter           | 实现记住我功能                                             |
  | 28     | AnonymousAuthenticationFilter            | 匿名认证过滤器                                             |
  | 29     | OAuth2AuthorizationCodeGrantFilter       | OAuth2 认证授权码                                          |
  | 30     | SessionManagementFilter                  | 管理 Session                                               |
  | 31     | ExceptionTranslationFilter               | 异常事件处理过滤器                                         |
  | 32     | FilterSecurityInterceptor                | 动态权限配置                                               |
  | 33     | SwitchUserFilter                         | 切换账户                                                   |

* WebSecurityConfigurerAdapter类：可以通过继承该类来自定义系统的安全配置。覆盖该类中的`configure(HttpSecurity http)`方法，可以指定URL路径和添加包括认证方式、角色授权、资源访问控制等各种安全配置

* `HttpSecurity`：主要用于配置拦截器链的关键类，通过该类可以添加各种安全配置。通过使用`addFilterAfter`、`addFilterBefore`、`addFilter`、`addFilterAt`方法来向链中指定顺序插入过滤器。

* `WebSecurity`：用于配置Spring Security的相关设置，例如是否启用CSRF保护、设置忽略URL等。

![image-20230831224330027](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308312243497.png)

![image-20230829220338611](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308292203812.png)

![image-20230829220753695](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308292207269.png)

SecurityContextPersistenceFilter：整个拦截过程的入口和出口，在请求开始时从配置好的SecurityContextRepository中获取SecurityContext ,然后把它设置给SecurityContextHolder。在请求完成后将SecurityContextHolder持有的SecurityContext再保存到配置好的SecurityContextRepository ,同时清除securityContextHolder所持有的SecurityContext ;
UsernamePasswordAuthenticationFilter：用于处理来自表单提交的认证。该表单必须提供对应的用户名和密码,其内部还有登录成功或失败后进行处理的AuthenticationSuccessHandler和AuthenticationFailureHandler ,这些都可以根据需求做相关改变;
FilterSecurityInterceptor：用于保护web资源的,使用AccessDecisionManager对当前用户进行授权访问。
ExceptionTranslationFilter：能够捕获来自FilterChain所有的异常,并进行处理。但是它只会处理两类异
常: AuthenticationException和AccessDeniedException ,其它的异常它会继续抛出。

#### 异常回收机制

#### 认证流程

![image-20230829225101910](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308292251183.png)

#### 授权流程

### 源码分析

## Shiro

## sa-token

## 统一单点登录（SSO）

常见的经典统一单点登录(SSO)实现方案有以下几种：

1. 基于代理服务器的SSO： 该方案使用一个专门的代理服务器，作为用户与应用系统之间的中介。当用户访问一个需要验证的应用系统时，代理服务器会负责接收用户的凭据并进行身份验证，然后将令牌传递给应用系统进行授权。代理服务器会为每个用户生成唯一的会话标识，并通过Cookie或请求参数的方式在用户浏览器中保存该会话标识。在用户访问其他应用系统时，代理服务器会验证会话标识，以确定用户是否已经通过身份验证。
2. 基于令牌的SSO（Token-based SSO）： 这种方案使用令牌机制来实现SSO。当用户通过身份认证后，认证中心会颁发一个令牌给用户。令牌包含用户的身份信息和权限，通常是一个加密的字符串。在用户访问其他应用系统时，他们需要将令牌发送给该系统进行验证。这种方案可以使用JSON Web Token（JWT）或Security Assertion Markup Language（SAML）等标准来实现令牌的生成和验证。
3. 基于身份提供商的SSO（Identity Provider-based SSO）： 这种方案将身份验证和授权的责任交给一个专门的身份提供商（IdP）。用户首先通过身份提供商进行身份验证，并获取一个身份令牌。然后，用户可以使用该令牌访问其他应用系统，而无需再次提供凭据。这种方案的一个典型示例是使用OpenID Connect或OAuth 2.0协议，其中身份提供商充当认证服务器并颁发访问令牌。
4. 基于统一目录的SSO： 这种方案使用一个集中式的用户目录（如LDAP或Active Directory）来管理用户身份和权限信息。用户只需要在该目录中进行一次身份验证，然后可以访问其他应用系统。其他应用系统会与统一目录进行集成，以验证用户的身份和权限。

## 第三方登录

JustAuth：

* 项目地址（gitee）：https://gitee.com/yadong.zhang/JustAuth
* 文档：https://www.justauth.cn/

钉钉登录：[实现第三方应用钉钉扫码登录](https://blog.csdn.net/weixin_43260238/article/details/126855205)

# 工作流

* jBPM
* Activiti
* Flowable
* CAMUNDA
* **LiteFlow**

典型责任链模式vs流程引擎模式

![image-20230924205004784](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202309242050742.png)

## 核心概念

1. 审批流vs工作流vs业务流

# Rancher

官网：https://www.rancher.com/

文档：https://docs.rancher.cn/