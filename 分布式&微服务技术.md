# 	微服务技术

## 微服务简介

### 微服务技术栈

1. 服务网关
2. 注册中心
3. 配置中心
4. 服务集群
5. 分布式缓存
6. 分布式搜索
7. 分布式日志框架
8. 统一部署平台

+++

学习课程：[SpringCloud+RabbitMQ+Docker+Redis+搜索+分布式，系统详解springcloud微服务技术栈课程|黑马程序员Java微服务](https://www.bilibili.com/video/BV1LQ4y127n4/?p=1&vd_source=fabefd3fabfadb9324761989b55c26ea)

![image-20220616221927980](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206162257980.png)

![image-20220616222141070](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206162258405.png)

![image-20220616221642790](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206162216086.png)

![image-20230311183945358](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303111839545.png)

学习课程：[尚硅谷2024最新SpringCloud教程，springcloud从入门到大牛](https://www.bilibili.com/video/BV1gW421P7RD/?p=2&spm_id_from=pageDriver&vd_source=fabefd3fabfadb9324761989b55c26ea)

> 使用的技术栈和框架相关版本：
>
> * Java17+
> * boot3.2.0
> * cloud2023.0.0
> * cloud alibaba 2022.0.0.0-RC2
> * Maven 3.9+
> * Mysql 8.0+

![image-20240303122017432](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202403031220846.png)

### 微服务架构演变

1. 单体架构：将业务所有功能集中在一个项目中开发，生成一个包进行部署

   * 优点：架构简单、部署成本低
   * 缺点：耦合度高

2. 分布式架构：根据业务功能对系统拆分，每个业务模块作为一个独立项目开发，称为一个服务。

   * 优点：降低服务耦合度，有利于服务升级扩展
   * 服务治理（分布式架构的要考虑的问题）
     * 服务拆分粒度如何?
     * 服务集群地址如何维护?
     * 服务之间如何实现远程调用?
     * 服务健康状态如何感知?

3. 微服务：**微服务是一种经过良好架构设计的分布式架构方案**

   * 微服务架构特征:

     * 单一职责:微服务拆分粒度更小，每-一个服务都对应唯一的业务能力，做到单一职责,避免重复业务开发
     * 面向服务：微服务对外暴露业务接口
     * 自治：团队独立、技术独立、数据独立、部署独立
     * 隔离性强：服务调用做好隔离、容错、降级,避免出现级联问题

   * 核心设计原则

     * 单一职责原则（SRP）：服务如何划分边界？
  * 领域驱动设计（DDD）：通过限界上下文（Bounded Context）划分服务。
     * 康威定律：组织架构如何影响系统设计？
     * 微服务的分布式本质：CAP 定理、BASE 理论。
   
   * 框架：在国内最知名的微服务技术框架就是SpringCloud和阿里巴巴Dubbo。
   
   * 技术对比
   
     ![image-20220616225122343](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206162258252.png)
     
   * 微服务功能组件
   
     * 服务注册发现：~~Eureka~~、**Nacos**、Consul、Zookeeper
     * 统一配置管理：~~SpringCloudCofing~~, **Nacos**
     * 服务负载与远程调用：Netflix，Feign，**OpenFeign**, Dubbo, ~~Ribbon~~, LoadBalancer
     * 统一网关路由：SpringCloudGateway，~~zuul~~
     * 服务链路监控：Zipkin，~~Sleuth~~，Mcirometer Tracing
     * 服务熔断和降级：~~Hystrix~~，Circuit Breaker（Resilience4J），Sentinel
     * 分布式事务：**Alibaba Seata**，LCN，Hmily
     
     > 上面及整篇笔记中使用删除线的组件表示这些组件要不已经被SpringCloud移除组件体系，要不并不是目前使用的主流组件。
     
* 服务搭建基本流程

     * 建项目（模块）
     * POM填写
     * 配置YML
     * 启动类

## Spring Cloud & SpringCloudAlibaba

### Spring Cloud

官网：https://spring.io/projects/spring-cloud/

源码：https://github.com/spring-cloud

1. 简介：目前国内使用最广泛的微服务框架，**分布式微服务架构的一站式解决方案，是微服务架构落地技术的集合体**。

2. SpringCloud和SpringBoot的版本兼容性

   ![image-20220616225638824](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181721335.png)
   
3. 重要组件

   * 服务注册与发现：Consul
* 服务调用与负载均衡：OpenFeign，LoadBalancer
   * 链路追踪：Micrometer Tacing
   * 服务网关：GateWay
   * 配置管理：Consul
   * 服务熔断与降级：Circuit Breaker
   
4. 相关组件历史变迁

   * 2020年Netflix OSS被移除：

     > Netflix OSS（Open Source Software）是指Netflix开源的一系列软件工具和框架，用于支持其在大规模分布式系统中的应用程序开发和运维。这些工具和框架旨在帮助开发人员构建高可靠性、高性能的云原生应用。
     >
     > 一些著名的Netflix OSS项目包括：
     >
     > 1. **Eureka**：一个基于REST的服务发现框架，用于在Netflix基础架构中实现微服务架构中的服务注册和发现。
     > 2. **Hystrix**：一个用于实现容错和延迟容忍的库，通过隔离服务之间的通信，防止级联故障，并提供回退机制。
     > 3. **Zuul**：一个动态路由、监控和安全的网关服务，用于Netflix的边缘服务，支持动态路由、负载均衡、验证和监控等功能。
     > 4. **Ribbon**：一个基于HTTP和TCP的客户端负载均衡器，用于在客户端发起请求时进行负载均衡。
     > 5. **Archaius**：一个配置管理库，支持动态配置管理和监控。
     > 6. **Feign**：一个声明式的HTTP客户端，简化了编写服务之间通信的代码。
     > 7. **Chaos Monkey**：一个用于在生产环境中模拟故障的工具，有助于测试系统的弹性和稳定性。

### Spring Cloud Alibaba

官网：https://sca.aliyun.com/?spm=5176.29160081.0.0.5f0478fetqumI2

源码：https://github.com/alibaba/spring-cloud-alibaba

1. 简介：致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。
2. 主要功能
3. 重要组件
   * 服务注册与发现：Nacos
   * 配置管理：Nacos
   * 分布式事务：Seata
   * 服务熔断与降级：Sentinel

## 服务注册与发现

常见服务注册中心组件列表：

* ~~Eureka~~
* **Consul**
* Etcd
* **Nacos**
* ZooKeeper 
* Dubbo 

### 服务拆分

1. 服务拆分注意事项：

   * 不同微服务，不重复开发相同业务
   * 微服务数据独立，不访问其他微服务的数据库
   * 微服务可以将自己的业务暴露为接口，供其他服务使用


### ~~EureKa~~

1. 服务调用中的问题

   * 服务消费者该如何获取服务提供者的地址信息?(服务启动时注册自己的信息到eureka，消费者根据服务名向Eureka拉取提供者信息)
   * 如果有多个服务提供者,消费者该如何选择?（利用负载均衡算法）
   * 消费者如何得知服务提供者的健康状态? （服务这每30秒向Eureka发送心跳请求，报告健康状态）

2. eureka的作用

   * EurekaServer：服务端，注册中心
     * 记录服务信息
     * 心跳监控
   * EruekaClient：客户端
     * Provider：服务提供者，将自身信息注册到注册中心，每隔30秒向注册中心发送心跳
     * consumer：服务消费者，根据服务名称从注册中心拉取服务列表，基于服务列表做负载均衡，选中一个微服务后发起远程调用

   ![image-20220618171448837](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181721711.png)

3. 快速入门

   * 搭建注册中心

     ![image-20220618172353099](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181723946.png)

   * 服务注册

     ![image-20220618175957800](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181800933.png)

     模拟多实例部署：

     ![image-20220618215953095](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206182200358.png)

   * 服务发现

     ![image-20220618220255386](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206182202134.png)

### Consul

官网：https://www.consul.io/

SpringConsul：https://spring.io/projects/spring-cloud-consul

1. 简介：由 HashiCorp 公司用 Go 语言开发的一套开源的分布式服务发现和配置管理系统。

2. 作用

   * 服务发现
   * 健康检测
   * KV存储
   * 多数据中心
   * 可视化Web界面

3. 安装部署

   * 下载安装包
   * 启动：使用开发模式启动`consul agent -dev -bind=0.0.0.0 -client=0.0.0.0`

4. 快速使用

   导入依赖

   ~~~xml
           <dependency>
               <groupId>org.springframework.cloud</groupId>
               <artifactId>spring-cloud-starter-consul-discovery</artifactId>
           </dependency>
   ~~~

   开启注册中心

   ~~~java
   @EnableDiscoveryClient
   @SpringBootApplication
   public class CloudOrderApplication {
       public static void main(String[] args) {
           SpringApplication.run(CloudOrderApplication.class, args);
       }
   }
   ~~~

   修改application.yml配置文件

   ~~~xml
   spring:
     application:
       name: cloud-order-service
     cloud:
       consul:
         discovery:
           heartbeat:
             enabled: true
           service-name: ${spring.application.name}
         host: 127.0.0.1
         port: 8500
   ~~~

### 注册中心异同点

| 服务注册中心  | CAP支持 | 一致性协议                         | 健康检查               | 服务发现方式      | 配置管理 | 管理界面 | 开发语言 | 适用场景                       |
| ------------- | ------- | ---------------------------------- | ---------------------- | ----------------- | -------- | -------- | -------- | ------------------------------ |
| **Eureka**    | AP      | 自定义心跳机制                     | 客户端心跳             | 客户端发现        | 不支持   | 简单UI   | Java     | 中小型云服务、Spring Cloud生态 |
| **Consul**    | CP/AP   | Raft                               | TCP/HTTP/脚本+健康检查 | 客户端/服务端发现 | 支持     | 自带UI   | Go       | 多数据中心、复杂健康检查场景   |
| **Zookeeper** | CP      | ZAB协议                            | 临时节点（会话心跳）   | 客户端发现        | 需扩展   | 第三方   | Java     | 分布式协调、强一致性场景       |
| **Nacos**     | AP/CP   | Raft（CP模式）<br>Distro（AP模式） | TCP/HTTP/心跳+主动探测 | 客户端/服务端发现 | 支持     | 自带UI   | Java     | 云原生、动态配置中心           |
| **Etcd**      | CP      | Raft                               | 租约（Lease）心跳      | 客户端发现        | 需扩展   | 第三方   | Go       | Kubernetes、强一致性存储需求   |

关键点说明：

1. **CAP模型**：
   - Eureka（AP）适合高可用场景，容忍短暂不一致。
   - Zookeeper/Etcd（CP）保证强一致性，牺牲可用性。
   - Consul/Nacos 支持灵活切换模式（Consul默认CP，Nacos支持AP/CP）。

2. **健康检查**：
   - Eureka依赖客户端主动上报心跳。
   - Consul/Nacos支持多种协议主动探测。
   - Zookeeper通过临时节点自动清理失效服务。

3. **服务发现**：
   - 客户端发现（Eureka/Zookeeper/Etcd）由消费者直接请求注册中心。
   - 服务端发现（Consul/Nacos）支持通过代理或DNS负载均衡。

4. **配置管理**：
   - Consul/Nacos原生支持配置中心，其他需通过扩展实现。

5. **生态集成**：
   - Eureka深度集成Spring Cloud。
   - Etcd是Kubernetes核心组件。
   - Nacos在云原生场景中功能更全面（服务+配置管理）。

总结：

- **Consul** 适用于需要强健康检查、分布式锁和 KV 存储的场景，且支持多种协议，比较适合容器化和云原生环境。
- **Eureka** 最适合与 Spring Cloud 配合使用，简化微服务架构的服务注册与发现，但不具备强一致性。
- **Zookeeper** 适用于大规模分布式系统，特别是在需要强一致性和分布式协调的场景中，操作和配置较为复杂。
- **Etcd** 是一个轻量级、易于使用的服务注册中心，特别适合云原生应用和配置管理，基于 Raft 协议提供高可用性。

## 服务调用与负载均衡

常见的服务调用与负载均衡组件列表：

* ~~Ribbon~~
* LoadBalancer
* ~~Feign~~
* OpenFeign

### RestTemplate

api文档：https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/client/RestTemplate.html

RestTemplate提供了多种便捷访问远程Http服务的方法，是一种简单便捷的访问restful服务模板类，是Spring提供的用于防问Rest服务的客户端模板工具集。

1. 基于RestTemplate发起远程调用

   * 基于RestTemplate发起的http请求实现远程调用
   * http请求做远程调用是与语言无关的调用，只要知道对方的ip、端口、接口路径、请求参数即可。

   注册RestTemplate，注入容器

   ![image-20220617224745750](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181721514.png)

   服务远程调用RestTemplate

   ![image-20220617225833140](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206181721414.png)

2. 提供者与消费者

   * 服务提供者与消费者是相对的

### OpenFeign

#### RestTemplate的问题

![image-20230506175657177](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061756412.png)

#### OpenFeign

> 说明：此处指的feign都是OpenFeign，由Spring提供，而非Netfix提供的feign

项目地址：https://github.com/OpenFeign/feign

文档：https://spring.io/projects/spring-cloud-openfeign#overview

其他参考：

* [Spring Cloud Open Feign_墨 禹的博客-CSDN博客](https://blog.csdn.net/qq_43437874/category_11612066.html)

1. 简介：一个声明式、模板化的http客户端，实现优雅的http请求发送。

2. 快速使用

   * 引入依赖

     ~~~xml
     <dependency>            
         <groupId>org.springframework.cloud</groupId>
         <artifactId>spring-cloud-starter-openfeign</artifactId>
     </dependency>
     ~~~

   * 启动类中添加注解开启Feign功能

     ![image-20230506180353483](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061803740.png)

   * 编写Feign客户端

     ![image-20230506180828135](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061808526.png)

3. 自定义feign配置（高级特性）

   ![image-20230506213938619](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062139929.png)

   **日志自定义**方式一：配置文件

   ![image-20230506222903876](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062229450.png)

   日志自定义方式二：java代码

   ![image-20230506223002338](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062230717.png)

   **超时时间**控制：

   * 全局配置
   * 指定配置

   ~~~yaml
   spring:
     cloud:
       openfeign:
         client:
           config:
             default:
               connect-timeout: 5000
               read-timeout: 5000
             payment:
               connect-timeout: 3000
               read-timeout: 3000
   ~~~

   **重试机制**

   * 重试机制默认关闭

   **http客户端**

   ![image-20230506223822399](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062238506.png)

   ![image-20230506224047084](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062240233.png)

   **请求/响应压缩**

   ~~~yaml
   spring:
     cloud:
       openfeign:
         compression:
           request:
             enabled: true
             min-request-size: 2048
             mime-types: text/xml,application/xml,application/x-www-form-urlencoded,text/plain,application/json
           response:
             enabled: true
   ~~~

5. 最佳实践

   * 方式一：

     ![image-20230506224848056](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062248178.png)

   * 方式二：

     ![image-20230506225107978](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062251195.png)

     > 实现步骤：
     >
     > * 创建一个module，命名为feign-api，引入feign相关依赖
     > * 将order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中
     > * 在order-service中引入feign-api的依赖
     > * 修改order-service中的所有与上述三个组件有关的import部分，改成导入feign-api中的包
     >
     > ![image-20230506231053347](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062310886.png)

### ~~Ribbon负载均衡~~

1. 负载均衡流程

   ![image-20230505181246896](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305051812821.png)

   ![image-20220619111733756](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191119756.png)

2. 负载均衡策略

   ![image-20220619111906061](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191124670.png)

   ![image-20220619111926430](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191124252.png)

   ![image-20220619112416337](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191124665.png)

   > 注意：第一种方式针对全局，第二种方式只针对指定服务

3. 饥饿加载

   ![image-20220619113011093](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206191130698.png)

### LoadBalancer

文档：https://docs.spring.io/spring-cloud-commons/reference/spring-cloud-commons/loadbalancer.html

1. 简介：

   * SpringCloud官方提供的一个开源的、简单易用的**客户端负载均衡器**。
   * 它包含在SpringCloud-commons中用它来替换了以前的Ribbon组件。
   * 相比较于Ribbon，SpringCloud LoadBalancer不仅能够支持RestTemplate，还支持WebClient（WeClient是Spring Web Flux中提供的功能，可以实现响应式异步请求）。

2. loadbalancer本地负载均衡客户端 VS Nginx服务端负载均衡

   | **对比维度**     | **客户端负载均衡（如LoadBalancer/Ribbon）**         | **服务端负载均衡（如Nginx）**                           |
   | ---------------- | --------------------------------------------------- | ------------------------------------------------------- |
   | **工作层级**     | 应用层（基于服务调用逻辑）                          | 传输层（TCP）或应用层（HTTP）                           |
   | **负载均衡位置** | 集成在服务消费者进程内部                            | 独立部署在服务消费者与服务提供者之间                    |
   | **配置方式**     | 客户端代码或配置文件中定义规则                      | 集中式配置文件（nginx.conf）或动态API                   |
   | **服务发现集成** | 直接对接注册中心（如Eureka、Nacos）动态获取服务列表 | 需通过第三方工具（如Consul-template）或手动维护服务列表 |
   | **性能损耗**     | 无额外网络跳转，延迟低                              | 需经过代理节点，可能增加少量延迟                        |
   | **动态扩展能力** | 自动感知服务实例变化                                | 需要手动更新配置或依赖动态模块（如Nginx Plus）          |
   | **健康检查**     | 依赖注册中心健康检查机制                            | 内置主动健康检查（HTTP/TCP探针）                        |
   | **流量控制**     | 基于客户端的策略（如轮询、权重）                    | 支持复杂策略（加权轮询、IP哈希、最少连接数等）          |
   | **协议支持**     | 主要支持应用层协议（如HTTP/GRPC）                   | 支持多协议（HTTP/HTTPS/TCP/UDP）                        |
   | **单点故障风险** | 无中心节点，天然去中心化                            | 存在代理节点单点故障风险（需集群化解决）                |
   | **配置复杂度**   | 分散在多个客户端，维护成本较高                      | 集中化管理，配置复杂度低                                |
   | **适用场景**     | 微服务内部调用、云原生环境                          | 南北流量管理（入口网关）、多语言混合架构                |

   核心差异说明：

   1. **架构模式**：
      - 客户端LB：去中心化模式，每个消费者独立决策流量分发
      - Nginx：中心化代理模式，所有流量经过统一入口

   2. **性能与扩展性**：
      - 客户端LB避免了带宽瓶颈，但需消耗客户端资源维护服务列表
      - Nginx更容易实现全局流量管控，但存在带宽上限

   3. **服务感知能力**：
      - 客户端LB天然与注册中心集成，实时感知服务变化
      - Nginx需额外工具实现服务列表动态更新（如Nacos+nginx-upsync-module）

   4. **运维复杂度**：
      - 客户端LB随应用发布更新，版本管理需谨慎
      - Nginx配置集中管理，但集群部署需保证配置一致性

   典型组合方案：

   - **客户端LB+服务端LB混合架构**：
     
     ```mermaid
     graph LR
       A[外部用户] --> B(Nginx集群)
       B --> C[服务网关]
       C --> D{微服务A}
       D -->|客户端LB| E[微服务B实例1]
       D -->|客户端LB| F[微服务B实例2]
     ```

3. 快速使用

   在消费者（客户端）引入依赖

   ~~~xml
           <dependency>
               <groupId>org.springframework.cloud</groupId>
               <artifactId>spring-cloud-starter-loadbalancer</artifactId>
           </dependency>
   ~~~

   使用`@LoadBalanced`注解开启服务的负载均衡

   ~~~java
   @Configuration
   public class RestTemplateConfig {
   
       @Bean
       @LoadBalanced
       public RestTemplate getRestTemplate() {
           return new RestTemplate();
       }
   
   }
   ~~~

4. 原理解析

   * 负载均衡算法，默认两种分别为轮询（RoundRobinLoadBalancer）和随机（RandomLoadBalancer）

   * 负载均衡算法执行过程：rest接口第几次请求数 % 服务器集群总数量 = 实际调用服务器位置下标 ，每次服务重启动后rest接口计数从1开始。示例如下：

     > List<ServiceInstance> instances = discoveryClient.getInstances("cloud-payment-service");
     >
     >  
     >
     > 如：  List [0] instances = 127.0.0.1:8002
     >
     > 　　　List [1] instances = 127.0.0.1:8001
     >
     >  
     >
     > 8001+ 8002 组合成为集群，它们共计2台机器，集群总数为2， 按照轮询算法原理：
     >
     >  
     >
     > 当总请求数为1时： 1 % 2 =1 对应下标位置为1 ，则获得服务地址为127.0.0.1:8001
     >
     > 当总请求数位2时： 2 % 2 =0 对应下标位置为0 ，则获得服务地址为127.0.0.1:8002
     >
     > 当总请求数位3时： 3 % 2 =1 对应下标位置为1 ，则获得服务地址为127.0.0.1:8001
     >
     > 当总请求数位4时： 4 % 2 =0 对应下标位置为0 ，则获得服务地址为127.0.0.1:8002
     >
     > 如此类推......

## 配置管理与刷新

微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务。由于每个服务都需要必要的配置信息才能运行，所以一套集中式的、动态的配置管理设施是必不可少的。比如某些配置文件中的内容大部分都是相同的，只有个别的配置项不同。

常见的配置中心组件列表：

* ~~Config+Bus~~
* Consul
* Nacos

### Nacos

GitHub主页：https://github.com/alibaba/nacos

GitHub的Release：https://github.com/alibaba/nacos/releases

网站：https://nacos.io/zh-cn/index.html

1. 安装nacos

   * 下载：在Nacos的GitHub页面，提供有下载链接，可以下载编译好的Nacos服务端或者源代码。
   * 配置：Nacos的默认端口是8848，若电脑上的其它进程占用了8848端口，请先尝试关闭该进程。**如果无法关闭占用8848端口的进程**，也可以进入nacos的conf目录中的配置文件application.properties修改的端口。
   * 启动
     * 双击bin目录中的startup.cmd
     * 执行命令startup.cmd -m standalone
   * 访问：在浏览器输入地址：http://127.0.0.1:8848/nacos即可，登录默认的账号和密码都是nacos进入。
   
2. 使用第三方数据库存储nacos数据（mysql为例）

   Nacos在存储数据时既可以使用内置数据库存储，也可以通过第三方指定的数据库存储。可以通过修改配置文件指定使用MySQL数据库来存储Nacos的相关数据，

   ~~~
   spring.datasource.platform=mysql
   db.num=1
   db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true
   db.user=root
   db.password=4112
   ~~~

   > 配置文件位置：NACOS_HOME/conf/application.properties

   修改完配置文件后，在配置的对应数据库中创建数据库。

   ~~~sql
   CREATE DATABASE `nacos` CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;
   ~~~

   数据库创建完成后，执行NACOS_HOME/conf/nacos-mysql.sql数据库脚本文件。

#### 服务注册发现

2. nacos的依赖（客户端）

   父工程：

   ```xml
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-alibaba-dependencies</artifactId>
       <version>2.2.5.RELEASE</version>
       <type>pom</type>
       <scope>import</scope>
   </dependency>
   ```

   客户端：

   ```xml
   <!-- nacos客户端依赖包 -->
   <dependency>
       <groupId>com.alibaba.cloud</groupId>
       <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
   </dependency>
   ```

3. 客户端注册

   ![image-20220621222022415](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206232155659.png)

   ![image-20220621222249577](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206232155264.png)

4. nacos服务分级存储模型

   * 分级存储模型
     * 一级是服务
     * 二级是集群
     * 三级是实例

   ![image-20220623215211993](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206232155127.png)

   * 服务跨集群调用的问题

     * 服务调用尽可能选择本地集群服务，跨集群调用延迟较高。只有本地集群不可访问时，再去访问其他集群。

   * 配置服务集群属性

     ![image-20220623215446583](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202206232155960.png)

   * 根据集群负载均衡

     ~~~yaml
     userservice:
       ribbon:
         NFLoadBalancerRuleCalssName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则
     ~~~

     > NacosRule负载均衡策略
     >
     > * 优先选择同集群服务实例列表
     > * 本地集群找不到提供者，才去其它集群寻找，并且会
     >   报警告
     > * 确定了可用实例列表后，再采用随机负载均衡挑选实

   * 根据权重负载均衡

     * 实际部署场景：
       * 服务器设备性能存在差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求
     * 通过nacos控制台配置权重：0~1之间同集群内的多个实例，权重越高被访问的频率越高，权重设置为0则完全不会被访问

5. 临时实例和非临时实例

   ![image-20230505211240620](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305052112776.png)

6. 环境隔离-namespace：Nacos中服务存储和数据存储的最外层都是一个名为namespace的东西，用来做最外层隔离

   * 在Nacos控制台创建namespace，用来隔离不同环境

   * 在服务的配置文件中配置命名空间

     ![image-20230505205906511](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305052059197.png)

   > namespace用来做环境隔离，每个namespace都有唯一id，**不同namespace下的服务不可见**

7. Nacos和Eureka对比

   * 共同点
     * 都支持服务注册和服务拉取
     * 都支持服务提供者心跳方式做健康检测
   * 不同点
     * Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式
     * 临时实例心跳不正常会被剔除，非临时实例则不会被剔除
     * Nacos支持服务列表变更的消息推送模式，服务列表更新更及时
     * Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式

#### 配置管理

##### 统一配置管理

> * 在Nacos中添加配置文件
> * 在微服务中引入nacos的config依赖
> * 在微服务中添加bootstrap.yml，配置nacos地址、当前环境、服务名称、文件后缀名。这些决定了程序
>   启动时去nacos读取哪个文件

1. 在nacos中创建配置文件

   ![image-20230505222635283](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305052226057.png)

2. 配置获取

   ![image-20230505225825641](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305052258264.png)

   ~~~yaml
   spring:
     application:
       name: userservice # 服务名称
     profiles:
       active: dev # 开发环境
     cloud:
       nacos:
         config:
           file-extension: yaml # 文件后缀名
         server-addr: localhost:8848 # Nacos地址
   ~~~

##### 配置热更新

1. 方式一：

   ![image-20230506171558427](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061716283.png)

2. 方式二：

   ![image-20230506172743217](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061727103.png)

##### 配置共享

1. 创建多配置文件

   ![image-20230506173120433](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305061745737.png)

2. 多配置文件优先级：[服务名]-[环境].yaml>[服务名].yaml>本地配置

##### 搭建Nacos集群

1. 步骤
   * 搭建MySQL集群并初始化数据库表
   * 下载解压nacos
   * 修改集群配置(节点信息)数据库配置
   * 分别启动多个nacos节点
   * nginx反向代理

### Consul

文档：https://docs.spring.io/spring-cloud-consul/reference/4.1/config.html

1. 快速使用

   依赖引入

   ~~~xml
           <dependency>
               <groupId>org.springframework.cloud</groupId>
               <artifactId>spring-cloud-starter-consul-config</artifactId>
           </dependency>
           <dependency>
               <groupId>org.springframework.cloud</groupId>
               <artifactId>spring-cloud-starter-bootstrap</artifactId>
           </dependency>
   ~~~

   配置bootstrap.yml文件

   > applicaiton.yml是用户级的资源配置项
   >
   > bootstrap.yml是系统级的，优先级更加高
   >
   > Spring Cloud会创建一个“Bootstrap Context”，作为Spring应用的`Application Context`的父上下文。初始化的时候，`Bootstrap Context`负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的`Environment`。
   >
   > `Bootstrap`属性有高优先级，默认情况下，它们不会被本地配置覆盖。 `Bootstrap context`和`Application Context`有着不同的约定，所以新增了一个`bootstrap.yml`文件，保证`Bootstrap Context`和`Application Context`配置的分离。
   >
   >  application.yml文件改为bootstrap.yml,这是很关键的或者两者共存

2. 配置动态刷新

   * 配置key/value文件
   * 使用注解`@RefreshScope` 开启配置自动更新功能

   > 注意配置刷新生效时间
   >
   > ```yaml
   > spring:
   >   cloud:
   >     consul:
   >       config:
   >         watch:
   >           wait-time: 1
   > ```

3. 配置持久化

## 服务网关

常见的服务网关组件列表：

* ~~Zuul~~
* Gateway

### 统一网关Gateway

#### 简介

1. 简介：在Spring生态系统之上构建的API网关服务，旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式，并为它们提供跨领域的关注点，例如：安全性、监控/度量和恢复能力。
2. 功能
   * 身份认证和权限校验
   * 服务路由和负载均衡
   * 请求限流
3. SpringCloud的网关实现
   * gateway：基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。
     * 核心是一系列的过滤器，通过这些过滤器可以将客户端发送的请求转发(路由)到对应的微服务。
     * 是整个微服务最前沿的防火墙和代理器。
   * zuul：基于Servlet的实现，属于阻塞式编程。（已弃用）
4. Gateway三大核心概念
   * Route
   * Predicate
   * Filter
5. Gateway工作流程

#### 搭建网关服务

1. 步骤：

   * 创建新的module，引入SpringCloudGateway的依赖和nacos的服务发现依赖

     ![image-20230506231549166](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305062315923.png)

   * 编写路由配置及nacos地址

     > 网关路由可以配置的内容包括
     >
     > * 路由id:路由唯一标示
     > * uri: 路由目的地，支持lb和http两种
     > * predicates: 路由断言，判断请求是否符合要求，符合则转发到路由目的地址
     > * filters:路由过滤器，处理请求或响应

     ~~~xml
     server:
       port: 10086
     spring:
       application:
         name: gateway
       cloud:
         nacos:
           server-addr: localhost:8848
         gateway:
           routes: # 网关路由配置
             - id: user-service # 路由id，自定义，只要唯一即可
               uri: lb://userservice # 路由的目标地址，lb就是负载均衡，后面跟服务名称，还可以使用http://127.0.0.1:8081的方式配置
               predicates: # 路由断言，即判断路由是否符合规则
                 - Path=/user/** # 按照路由路径匹配，只要以/user/开头就匹配
             - id: order-service
               uri: lb://orderservice
               predicates:
                 - Path=/order/**
     ~~~

2. 网关流程

   ![image-20230507115109352](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305071151354.png)

3. 路由断言工厂

   > 在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件
   > 例如Path=/user/**是按照路径匹配，这个规则是由orq.springframework.cloud.qateway.handler.predicatePathRoutePredicateFactory类来处理的

   ![image-20230507115523705](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305071155592.png)
   
4. 路由过滤器（GatewayFilter）：网关中提供的一种过滤器，可以对进入网关的**请求**和微服务返回的**响应**做处理。

   ![image-20230508225305428](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082253251.png)

   * 局部过滤器：配置在路由下

   ~~~xml
         routes:
           - id: user-service # 路由标示，必须唯一
             uri: lb://userservice # 路由的目标地址
             predicates: # 路由断言，判断请求是否符合规则
               - Path=/user/** # 路径断言，判断路径是否是以/user开头，如果是则符合
             filter:
               - AddRequestHeader=Trueth,Come on whyme-chen!
   ~~~

   * 默认过滤器

   ![image-20230508225828849](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082258640.png)

5. 全局过滤器（GlobalFilter）

   全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的。而GlobalFilter的逻辑需要自己写代码实现。

   ![image-20230508230421859](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082304761.png)

6. 过滤器执行顺序

   ![image-20230508231853814](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082318558.png)

   > * 每一个过滤器都必须指定一个int类型的order值，order值越小，优先级越高，执行顺序越靠前.
   > * GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。
   > * 当过滤器的order值一样时，会按照 defaultFilter > 路由过滤器>GlobalFilter的顺序执行。

7. 跨域问题处理

   ![image-20230508232228486](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082322188.png)

   ![image-20230508232245310](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305082322067.png)

## 分布式事务

常见的分布式事务组件列表：

* seata
* LCN
* Hmily

1. 分布式事务
   * 对于分布式系统而言，需要保证分布式系统中的数据一致性，保证数据在子系统中始终保持一致，避免业务出现问题。分布式系统中对数据的操作要么一起成功，要么一起失败，必须是一个整体性的事务。
2. 问题产生原因
   * 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题。
   * 单体应用被拆分为多个独立微服务应用，分别使用独立数据库，业务操作需要调用多个服务完成，每个服务内部的数据一致性由本地事务来保证，但全局数据一致性问题无法保证。
3. 分布式事务解决方案
4. 典型场景
   * 电商系统：如何保证下订单、冻库存、做支付、减库存、抵扣积分、送积分、做推送、派物流一系列操作的事务一致性。

### Seata

官方文档：https://seata.apache.org/

1. 简介：Seata（Simple Extensible Autonomous Transaction Architecture，简单可扩展自治事务框架）是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。

   * 纵观整个分布式事务的管理，就是**全局事务ID的传递和变更**，要让开发者无感知。
   * 事务协调与控制
     * **XID是全局事务的唯一标识**，它可以在服务的调用链路中传递，绑定到服务的事务上下文中。
     * TC（Transaction Coordinator，事务协调器）
     * TM（Transaction Manager，事务管理器）
     * RM（Resource Manager，资源管理器 ）

   ![img](https://seata.apache.org/zh-cn/img/index/TB1rDpkJAvoK1RjSZPfXXXPKFXa-794-478.png)

2. 快速使用

3. `@Transactional`&`@GlobalTransactional`

4. 工作流程

   * TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID；
   * XID 在微服务调用链路的上下文中传播；
   * RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖；
   * TM 向 TC 发起针对 XID 的全局提交或回滚决议；
   * TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。

5. 事务失效场景

### LCN

### Hmily

## 服务熔断与降级

常见的服务熔断与降级组件列表：

* ~~Hystria~~
* Circuit Breaker
  * [Resilience4J](https://github.com/resilience4j/resilience4j)
  * [Spring Retry](https://github.com/spring-projects/spring-retry)
* Sentinel

1. 问题：在分布式系统或微服务架构中，服务之间的依赖关系非常复杂。若某个服务发生故障（例如，响应超时或返回错误），可能会导致整个系统的连锁反应，最终影响到整个应用的稳定性。

2. 基本概念

   * 服务雪崩
   * 服务熔断
   * 服务降级：降级是针对服务消费者的应对策略，在服务出现异常或限流时，通过对服务调用进行降级处理，确保消费者端能够在异常情况下正常工作。
   * 服务限流：限流是一种针对服务提供者的策略，用于控制对特定服务接口或服务实例的访问量。
   * 服务隔离
   * 服务超时

   > 限流关注于保护服务提供者，控制请求流量；而降级则关注于服务消费者，确保在服务不可用或异常情况下提供基本的功能。

3. 地方

### ~~Hystria~~

> 不再维护。

项目地址：https://github.com/Netflix/Hystrix

1. 简介：Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。

### Circuit Breaker

文档地址：https://docs.spring.io/spring-cloud-circuitbreaker/reference/

1. 简介：一套接口规范，具体实现有**Resilience4J**

2. 作用：保护分布式系统免受故障和异常，提高系统的可用性和健壮性。

3. 实现原理：

   “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应(FallBack)，而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。

   熔断器模式的核心思想是，当某个服务的调用失败次数达到预设阈值时，熔断器会暂时停止向该服务发送请求，直接返回一个默认的错误响应或快速失败，以避免系统过载。当系统恢复健康后，熔断器会重新允许请求通过。当一个组件或服务出现故障时，CircuitBreaker会迅速切换到开放OPEN状态(保险丝跳闸断电)，阻止请求发送到该组件或服务从而避免更多的请求发送到该组件或服务。这可以减少对该组件或服务的负载，防止该组件或服务进一步崩溃，并使整个系统能够继续正常运行。

4. 断路器三大状态及转换

   * 普通状态：
     * 关闭（CLOSED）：所有请求都会正常发送到被保护的服务。如果请求成功，熔断器保持在关闭状态。如果请求失败且达到设定的失败阈值（例如，连续失败次数），熔断器会进入 **Open** 状态。
     * 开启（OPEN）：在打开状态下，熔断器会立即返回一个错误响应（如超时、500错误等），而不是继续发送请求给失败的服务。熔断器保持在打开状态，直到一定的时间窗口过去，系统自动进入 **Half-Open** 状态。
     * 半开（HALF_OPEN）：在半开状态下，熔断器会尝试允许少量的请求通过，以检测被保护的服务是否已经恢复健康。如果这些请求成功，熔断器会重新切换到 **Closed** 状态，表示服务恢复正常。如果这些请求依然失败，熔断器会回到 **Open** 状态，继续保护系统。
   * 特殊状态：禁用（DISABLED）、强制开启（FORCED_OPEN）

#### Resilience4J

项目地址：https://github.com/resilience4j/resilience4j

文档：https://resilience4j.readme.io/

1. 主要功能

   * **熔断（Circuit Breaker）**：与Hystrix类似，可以设置不同的阈值和状态。
   * **限流（Rate Limiter）**：限制服务调用的频率，避免服务过载。
   * **重试（Retry）**：在请求失败时，可以重新尝试请求。
   * **隔离（Thread Pool）**：通过线程池实现请求隔离，防止某个服务过载影响整个系统。

2. 熔断（Circuit Breaker）

   在调用方使用注解`@CircuitBreaker`，示例：

   ~~~java
       @GetMapping("/getById/{id}")
       @CircuitBreaker(name = "cloud-payment-service", fallbackMethod = "getOrderByIdFallback")
       public ApiResult<String> getOrderById(@PathVariable(value = "id") Integer id) {
   //        Object result = restTemplate.getForObject(paymentServiceUrl + "/getById/" + id, Object.class, id);
           ApiResult<PayDTO> result = paymentFeignApi.getPayById(id);
           assert result != null;
           return ApiResult.success(JSONUtil.toJsonStr(result.getData()));
       }
   
       public ApiResult<String> getOrderByIdFallback(Integer id, Throwable e) {
           log.error("getOrderByIdFallback: {}", e.getMessage());
           return ApiResult.error(ReturnCodeEnum.SYSTEM_BUSINESS_ERROR);
       }
   ~~~

3. 隔离（BulkHead）

   * 概念来自造船行业，床仓内部一般会分成很多小隔舱，一旦一个隔舱漏水因为隔板的存在而不至于影响其它隔舱和整体船。
   * 主要目的是限并发。
   * 两种实现方式
     * SemaphoreBulkHead使用信号量
     * FixedThreadPoolBulkHead使用了有界队列和固定大小线程池

4. 限流

   * 目的：频率控制
   * 常见限流算法
     * 漏斗算法（Leaky Bucket）
     * 令牌桶算法（Token Bucket）
     * 滚动时间窗（Tumbling Time Window）
       * 缺点：由于计数器算法存在时间临界点缺陷，因此在时间临界点左右的极短时间段内容易遭到攻击
     * 滑动时间窗（Sliding Time Window）

### Sentinel

文档：http://sentinelguard.io/zh-cn/

Github：https://github.com/alibaba/Sentinel?spm=7145af80.3dce6fe0.0.0.18134bc9pM4J1S

1. 简介

2. 工作流程

   ![opensergo-and-sentinel](https://sentinelguard.io/docs/zh-cn/img/opensergo/opensergo-sentinel-fault-tolerance-zh-cn.jpg)

#### 流控规则

1. 基本使用

   对流量进行控制，主要是监控应用的QPS流量或者并发线程数等指标，如果达到指定的阈值时，就会被流量进行控制，以避免服务被瞬时的高并发流量击垮，保证服务的高可靠性。参数说明：

   | 参数名   | 说明                                                         |
   | -------- | ------------------------------------------------------------ |
   | 资源名   | 资源的唯一名称，默认就是请求的接口路径，可以自行修改，但是要保证唯一。 |
   | 针对来源 | 具体针对某个微服务进行限流，默认值为default，表示不区分来源，全部限流。 |
   | 阈值类型 | QPS表示通过QPS进行限流，并发线程数表示通过并发线程数限流。   |
   | 单机阈值 | 与阈值类型组合使用。如果阈值类型选择的是QPS，表示当调用接口的QPS达到阈值时，进行限流操作。如果阈值类型选择的是并发线程数，则表示当调用接口的并发线程数达到阈值时，进行限流操作。 |
   | 是否集群 | 选中则表示集群环境，不选中则表示非集群环境。                 |

2. 流控模式

   * 直接
   * 关联
   * 链路

3. 流控效果

   * 直接（默认）
   * 预热WarmUp
   * 排队等待

#### 熔断规则

1. 基本流程

   *  熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，

     让请求快速失败，避免影响到其它的资源而导致级联错误。当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException）

2. 参数说明

   * 慢调用比例
   * 异常比例
   * 异常数

#### 热点规则

#### 授权规则

#### 规则持久化

## 服务链路追踪

常见的服务链路追踪组件列表：

* ~~Sleuth~~+Zipkin
* Micrometer Tracing
* Skywalking

> Sleuth已进入维护模式，推荐替代方案Micrometer Tracing

1. 必要性：微服务框架中，一个由客户端发起的请求在后端系统中会经过多个不同的的服务节点调用来协同产生最后的请求结果，每一个前段请求都会形成一条复杂的分布式服务调用链路，链路中的任何一环出现高延时或错误都会引起整个请求最后的失败。在大规模分布式与微服务集群下

   * 如何实时观测系统的整体调用链路情况。
   * 如何快速发现并定位到问题。
   * 如何尽可能精确的判断故障对系统的影响范围与影响程度。
   * 如何尽可能精确的梳理出服务之间的依赖关系，并判断出服务之间的依赖关系是否合理。
   * 如何尽可能精确的分析整个系统调用链路的性能与瓶颈点。
   * 如何尽可能精确的分析系统的存储瓶颈与容量规划。

2. 作用（能力）：将一次分布式请求还原成调用链路，进行日志记录和性能监控并将一次分布式请求的调用情况集中web展示。

3. 其他分布式链路追踪解决方案

   | **方案名称**      | **主要特点**                                                 | **适用场景**                                           |
   | ----------------- | ------------------------------------------------------------ | ------------------------------------------------------ |
   | **Jaeger**        | - 开源项目，支持分布式追踪<br>- 支持多种后端存储，如Cassandra、Elasticsearch等<br>- 提供可视化界面 | 微服务架构、大规模分布式系统                           |
   | **Zipkin**        | - 开源分布式追踪系统<br>- 轻量级，易于集成<br>- 支持多种数据存储方案，常见使用HBase、MySQL、Elasticsearch等 | 微服务应用，系统性能监控与故障排查                     |
   | **OpenTelemetry** | - 提供标准化的分布式追踪、度量和日志<br>- 支持多种编程语言和框架<br>- 聚焦于可扩展性和灵活性，可以与其他工具（如Jaeger、Zipkin）集成 | 统一日志、度量、追踪的监控方案，跨语言和跨框架集成追踪 |
   | **Datadog APM**   | - 提供分布式追踪与应用性能管理（APM）服务<br>- 自动化追踪代码，支持多种框架和云平台<br>- 提供强大的分析和告警功能 | 企业级应用、微服务架构，云原生应用性能监控             |
   | **Elastic APM**   | - Elastic Stack的一部分，支持分布式链路追踪<br>- 支持与Elasticsearch、Kibana的深度集成<br>- 提供丰富的性能分析和仪表板功能 | 需要Elastic Stack集成的分布式系统与微服务架构          |
   | **New Relic**     | - 提供应用性能管理和分布式追踪<br>- 具有强大的性能监控和智能告警功能<br>- 支持详细的分布式追踪可视化和分析 | 企业级应用监控，微服务、容器化应用，云基础架构         |
   | **AWS X-Ray**     | - 亚马逊AWS提供的分布式追踪服务<br>- 集成AWS生态系统，支持多种AWS服务的自动追踪<br>- 提供详细的追踪和错误分析功能 | 使用AWS的应用与服务，尤其是云原生应用和微服务          |
   | **SkyWalking**    | - 支持分布式追踪、日志和度量的统一监控平台<br>- 多种存储后端支持，性能优秀<br>- 支持容器化、Kubernetes环境下的分布式追踪 | 大规模微服务架构、容器化和Kubernetes环境的分布式监控   |

4. 核心原理：通过为每个请求生成一个唯一的追踪标识符（Trace ID）和一系列关联的“跨度”（Span），来追踪请求在各个服务之间的流转。

   * **Trace（追踪）**: 一个**Trace**表示一次完整的请求流程，从请求进入系统到完成返回的全过程。一个Trace通常由多个**Span**构成。
   * **Span（跨度）**: 每个Span代表一次操作或处理，它包含了以下信息：
     - **Span ID**: 唯一标识当前跨度的ID。
     - **Trace ID**: 唯一标识整个请求链路的ID，所有属于同一个Trace的Span都会使用相同的Trace ID。
     - **Parent Span ID**: 当前Span的父Span ID，表明它在请求链路中的位置。根Span没有父Span。
     - **时间戳**: 记录Span的开始时间和结束时间。
     - **操作名称**: 代表Span所执行的操作（如“数据库查询”、“HTTP请求”等）。
     - **标签和日志**: Span中可以包含其他相关信息（如错误信息、HTTP状态码等）。

5. 基本流程

   - **请求到达**: 当用户发起请求时，系统会为这个请求生成一个唯一的**Trace ID**。这个Trace ID会在整个请求的生命周期中被携带和传递。
   - **传播Trace ID**: 每经过一个服务时，服务会为当前操作（如数据库查询、远程服务调用等）创建一个新的**Span**，并将原始Trace ID传递给下一个服务。这保证了所有相关的服务操作都能被关联在同一个Trace中。
     - 在分布式系统中，各个服务通常是通过HTTP、gRPC等协议进行通信的。每次一个服务调用另一个服务时，Trace ID会随着请求一起传递，通常是通过HTTP头（如`X-Request-ID`或`X-B3-TraceId`）进行携带。
     - 如果请求在多个服务之间传递，则Trace ID保证这些服务的Span能关联到同一个Trace上。这种信息的传递通过自动化的代码库（如OpenTelemetry、Jaeger等）来实现，开发者无需手动添加。
   - **记录Span**: 每个服务会在处理请求的过程中记录每个操作的Span信息，包括操作的开始和结束时间、操作的类型（如数据库查询、外部API请求等）以及处理结果等。
   - **链路汇聚**: 当请求在多个服务之间传递时，每个服务都会生成自己的Span，并记录到分布式追踪系统中。这些信息会被集中汇聚在一个后端存储系统中，如Jaeger、Zipkin等。
   - **展示与分析**: 分布式追踪系统提供可视化界面，让开发者可以查看每个Trace的执行路径、时延、各个Span的耗时等信息，帮助开发者分析性能瓶颈、服务间的依赖关系和潜在问题。

6. 关键组成部分

   * **采样策略（Sampling）**: 在高流量的分布式系统中，追踪所有请求可能会产生大量的数据。因此，链路追踪系统通常采用采样策略，即只跟踪部分请求。常见的采样策略有全量采样（追踪所有请求）和概率采样（根据一定的概率选择要追踪的请求）。
   * **后端存储与聚合**: 各个服务生成的Span会被收集到一个后端存储系统中（如Jaeger、Zipkin、Elasticsearch等），并聚合成完整的Trace。系统通常会提供查询、搜索、可视化的界面，帮助开发者快速定位问题。
   * **时效性与告警**: 基于追踪数据，系统可以为开发者提供关于系统性能、延迟、错误等的实时监控和告警，进一步帮助定位和处理问题。

7. 应用

   * **故障排查**: 通过查看Trace的可视化图表，开发者可以看到每个服务的执行时长、错误和瓶颈，帮助快速诊断和排查问题。
   * **性能优化**: 追踪系统可以揭示请求的延迟和各服务间的性能瓶颈，开发者可以据此进行优化。
   * **依赖关系分析**: 通过追踪请求在不同服务间的流动，可以帮助开发者理解系统中各个服务之间的依赖关系。
   * **可观察性**: 提高系统的可观察性，帮助开发者深入了解系统的内部运作，并提供数据支持进行决策。

### Micrometer

官方文档：https://micrometer.io/docs/tracing

# 中间件

1. 定义：**中间件** 是一种在操作系统和应用程序之间提供服务的软件层，它作为不同软件之间的中介，处理不同应用程序之间的通信、数据交换、请求转发等任务。
2. 作用：简化开发、提升系统的可扩展性和可靠性。
   * **解耦**：帮助不同的系统组件之间解耦，使它们可以通过中间件进行通信，而不需要直接相互依赖。
   * **性能优化**：提供缓存、负载均衡、异步处理等机制，提升系统的性能。
   * **事务管理**：确保数据操作的一致性和事务处理。
   * **扩展性和可维护性**：使得系统能够更容易地扩展和维护。
3. 常见的中间件：中间件种类多样，根据其用途不同，具有不同的功能。
   * 消息队列：用于系统之间异步传输数据，解耦系统各个部分，提高系统的吞吐量与容错性。
     * **RabbitMQ**：基于 AMQP 协议的消息队列系统，广泛用于异步消息传递、任务调度等场景。
     * **Kafka**：一个分布式的流处理平台，用于高吞吐量、低延迟的消息传递，广泛应用于大数据和实时数据处理。
     * **ActiveMQ**：Apache 提供的开源消息中间件，支持多种消息协议。
     * **RocketMQ**
   * 缓存：缓存中间件用于存储和快速访问经常使用的数据，以提高系统性能。
     * **Redis**：一个高性能的键值存储数据库，广泛用于缓存、消息队列、实时分析等场景。
     * **Memcached**：一个分布式内存缓存系统，用于加速动态Web应用。
     * **Ehcache**：基于 Java 的缓存框架，广泛用于应用级缓存。
   * 数据库：用于数据库的连接管理、负载均衡、事务管理等，帮助简化数据库操作。
     - **Mycat**：一款开源的数据库中间件，支持数据分片、读写分离等功能。
     - **ShardingSphere**：Apache 基金会的一个分布式数据库中间件，可以实现数据库的水平分片、读写分离等。
     - **TDDL**：阿里巴巴的数据库中间件，支持数据库的透明化分片和高可用。
   * 负载均衡：用于在多台服务器之间分配负载，以确保高可用性和性能。
     * **Nginx**：不仅是一个反向代理服务器，还能作为负载均衡器，广泛用于处理 HTTP 和 TCP 请求。
     * **HAProxy**：一个高性能的 TCP/HTTP 负载均衡器，广泛应用于高可用性系统中。
     * **LVS (Linux Virtual Server)**：Linux 下的一款负载均衡解决方案，适用于大规模集群。
   * API 网关：用于处理外部请求，聚合多个后端服务的功能，提供统一的入口。
     * **Zuul**：由 Netflix 提供的一个 API 网关，支持动态路由、监控和服务限流等功能。
     * **APISIX**：一个高性能、可扩展的开源 API 网关，它提供了对 RESTful API 的管理、路由、负载均衡、安全认证、流量控制、日志记录、监控等功能。
   * 安全
     * **OAuth2**：开放授权协议，常用于第三方授权登录，广泛用于 Web 和移动应用中。
     * **JWT (JSON Web Token)**：一种开放标准，用于身份验证和信息交换，通常与 OAuth2 一起使用。
     * **Shiro**：Apache 提供的一个安全框架，用于 Java 应用的身份验证和授权。
   * 日志：用于集中管理、存储、分析和查看日志。
     * **ELK Stack (Elasticsearch, Logstash, Kibana)**：一个集成的日志管理解决方案，用于数据搜索、日志收集和可视化展示。

# 消息中间件

## MQ理论基础

1. MQ：全称Message Queue (消息队列)，是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信，实现不同系统之间的异步通信。

   * 消息（Message）：消息是在不同进程之间传递的数据。这些进程可以部署在同一台机器上，也可以分布在不同机器上。
   * 队列（Queue）：队列原意是指一种具有FIFO(先进先出)特性的数据结构，是用来缓存数据的。
   *  广义上来说，只要能够实现消息跨进程传输以及队列数据缓存，就可以称之为消息队列。例如我们常用的QQ、微信、阿里旺旺等就都具备了这样的功能。只不过他们对接的使用对象是人，而我们这里讨论的MQ产品需要对接的使用对象是应用程序。

2. 优势&应用场景

   * 应用解耦

   * 削峰填谷：应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了消息队列可以将大量请求缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。

   * 异步提速

     ![image-20230313225333941](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132253511.png)

3. 劣势

   * 系统可用性降低：系统引入的外部依赖越多，系统稳定性越差。一旦MQ宕机，就会对业务造成影响。
   * 系统复杂性提高
   * 一致性问题

4. MQ应用条件

   * 生产者不需要从消费者处获得反馈
   * 容许短暂的不一致性

5. 模型演化

   * 点对点模式（Point to Point , P2P）：消息的发送者将消息发送到一个队列中，消息的接收者从队列中获取消息。每个消息只能被一个接收者消费，消费后即被移除队列。P2P模式的特点是可靠性高，消息不会丢失，但是只能有一个接收者处理消息，不能实现消息广播。
   * 发布订阅模式（Publish-Subscribe, Pub-Sub）：消息的发送者将消息发布到一个主题（topic）中，消息的接收者通过订阅主题来接收消息。每个订阅者都会接收到相同的消息副本。Pub-Sub模式可以实现消息广播，但是消息的可靠性较低，可能会有消息丢失。

   ![image-20240601140408805](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202406011404626.png)

   ![image-20240601140443369](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202406011404872.png)

### 常见的MQ产品

* RabbitMQ
* RocketMQ
* ActiveMQ
* Kafka
* ZeroMQ
* MetaMq

![image-20230313230133285](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132301585.png)

### 常见协议

#### AMQP

官网：[AMQP](https://www.amqp.org/)

AMQP，即Advanced Message Queuing Protocol (高级消息队列协议) ,是一个网络协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。2006年， AMQP规范发布。类比HTTP。

## RabbitMQ

### RabbitMQ简介

![image-20230313232906539](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132329639.png)

![image-20230313232947012](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132329894.png)

![image-20230313233040344](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132330009.png)

![image-20230313233121119](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303132331854.png)

### 快速使用

官网：https://www.rabbitmq.com/

1. 下载安装和管控台的使用

   > 使用docker安装rabbitmq：https://blog.csdn.net/weixin_44666439/article/details/127265712?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-127265712-blog-124470698.235^v27^pc_relevant_3mothn_strategy_recovery&spm=1001.2101.3001.4242.1&utm_relevant_index=3

2. 使用**简单模式**完成消息传递

   * 创建工程（生产者、消费者）
   * 分别添加依赖
   
   ~~~xml
    <dependency>
         <groupId>com.rabbitmq</groupId>
         <artifactId>amqp-client</artifactId>
         <version>5.16.0</version>
       </dependency>
   ~~~
   
   * 编写生产者发送消息、编写消费者接收消息
   
   ~~~java
   package org.example.producer;
   
   import com.rabbitmq.client.AMQP;
   import com.rabbitmq.client.Channel;
   import com.rabbitmq.client.Connection;
   import com.rabbitmq.client.ConnectionFactory;
   
   import java.io.IOException;
   import java.nio.charset.StandardCharsets;
   import java.util.concurrent.TimeoutException;
   
   /**
    * 简单模式
    * @Author chen
    * @Date 2023/3/25
    * @Version 1.0
    **/
   public class Producer_HelloWorld {
       public static void main(String[] args) throws IOException, TimeoutException {
           //创建连接工厂
           ConnectionFactory connectionFactory = new ConnectionFactory();
           //设置参数
           connectionFactory.setHost("47.120.2.57");
           connectionFactory.setPort(5672);
           connectionFactory.setVirtualHost("demo");
           connectionFactory.setUsername("admin");
           connectionFactory.setPassword("admin");
           //创建连接
           Connection connection = connectionFactory.newConnection();
           //创建Channel
           Channel channel = connection.createChannel();
           //创建队列Quene
           /*
            * queueDeclare方法参数说明
            * String queue,队列名称
         * boolean durable,是否持久化
            * boolean exclusive,是否独占，只能有一个消费者监听该队列。当Connection关闭时，是否删除队列
            * boolean autoDelete,是否自动删除，当该队列没有消费者时，自动删除
            * Map<String, Object> arguments,参数
            */
           AMQP.Queue.DeclareOk declareOk = channel.queueDeclare("hello",true,false,false,null);
           //发送消息
           String body = "hello rabbitmq!";
           /*
            *basicPublish方法参数说明
            * String exchange,交换机名称，简单模式下交换机默认使用“
            * String routingKey,路由名称
            * BasicProperties props,配置信息
            * byte[] body,发送消息数据
            */
           channel.basicPublish("","hello",null,body.getBytes(StandardCharsets.UTF_8));
   
           channel.close();
           connection.close();
       }
   }
   ~~~
   
   ~~~java
   package org.example.consumer;
   
   import com.rabbitmq.client.*;
   
   import java.io.IOException;
   import java.nio.charset.StandardCharsets;
   import java.util.concurrent.TimeoutException;
   
   /**
    * 消费者
    * @Author chen
    * @Date 2023/3/25
    * @Version 1.0
    **/
   public class ConsumerDemo1 {
       public static void main(String[] args) throws IOException, TimeoutException {
           //创建连接工厂
           ConnectionFactory connectionFactory = new ConnectionFactory();
           //设置参数
           connectionFactory.setHost("47.120.2.57");
           connectionFactory.setPort(5672);
           connectionFactory.setVirtualHost("demo");
           connectionFactory.setUsername("admin");
           connectionFactory.setPassword("admin");
           //创建连接
           Connection connection = connectionFactory.newConnection();
           //创建Channel
           Channel channel = connection.createChannel();
           //创建队列Quene
           AMQP.Queue.DeclareOk declareOk = channel.queueDeclare("hello",true,false,false,null);
           //消费消息
           Consumer consumer = new DefaultConsumer(channel){
               /**
                * 这是一个回调方法，当收到消息后会自动执行该方法
                * @param consumerTag 标识
                * @param envelope 获取信息，包括：交换机、路由key
                * @param properties 配置信息
                * @param body 数据
                * @throws IOException
                */
               @Override
               public void handleDelivery(String consumerTag,
                                          Envelope envelope,
                                          AMQP.BasicProperties properties,
                                          byte[] body) throws IOException {
                   System.out.println("consumerTag:"+consumerTag);
                   System.out.println("envelope:"+envelope.getExchange());
                   System.out.println("envelope:"+envelope.getRoutingKey());
                   System.out.println("properties:"+properties);
                   System.out.println("body:"+new String(body));
               }
           };
           channel.basicConsume("hello",true,consumer);
   
       }
   }
   
   ~~~
   
3. 工作队列模式（Work Queues）

   * 特点：与简单模式相比有多个消费者
   * 应用场景：对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度
   * 在一个队列中如果有多个消费者，那么消费者之间对于同一个消息的关系是竞争的关系
   * Work Queues 对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。例如: 短信服务部署多个只需要有一个节点成功发送即可。

4. Pub/Sub订阅模式

   ![image-20230510215142430](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305102151306.png)

5. 路由模式

   ![image-20230511115213003](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202305111152263.png)

### Spring整合RabbitMQ

## RocketMQ

官网：https://rocketmq.apache.org/zh/

参考资料：

* https://www.bilibili.com/video/BV1L4411y7mn/?spm_id_from=333.337.search-card.all.click&vd_source=fabefd3fabfadb9324761989b55c26ea
* [RocketMq快速实战以及集群架构原理详解 - 掘金 (juejin.cn)](https://juejin.cn/post/7308909489154899983)

### 简介

RocketMQ是由阿里捐赠给Apache的一款低延迟、高并发、高可用、高可靠的分布式消息中间件。

1. 领域模型

   ![RocketMQ基本模型](https://rocketmq.apache.org/zh/assets/images/RocketMQ%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B-ebcf3458d04b36f47f4c9633c1e36bf7.png)

2. 核心概念
   - **Topic**：消息传输和存储的顶层容器，**用于标识同一类业务逻辑的消息**。主题通过TopicName来做唯一标识和区分。
   - **Message Queue**：Apache RocketMQ 中消息存储和传输的实际容器，也是消息的**最小存储单元**。
   - **Message**：生产者向Topic发送并最终传送给消费者的数据消息的载体。消息是 Apache RocketMQ 中的**最小数据传输单元**。按照消息传输特性的不同而定义的分类，用于类型管理和安全校验。 Apache RocketMQ 支持的消息类型（**Message Type**）有：
     - 普通消息
     - 顺序消息
     - 事务消息
     - 定时/延时消息
   - **消息属性**：生产者可以为消息定义的属性，包含Message Key和Tag。
   - **Message Key**：消息的业务标识，由消息生产者（Producer）设置，唯一标识某个业务逻辑。
   - **Message ID**：消息的全局唯一标识，由消息队列RocketMQ系统自动生成，唯一标识某条消息。
   - **Message Tag**：消息标签，二级消息类型，用来**进一步区分某个Topic下的消息分类**。
   - **Producer**：也称为消息发布者，负责生产并发送消息至Topic。
   - **Consumer**：也称为消息订阅者，负责从Topic接收并消费消息。
   - **Broker**：暂存和传输消息
   - **NameServer**：管理Broker
   - **分区**：即Topic Partition，物理上的概念。每个Topic包含一个或多个分区。
   - **消费位点**：每个Topic会有多个分区，每个分区会统计当前消息的总条数，这个称为最大位点MaxOffset；分区的起始位置对应的位置叫做起始位点MinOffset。
   - **Group**：一类生产者或消费者，这类生产者或消费者通常生产或消费同一类消息，且消息发布或订阅的逻辑一致。
   - **Group ID**：Group的标识。
   - **队列**：个Topic下会由一到多个队列来存储消息。
   - **Exactly-Once投递语义**：Exactly-Once投递语义是指发送到消息系统的消息只能被Consumer处理且仅处理一次，即使Producer重试消息发送导致某消息重复投递，该消息在Consumer也只被消费一次。
   - **集群消费**：一个Group ID所标识的所有Consumer平均分摊消费消息。例如某个Topic有9条消息，一个Group ID有3个Consumer实例，那么在集群消费模式下每个实例平均分摊，只消费其中的3条消息。
   - **广播消费**：一个Group ID所标识的所有Consumer都会各自消费某条消息一次。例如某个Topic有9条消息，一个Group ID有3个Consumer实例，那么在广播消费模式下每个实例都会各自消费9条消息。
   - **定时消息**：Producer将消息发送到消息队列RocketMQ服务端，但并不期望这条消息立马投递，而是推迟到在当前时间点之后的某一个时间投递到Consumer进行消费，该消息即定时消息。
   - **延时消息**：Producer将消息发送到消息队列RocketMQ服务端，但并不期望这条消息立马投递，而是延迟一定时间后才投递到Consumer进行消费，该消息即延时消息。
   - **事务消息**：RocketMQ提供类似X/Open XA的分布事务功能，通过消息队列RocketMQ的事务消息能达到分布式事务的最终一致。
   - **顺序消息**：RocketMQ提供的一种按照顺序进行发布和消费的消息类型，分为全局顺序消息和分区顺序消息。
   - **全局顺序消息**：对于指定的一个Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。
   - **分区顺序消息**：对于指定的一个Topic，所有消息根据Sharding Key进行区块分区。同一个分区内的消息按照严格的FIFO顺序进行发布和消费。Sharding Key是顺序消息中用来区分不同分区的关键字段，和普通消息的Message Key是完全不同的概念。
   - **消息堆积**：Producer已经将消息发送到消息队列RocketMQ的服务端，但由于Consumer消费能力有限，未能在短时间内将所有消息正确消费掉，此时在消息队列RocketMQ的服务端保存着未被消费的消息，该状态即消息堆积。
   - **消息过滤**：Consumer可以根据消息标签（Tag）对消息进行过滤，确保Consumer最终只接收被过滤后的消息类型。消息过滤在消息队列RocketMQ的服务端完成。
   - **消息轨迹**：在一条消息从Producer发出到Consumer消费处理过程中，由各个相关节点的时间、地点等数据汇聚而成的完整链路信息。通过消息轨迹，您能清晰定位消息从Producer发出，经由消息队列RocketMQ服务端，投递给Consumer的完整链路，方便定位排查问题。
   - **重置消费位点**：以时间轴为坐标，在消息持久化存储的时间范围内（默认3天），重新设置Consumer对已订阅的Topic的消费进度，设置完成后Consumer将接收设定时间点之后由Producer发送到消息队列RocketMQ服务端的消息。
   - **死信队列**：死信队列用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列RocketMQ会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明Consumer在正常情况下无法正确地消费该消息。此时，消息队列RocketMQ不会立刻将消息丢弃，而是将这条消息发送到该Consumer对应的特殊队列中。  消息队列RocketMQ将这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），将存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。

### 快速入门

参考：[快速开始](https://rocketmq.apache.org/zh/docs/quickStart/01quickstart)

1. 组件
   * Broker
     * Broker是RocketMQ中的核心组件，**负责存储和处理消息**。
     * 在RocketMQ中，通常会有多个Broker组成一个Broker集群（Cluster），每个Broker负责存储一部分消息数据。
     * Broker之间通过主从复制（Master-Slave）来实现数据的高可用性和容错性。
     * 在 Master-Slave 架构中，Broker 分为 Master 与 Slave。一个Master可以对应多个Slave，但是一个Slave只能对应一个Master。Master 与 Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。
   * Nameserver
     * Nameserver负责**管理整个RocketMQ集群的路由信息**。
     * 客户端通过Nameserver来发现和获取消息Broker的信息，包括Topic的路由信息和各个Broker的地址。
     * Nameserver本身是一个轻量级的组件，不参与实际的消息存储和传输。
     * NameServer通常会有多个实例部署，各实例间相互不进行信息通讯。
   * Proxy
     * Proxy充当了消息生产者和消费者与Broker之间的中间层。
     * Proxy可以理解为消息的网关，负责转发消息请求、负载均衡、流量控制等。
     * 在某些场景下，Proxy还可以用于对消息进行加速、过滤或者安全验证等操作。
2. 运行模式
   * **Local模式**：在RocketMQ的Local模式中，所有的Broker、Nameserver和Proxy都运行在同一个进程内，通常用于开发和测试环境，以简化部署和配置。
   * **Cluster模式**：在生产环境中，通常会使用RocketMQ的Cluster模式。在Cluster模式下，Broker、Nameserver和Proxy各自运行在不同的物理机器或者虚拟机上，通过网络连接进行通信和协作，以实现高可用性、容错性和水平扩展能力。

#### 集群搭建

docker部署rocket参考：https://blog.csdn.net/weixin_44606481/article/details/129780540

![RocketMQ角色](微服务技术.assets/RocketMQ角色-1690212428594.jpg)

1. 特点
   * NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。
   * Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。
   * Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。
   * Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。
2. 集群模式
   * 单Master模式：这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。
   * 多Master模式：一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优点是配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高；缺点是单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。
   * 多Master多Slave模式（异步）：每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优点是即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样；缺点是Master宕机，磁盘损坏情况下会丢失少量消息。
   * 多Master多Slave模式（同步）：每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优点是数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；缺点是性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。

### 消息

1. 构成
   * **topic**，表示要发送的消息的主题。
   * **body** 表示消息的存储内容
   * **properties** 表示消息属性
   * **transactionId** 会在事务消息中使用。

普通消息

顺序消息

事务消息

定时/延时消息

### Java客户端

官网示例：https://rocketmq.apache.org/zh/docs/sdk/02java

#### 发送普通消息

同步消息

~~~java
package com.whymechen.demorocket.common;

import org.apache.rocketmq.client.exception.MQBrokerException;
import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.client.producer.SendResult;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.exception.RemotingException;

import java.nio.charset.StandardCharsets;

/**
 * @author： chenwenjian
 * @date： 2023/7/26 11:01
 * @description： 同步发送普通消息
 * @modifiedBy：
 * @version: 1.0
 */
public class SyncCommonMessage {
    public static void main(String[] args) {
        // 创建生产者并设置生产组
        DefaultMQProducer commonMessage = new DefaultMQProducer("COMMON_MESSAGE");
        // 设置nameserver地址
        commonMessage.setNamesrvAddr("localhost:9876");
        try {
            // 启动producer
            commonMessage.start();
        } catch (MQClientException e) {
            throw new RuntimeException(e);
        }
        // 构建消息，指定topic、tag、body等信息
        for (int i = 0; i < 10; i++) {
            String msg = "msg"+i+"：Hello Rocket";
            Message message = new Message("commonMsg", "tag1", msg.getBytes(StandardCharsets.UTF_8));
            SendResult send;
            try {
                // 发送消息
                send = commonMessage.send(message);
            } catch (MQClientException | RemotingException | MQBrokerException | InterruptedException e) {
                throw new RuntimeException(e);
            }
            System.out.println("msg"+i+"：发送成功！msgId为"+send.getMsgId());
        }
        // 关闭producer
        commonMessage.shutdown();
    }
}

~~~

异步消息

~~~java
package com.whymechen.demorocket.common;

import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.client.producer.SendCallback;
import org.apache.rocketmq.client.producer.SendResult;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.exception.RemotingException;

import java.nio.charset.StandardCharsets;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * @author： chenwenjian
 * @date： 2023/7/26 12:53
 * @description： 异步发送普通消息，异步发送一般用于链路耗时较长，对响应时间较为敏感的业务场景。例如，视频上传后通知启动转码服务，转码完成后通知推送转码结果等。
 * @modifiedBy：
 * @version: 1.0
 */
public class AsyncCommonMessage {
    public static void main(String[] args) throws InterruptedException {
        DefaultMQProducer commonMessage = new DefaultMQProducer("COMMON_MESSAGE");
        commonMessage.setNamesrvAddr("localhost:9876");
        try {
            commonMessage.start();
            commonMessage.setRetryTimesWhenSendAsyncFailed(0);
        } catch (MQClientException e) {
            throw new RuntimeException(e);
        }
        int count = 10;
        final CountDownLatch countDownLatch = new CountDownLatch(count);
        for (int i = 0; i < count; i++) {
            String msg = "async msg"+i+"hello RocketMQ";
            Message message = new Message("commonMsg", "tag2", msg.getBytes(StandardCharsets.UTF_8));
            try {
                commonMessage.send(message, new SendCallback() {
                    @Override
                    public void onSuccess(SendResult sendResult) {
                        System.out.println("消息发送成功!msgId为"+sendResult.getMsgId());
                        countDownLatch.countDown();

                    }

                    @Override
                    public void onException(Throwable throwable) {
                        System.out.println("消息发送失败!失败原因为"+throwable.getMessage());
                        countDownLatch.countDown();
                    }
                });
            } catch (MQClientException | RemotingException | InterruptedException e) {
                throw new RuntimeException(e);
            }
        }
        //异步发送，如果要求可靠传输，必须要等回调接口返回明确结果后才能结束逻辑，否则立即关闭Producer可能导致部分消息尚未传输成功
        countDownLatch.await(5, TimeUnit.SECONDS);
        commonMessage.shutdown();
    }
}

~~~

单向模式

```java
package com.whymechen.demorocket.common;

import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.exception.RemotingException;

import java.nio.charset.StandardCharsets;

/**
 * @author： chenwenjian
 * @date： 2023/7/26 13:53
 * @description： 单向模式发送普通消息，此方式发送消息的过程耗时非常短，一般在微秒级别。适用于某些耗时非常短，但对可靠性要求并不高的场景，例如日志收集。
 * @modifiedBy：
 * @version: 1.0
 */
public class OneWayCommonMessage {
    public static void main(String[] args) throws MQClientException, RemotingException, InterruptedException {
        DefaultMQProducer commonMessage = new DefaultMQProducer("COMMON_MESSAGE");
        commonMessage.setNamesrvAddr("localhost:9876");
        commonMessage.start();
        for (int i = 0; i < 5; i++) {
            Message message = new Message("commonMsg", "tag3", ("one wag message" + i).getBytes(StandardCharsets.UTF_8));
            commonMessage.sendOneway(message);
        }

        commonMessage.shutdown();
    }
}
```

#### 发送顺序消息

```java
package com.whymechen.demorocket.sequence;

import org.apache.rocketmq.client.exception.MQBrokerException;
import org.apache.rocketmq.client.exception.MQClientException;
import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.client.producer.SendResult;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.common.RemotingHelper;
import org.apache.rocketmq.remoting.exception.RemotingException;

import java.io.UnsupportedEncodingException;

/**
 * @author： chenwenjian
 * @date： 2023/7/26 14:13
 * @description：
 * @modifiedBy：
 * @version: 1.0
 */
public class SequenceMessage {
    public static void main(String[] args) throws UnsupportedEncodingException {
        DefaultMQProducer producer = null;
        try {
            producer = new DefaultMQProducer("SEQUENCE_MESSAGE");
            producer.setNamesrvAddr("localhost:9876");
            producer.start();

            String[] tags = new String[]{"TagA", "TagB", "TagC", "TagD", "TagE"};
            for (int i = 0; i < 50; i++) {
                int orderId = i % 10;
                Message msg = new Message("secquenceMsg", tags[i % tags.length], "KEY" + i,
                                ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
                SendResult sendResult = producer.send(msg, (mqs, msg1, arg) -> {
                    Integer id = (Integer) arg;
                    int index = id % mqs.size();
                    return mqs.get(index);
                }, orderId);

                System.out.printf("%s%n", sendResult);
            }
        } catch (MQClientException | RemotingException | MQBrokerException | InterruptedException e) {
            e.printStackTrace();
        }finally {
           if (producer!=null){
               producer.shutdown();
           }
        }
    }
}
```

MessageQueueSelector的接口如下：

```java
public interface MessageQueueSelector {
    MessageQueue select(final List<MessageQueue> mqs, final Message msg, final Object arg);
}
```

其中 mqs 是可以发送的队列，msg是消息，arg是上述send接口中传入的Object对象，返回的是该消息需要发送到的队列。上述例子里，是以orderId作为分区分类标准，对所有队列个数取余，来对将相同orderId的消息发送到同一个队列中。

生产环境中建议选择最细粒度的分区键进行拆分，例如，将订单ID、用户ID作为分区键关键字，可实现同一终端用户的消息按照顺序处理，不同用户的消息无需保证顺序。

## ActiveMQ

学习参考：https://www.bilibili.com/video/BV164411G7aB/?spm_id_from=333.788.video.desc.click

# 缓存中间件

## Redis

Redis 是一种基于内存的键值存储系统，具有高性能和灵活的数据结构。它支持多种数据类型，并提供了丰富的功能，如缓存、发布/订阅、事务等，被广泛应用于微服务架构中的缓存和数据存储。

> Redis既可以作为缓存中间件，也可以当作数据库使用，具体视应用场景而定。当作为缓存时，它通常被视为 **中间件**；当用于持久化存储时，它也可被视为 **数据库**。
>
> Redis相关内容具体参考[Redis.md](./Redis.md)

## Memcached

Memcached 是一个简单而快速的分布式内存对象缓存系统，广泛用于加快动态网站的速度。它以键值对的形式存储数据，并将数据存储在内存中，从而提供了快速的读写访问。

## Hazelcast

Hazelcast 是一个开源的内存数据网格（In-Memory Data Grid）解决方案，提供了分布式缓存和分布式计算能力。它具有高度可扩展性、容错性和数据一致性，并可以与各种语言和框架集成。

## Couchbase

Couchbase 是一个分布式 NoSQL 数据库，同时也提供了内存缓存功能。它支持键值存储、文档存储和查询、全文搜索等功能，并具有自动分片、数据复制和故障转移的能力。

## Caffeine

Caffeine 是一个基于 Java 的高性能缓存库，提供了内存缓存的功能。它具有高速、异步加载、自动过期等特性，并支持多种缓存策略和数据回收机制。

# 容器化和部署

## Docker

视频：https://www.bilibili.com/video/BV1CJ411T7BK?p=1

文档：

* https://pdai.tech/md/devops/docker/docker-00-overview.html

### 简介

1. 容器：

   * **解决软件跨环境迁移问题**
   * 完全使用沙箱机制，相互隔离
   * 性能开销极低

2. Docker：一个开源的应用容器引擎

   * 官网：https://www.docker.com
   * 诞生于2013年初,基于Go语言实现，dotCloud 公司出品(后改名为Docker Inc)
   * Docker可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的Linux机器上。
   * Docker从17.03版本之后分为CE (Community Edition:社区版)和EE (Enterprise Edition:企业版)

3. docker架构

   ![image-20230311195708638](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303111957973.png)

4. 配置镜像加速器

   阿里云：https://cr.console.aliyun.com/cn-heyuan/instances/mirrors

   网易加速器：http://hub-mirror.c.163.com

   Docker官方中国加速器：https://registry.docker-cn.com

   ustc 的镜像：https://docker.mirrors.ustc.edu.cn

   daocloud：https://www.daocloud.io/mirror#accelerator-doc（注册后使用）

5. docker容器虚拟化和传统虚拟机虚拟化的比较

   ![image-20230311230728514](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112307226.png)
   
6. 重要概念

   * images
   * container

### 常用命令

1. 服务相关

   > 启动docker服务：system start docker
   >
   > 停止docker服务：system stop docker
   >
   > 重启docker服务：system restart docker
   >
   > 查看docker服务状态：system status docker
   >
   > 开机启动docker服务：system enable docker

2. 镜像相关命令

   镜像地址：https://hub.docker.com/

   > 查看镜像：docker images
   >
   > 搜索镜像：docker search
   >
   > 拉取镜像：docker pull
   >
   > 删除镜像：docker rmi

3. 容器相关命令

   > 查看正在运行的容器：docker ps
   >
   > ​	-a：表示查看所有容器
   >
   > 创建容器：docker run 
   >
   > ​	-i：保持容器运行。通常与-t同时使用。加入it这两个参数后,容器创建后自动进入容器中，退出容器后，容器自动关闭。
   >
   > ​	-t: 为容器重新分配一个伪输入终端，通常与-i同时使用。
   > ​	-d:以守护(后台)模式运行容器。创建一个容器在后台运行， 需要使用dockerexec进入容器。退出后，容器不会关闭。
   > ​	-it创建的容器-般称为交互式容器， -id 创建的容器一般称为守护式容器
   > ​	--name:为创建的容器命名。
   >
   > 进入容器：docker exec
   > 启动容器：docker start
   > 停止容器：docker stop
   > 删除容器：docker rm
   > 查看容器信息：docker inspect

### 容器数据卷

1. 数据卷：数据卷是宿主机中的一个目录或文件

   * 当容器目录和数据卷目录绑定后，对方的修改会立即同步
   * 一个数据卷可以被多个容器同时挂载
   * 一个容器也可以被挂载多个数据卷

2. 作用

   * 容器数据持久化
   * 外部机器和容器间接通信
   * 容器之间数据交换

3. 配置数据卷

   > docker run ... -v 宿主机目录(文件) :容器内目录(文件)
   >
   > 注意事项：
   >
   > * 目录必须是绝对路径
   > * 如果目录不存在,会自动创建
   > * 可以挂载多个数据卷

4. 数据卷容器

   ![image-20230311213730377](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112137385.png)

### Dockerfile

#### 镜像原理

docker镜像原理：**docker镜像的本质是一个分层文件系统**

![image-20230311215746393](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112157213.png)

#### 镜像制作

##### 基于容器制作

![image-20230311220359398](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112204252.png)

##### 基于dockerfile文件制作

1. 简介

   * Dockerfile是一个文本文件
   * 包含了一条条的指令，每一条指令构建一层,基于基础镜像，最终构建出一一个新的镜像
   * 对于开发人员:可以为开发团队提供一个完全一致的开发环境
   * 对于测试人员:可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作
   * 对于运维人员:在部署时，可以实现应用的无缝移植

2. 常见关键字

   | 关键字      | 作用                     | 备注                                                         |
   | ----------- | ------------------------ | ------------------------------------------------------------ |
   | FROM        | 指定父镜像               | 指定dockerfile基于那个image构建                              |
   | MAINTAINER  | 作者信息                 | 用来标明这个dockerfile谁写的                                 |
   | LABEL       | 标签                     | 用来标明dockerfile的标签 可以使用Label代替Maintainer 最终都是在docker image基本信息中可以查看 |
   | RUN         | 执行命令                 | 执行一段命令 默认是/bin/sh 格式: RUN command 或者 RUN ["command" , "param1","param2"] |
   | CMD         | 容器启动命令             | 提供启动容器时候的默认命令 和ENTRYPOINT配合使用.格式 CMD command param1 param2 或者 CMD ["command" , "param1","param2"] |
   | ENTRYPOINT  | 入口                     | 一般在制作一些执行就关闭的容器中会使用                       |
   | COPY        | 复制文件                 | build的时候复制文件到image中                                 |
   | ADD         | 添加文件                 | build的时候添加文件到image中 不仅仅局限于当前build上下文 可以来源于远程服务 |
   | ENV         | 环境变量                 | 指定build时候的环境变量 可以在启动的容器的时候 通过-e覆盖 格式ENV name=value |
   | ARG         | 构建参数                 | 构建参数 只在构建的时候使用的参数 如果有ENV 那么ENV的相同名字的值始终覆盖arg的参数 |
   | VOLUME      | 定义外部可以挂载的数据卷 | 指定build的image那些目录可以启动的时候挂载到文件系统中 启动容器的时候使用 -v 绑定 格式 VOLUME ["目录"] |
   | EXPOSE      | 暴露端口                 | 定义容器运行的时候监听的端口 启动容器的使用-p来绑定暴露端口 格式: EXPOSE 8080 或者 EXPOSE 8080/udp |
   | WORKDIR     | 工作目录                 | 指定容器内部的工作目录 如果没有创建则自动创建 如果指定/ 使用的是绝对地址 如果不是/开头那么是在上一条workdir的路径的相对路径 |
   | USER        | 指定执行用户             | 指定build或者启动的时候 用户 在RUN CMD ENTRYPONT执行的时候的用户 |
   | HEALTHCHECK | 健康检查                 | 指定监测当前容器的健康监测的命令 基本上没用 因为很多时候 应用本身有健康监测机制 |
   | ONBUILD     | 触发器                   | 当存在ONBUILD关键字的镜像作为基础镜像的时候 当执行FROM完成之后 会执行 ONBUILD的命令 但是不影响当前镜像 用处也不怎么大 |
   | STOPSIGNAL  | 发送信号量到宿主机       | 该STOPSIGNAL指令设置将发送到容器的系统调用信号以退出。       |
   | SHELL       | 指定执行脚本的shell      | 指定RUN CMD ENTRYPOINT 执行命令的时候 使用的shell            |

### Docker Compose

Docker Compose是一个编排多容器分布式部署的工具，提供命令集管理容器化应用的完整开发周期，包括服务构建启动和停止。使用步骤:

* 利用 Dockerfile定义运行环境镜像
* 使用docker-compose.yml定义组成应用的各服务
* 运行 docker-composeup 启动应用

![image-20230311230230122](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202303112302382.png)

### Docker 私有仓库

## kubernetes

## Rancher

官网：https://www.rancher.com/

文档：https://docs.rancher.cn/

# 分布式系统基础

负载均衡、高可用性、容错机制

# 分布式搜索

数据类型：

* 结构化数据：可以用二维表存储的数据
* 非结构化数据：音视频，图表，日志等
* 半结构化数据：html，xml等

## Elastic tack

官网：https://www.elastic.co/cn/

学习参考：

* https://www.bilibili.com/video/BV1hh411D7sb?p=1
* https://www.bilibili.com/video/BV1Nt4y1m7qL?p=1

The Elastic Stack，也称为ELK Stack，是一个免费开源的日志分析架构技术栈总称。包括Logstash（数据抽取），ElasticseaIch（搜索分析）、Kibana（数据展示）、Beats等基础组件。

ELK能够安全可靠地获取任何来源、任何格式的数据，然后实时地对数据进行搜索、分析和可视化。

ELK不仅仅适用于日志分析，它还可以支持其它任何数据搜索、分析和收集的场景，日志分析和收集只是更具有代表性。并非唯一性。 下面是ELK简单架构示意图 :

![image-20230912232631464](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202309122326772.png)

1. 特点

   * 处理方式灵活：elasticsearch是目前最流行的准实时全文检索引擎,具有高速检索大数据的能力。
   * 配置简单：安装elk的每个组件,仅需配置每个组件的一个配置文件即可。修改处不多,因为大量参数已经默认配在系统中,修改想要修改的选项即可。
   * 接口简单：采用json形式RESTFUL API接受数据并响应,无关语言。
     性能高效: elasticsearch基于优秀的全文搜索技术Lucene ,采用倒排索引,可以轻易地在百亿级别数据量下,搜索出想要的内容,并且是秒级响应。
   * 灵活扩展：elasticsearch和logstash都可以根据集群规模线性拓展，elasticsearch内部自动实现集群协作。
   * 数据展现华丽：kibana作为前端展现工具,图表华丽,配置简单。

2. 组件

   * `Logstash`：Logstash基于java开发,是一个数据抽取转化工具。一般工作方式为c/s架构, client端安装在需要收集信息的主机上, server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch或其他组件上。

   * `Elasticsearch`：Elasticsearch是使用java开发,基于Lucene、分布式、通过Restful方式进行交互的近实时搜索平台框架。它的特点有: 分布式,零配置，自动发现,索引自动分片,索弓副本机制, restful风格接口,多数据源,自动搜索负载等。

   * `Kibana`：Kibana基于nodejs ,也是一个开源和免费的可视化工具。Kibana可以为Logstash和ElasticSearch提供的日志分析友好的Web界面，可以汇总、分析和搜索重要数据日志。

   * `Beats`：Beats 平台集合了多种单一用途数据采集器。它们从成百上千或成千上万台机器和系统向 Logstash 或 Elasticsearch 发送数据。Beats由如下组成:

      Packetbeat：轻量型网络数据采集器，用于深挖网线上传输的数据，了解应用程序动态。Packetbeat 是一款轻量型网络数据包分析器，能够将数据发送至 Logstash 或 Elasticsearch。其支 持ICMP (v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache等协议。

      Filebeat：轻量型日志采集器。当您要面对成百上千、甚至成千上万的服务器、虚拟机和容器生成的日志时，请告别 SSH 吧。Filebeat 将为您提供一种轻量型方法，用于转发和汇总日志与文件，让简单的事情不再繁杂。

      Metricbeat ：轻量型指标采集器。Metricbeat 能够以一种轻量型的方式，输送各种系统和服务统计数据，从 CPU 到内存，从 Redis 到 Nginx，不一而足。可定期获取外部系统的监控指标信息，其可以监控、收集 Apache http、HAProxy、MongoDB、MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务。

      Winlogbeat：轻量型 Windows 事件日志采集器。用于密切监控基于 Windows 的基础设施上发生的事件。Winlogbeat 能够以一种轻量型的方式，将 Windows 事件日志实时地流式传输至 Elasticsearch 和 Logstash。

      Auditbeat：轻量型审计日志采集器。收集您 Linux 审计框架的数据，监控文件完整性。Auditbeat 实时采集这些事件，然后发送到 Elastic Stack 其他部分做进一步分析。

      Heartbeat：面向运行状态监测的轻量型采集器。通过主动探测来监测服务的可用性。通过给定 URL 列表，Heartbeat 仅仅询问：网站运行正常吗？Heartbeat 会将此信息和响应时间发送至 Elastic 的其他部分，以进行进一步分析。

      Functionbeat：面向云端数据的无服务器采集器。在作为一项功能部署在云服务提供商的功能即服务 (FaaS) 平台上后，Functionbeat 即能收集、传送并监测来自您的云服务的相关数据。

   * `ELastic cloud`：基于 Elasticsearch 的软件即服务(SaaS)解决方案。通过 Elastic 的官方合作伙伴使用托管的 Elasticsearch 服务。

### ElasticSearch

#### 简介

ElasticSearch官网：https://www.elastic.co/cn/products/elasticsearch

ElasticSearch文档：https://www.elastic.co/guide/en/elasticsearch/reference/7.6/index.html

lucene官网：https://lucene.apache.org/

一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文**搜索引擎**，基于RESTful web接口。

> Lucene：一个封装了全文检索的引擎、搜索算法代码的jar包。可以通过该包中的API开发搜索相关业务，底层会在磁盘建立索引库。
>
> * 搜索：根据关键词返回含有该关键词的所有信息。
> * 全文检索
> * 倒排索引：倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。带有倒排索引的文件我们称为倒排[索引文件](https://baike.baidu.com/item/索引文件)，简称[倒排文件](https://baike.baidu.com/item/倒排文件/4137688)(inverted file)。
> * Lucene的问题
>   * 数据分布-》分片机制
>   * 数据交互-》平行节点，内部交互
>   * 数据备份-》副本机制

1. 数据库搜索的存在的问题

   * 站内搜索：数据量大时无法，需要分库分表；模糊搜索，不能分词，可能导致搜索结果不是预期结果。
   * 互联网搜索：数据量级太大，数据库无法负载

2. 功能：

   * 分布式的搜索引擎和数据分析引擎
   * 全文检索，结构化检索，数据分析
   * 对海量数据进行近实时的处理

3. 使用场景：（互联网搜索/站内搜索）

   * 维基百科，类似百度百科，“网络七层协议”的维基百科，全文检索，高亮，搜索推荐
   * Stack Overflow（国外的程序讨论论坛），相当于程序员的贴吧。遇到it问题去上面发帖，热心网友下面回帖解答。
   * GitHub（开源代码管理），搜索上千亿行代码。
   * 电商网站，检索商品
   * 日志数据分析，logstash采集日志，ES进行复杂的数据分析（ELK技术，elasticsearch+logstash+kibana）
   * 商品价格监控网站，用户设定某商品的价格阈值，当低于该阈值的时候，发送通知消息给用户，比如说订阅《java编程思想》的监控，如果价格低于27块钱，就通知我，我就去买。
   * BI系统，商业智能（Business Intelligence）。大型连锁超市，分析全国网点传回的数据，分析各个商品在什么季节的销售量最好、利润最高。成本管理，店面租金、员工工资、负债等信息进行分析。从而部署下一个阶段的战略目标。
   * 百度搜索，第一次查询，使用es。
   * OA、ERP系统站内搜索。

4. **核心概念**

   * 近实时（NRT，Near Realtime）：写入数据时需要1秒后才可被搜索，搜索时需要秒级才能出结果

   * 集群（cluster）

   * 节点（node）

   * **文档**（document）：

     * es中的最小数据单元，一个document就像数据库中的一条记录，通常以json格式显示。
     * 多个document存储于一个索引（Index）中。
     * 每个文档都有一个唯一的标识符（ID），用于在索引中标识和检索文档。

   * **索引**（index）：包含一堆有相似结构的文档数据。

     * 索引是存储数据的逻辑空间，类似于关系型数据库中的数据库。
     * 索引包含多个文档，并且可以在索引中执行搜索、聚合和分析操作。

   * 映射（mapping）

     * 映射定义了索引中文档的结构和字段的类型。
     * 映射规定了每个字段的数据类型，如文本、数字、日期等，以及字段的索引方式、分词器等。

   * 字段（field）：就像数据库中的列(Columns)，定义每个document应该有的字段

   * 类型（type）

     * 在较早的版本中，Elasticsearch 中的文档会根据类型进行分类。但在最新版本中，类型被废弃，建议将所有文档存储在单个索引中。
     * 在新版本中，可以通过字段来对文档进行分类和过滤。

     > **注意**：6.0之前的版本有type（类型）概念，type相当于关系数据库的表，ES官方将在ES9.0版本中彻底删除type。

   * 分片（shared）

     * 为了实现水平扩展和高可用性，Elasticsearch 将索引划分为多个分片。
     * 每个分片是一个独立的索引单元，包含部分文档和索引结构。

   * 副本（replica）

     * 为了提高搜索性能和可用性，Elasticsearch 允许创建索引的副本。

     * 副本是分片的完全复制，可以在集群中的其他节点上进行复制，提供冗余和负载均衡。


| MySQL  | Elasticsearch | 说明                                                         |
| ------ | ------------- | ------------------------------------------------------------ |
| Table  | Index         |                                                              |
| ROW    | Document      |                                                              |
| column | Field         |                                                              |
| Schema | Mapping       |                                                              |
| SQL    | DSL           | DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD |

   > 虽然MySQL和ELasticsearch的概念在实质上有一定区别，但是可以根据上述类比来帮助理解。**Mysql擅长事务类型操作，可以确保数据的安全和一致性。Elasticsearch擅长海量数据的搜索、分析、计算。**

#### 安装

1. 安装过程（windows）

   * 安装jdk
   * 解压ELasticsearch安装包

   > docker方式部署参考：https://blog.csdn.net/qq_44861126/article/details/132480537

2. 配置文件

   * 位置：ES的配置文件的地址根据安装形式的不同而不同。
     * 使用zip、tar安装，配置文件的地址在安装目录的config下。
     * 使用RPM安装，配置文件在/etc/elasticsearch下
     * 使用MSI安装，配置文件的地址在安装目录的config下，并且会自动将config目录地址写入环境变量ESPATH CONF。
   * 内容
     * elasticsearch.yml
     * jvm.options
     * log4j2.properties

3. 分词器

   es在创建倒排索引时需要对文档分词；在搜索时，需要对用户输入内容分词。常见的分词器有以下几种：

   * Standard Analyzer：一个基于 Unicode Text Segmentation 算法的分词器，可以将文本分解成单词，并去除一些停用词，如“a”、“the”等。因为它是 Elasticsearch 的默认分词器，所以任何字段如果没有指定别的分词器，都会使用该分词器。
   * Simple Analyzer：只能根据非字母字符对文本进行分解，并将得到的单词转化为小写形式。不支持词干化或停用词过滤，适合简单的短语匹配。
   * Whitespace Analyzer：仅仅是将输入的字符串根据空格分隔成单词序列，适合处理不需要进一步处理的文本，如标识符或者序列号。
   * Keyword Analyzer：将输入的内容当成一个整体，不会进行分词，但是会进行大小写转换等规范化操作。主要用于需要精确匹配的场景，如身份证号、电话号码等。
   * Stop Analyzer：对文本进行分词，并去除其中一些常用词汇，如“a”、“the”等。这是一个较为基础和常用的分词器。
   * Pattern Analyzer：这个分词器使用正则表达式对文本进行分词和规则化。通过灵活的正则表达式来定义分词规则，可以很好地适应各种特殊场景。
   * Language Analyzers：Elasticsearch 还提供了多个针对不同语言的分词器，如中文、日本语、韩语、法语、德语、西班牙语等。

   默认的分词规则对中文处理并不友好。处理中文分词，一般会使用IK分词器（https://github.com/medcl/elasticsearch-analysis-ik）。ik分词器包含两种模式：

   * ik_smart：最少切分，粗粒度
   * ik_max_word：最细切分，细粒度

   同时只需要修改一个ik分词器目录中的config目录中的IkAnalyzer.cfg.xml文件就可以实现拓展词库和停用词库。

#### 集群管理

集群管理：es提供了一套api，叫做cat api，可以查看es中各种各样的数据。

~~~
# 了解集群的健康状况
GET /_cat/health?v

# 查看集群中所有索引
GET /_cat/indices?v
~~~

> 说明：v是用来要求在结果中返回表头

#### Index操作

mapping是对索引库中文档的约束，常见的mapping属性包括：

* type：字段数据类型，常见的简单类型有：
  * 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）
  * 数值：long、integer、short、byte、double、float、
  * 布尔：boolean
  * 日期：date
  * 对象：object
  * ES中支持两种地理坐标数据类型：
    * geo_point：由纬度（latitude）和经度（longitude）确定的一个点。例如："32.8752345, 120.2981576"
    * geo_shape：有多个geo_point组成的复杂几何图形。例如一条直线，"LINESTRING (-77.03653 38.897676, -77.009051 38.889939)"
* index：是否创建索引，默认为true
* analyzer：使用哪种分词器
* properties：该字段的子字段
* copy_to：字段拷贝可以使用copy_to属性将当前字段拷贝到指定字段。

~~~
# 创建索引
PUT /demo?pretty

PUT /user
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "index": true
      },
      "age": {
        "type": "integer"
      },
      "email":{
        "type": "text"
      },
      "title":{
        "type": "text"
        , "analyzer": "ik_smart"
      }
    }
  }  
}

# 查看索引
GET /user

# 删除索引
DELETE /demo?pretty

# 修改索引
# 索引库和mapping一旦创建无法修改，但是可以添加新的字段
PUT /user/_mapping
{
  "properties": {
    "address": {
      "type": "text",
      "analyzer": "ik_smart"
    }
  }
}
~~~

在 Elasticsearch 中，使用 PUT 方法创建索引是因为 PUT 方法在 HTTP 协议中被定义为幂等的，而创建索引是一个幂等的操作。即可以多次执行相同的 PUT 请求，但只会创建一个索引。

在计算机科学中，幂等是一个重要的概念，用于描述一个操作或者函数的特性。**具体来说，幂等指的是对同一个操作进行多次执行的结果与仅执行一次的结果相同。**

换句话说，无论对一个幂等操作执行多少次，其最终的状态都是一致的。这样的特性对于设计和实现系统和算法非常重要，尤其在分布式系统、网络通信和数据存储等领域。

下面通过几个例子来说明幂等的概念：

1. GET 请求：HTTP 的 GET 请求是幂等的，即对同一资源的多次 GET 请求将始终返回相同的结果，并不会对服务器端产生影响或副作用。因此，可以放心地发送多个相同的 GET 请求，而不用担心结果会有变化。
2. 数据库的 INSERT 操作：在数据库中，如果执行一条 INSERT 语句多次，实际上只会插入一条记录，因为主键冲突了。所以 INSERT 操作可以看作是幂等的，多次执行也不会改变数据库的状态。
3. 去重操作：在处理消息、日志或者其他类型的数据时，往往需要进行去重操作，以避免重复处理相同的数据。去重操作是幂等的，因为无论对同一条数据进行多少次去重，最终结果都只会保留一条。

#### Document操作

1. CRUD操作

   ~~~
   # 创建索引
   PUT /book?pretty
   
   # 插入数据
   # 语法：PUT /index/type/id
   PUT /book/_doc/1
   {
   "name": "Bootstrap开发",
   "description": "Bootstrap是由Twitter推出的一个前台页面开发css框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长css页面开发的程序人员）轻松的实现一个css，不受浏览器限制的精美界面css效果。",
   "studymodel": "201002",
   "price":38.6,
   "timestamp":"2019-08-25 19:11:35",
   "pic":"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg",
   "tags": [ "bootstrap", "dev"]
   }
   
   PUT /book/_doc/2
   {
   "name": "java编程思想",
   "description": "java语言是世界第一编程语言，在软件开发领域使用人数最多。",
   "studymodel": "201001",
   "price":68.6,
   "timestamp":"2019-08-25 19:11:35",
   "pic":"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg",
   "tags": [ "java", "dev"]
   }
   PUT /book/_doc/3
   {
   "name": "spring开发基础",
   "description": "spring 在java领域非常流行，java程序员都在用。",
   "studymodel": "201001",
   "price":88.6,
   "timestamp":"2019-08-24 19:11:35",
   "pic":"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg",
   "tags": [ "spring", "java"]
   }
   
   # 查询操作
   # 语法：GET /index/type/id
   GET /book/_doc/1
   
   # 更新（修改）操作
   # 方式一：全局替换，即整体覆盖，要带上所有信息。
   PUT /book/_doc/1
   {
       "name": "Bootstrap开发教程",
       "description": "Bootstrap是由Twitter推出的一个前台页面开发css框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长css页面开发的程序人员）轻松的实现一个css，不受浏览器限制的精美界面css效果。",
       "studymodel": "201002",
       "price":38.6,
       "timestamp":"2019-08-25 19:11:35",
       "pic":"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg",
       "tags": [ "bootstrap", "开发","web"]
   }
   # 方式二：部分
   # 语法：POST /{index}/type /{id}/_update 或者 POST /{index}/_update/{id}
   POST /book/_update/1
   {
     "doc": {
      "name": " Bootstrap开发教程高级"
     }
   }
   
   # 删除操作
   DELETE /book/_doc/1
   ~~~
   
   在进行id相同时的两次更新操作，旧文档的内容不会立即删除，只是标记为deleted。适当的时机（达到一定阈值），集群会将这些文档删除，但版本号（_version）字段不断上升。当然为防止覆盖原有数据，我们在新增时，可以通过下面的语法设置为强制创建，不会覆盖原有文档。
   
   ~~~
      PUT /index/ _doc/id/_create
   ~~~
   
   同样的在进行删除操作时，也不会立即删除，而是标记为删除状态，在合适的时机进行统一删除。（即lazy delete机制）

2. 默认自带字段

   * _index：此文档属于哪个索引

     - 原则：类似数据放在一个索引中。数据库中表的定义规则。如图书信息放在book索引中，员工信息放在employee索引中。各个索引存储和搜索时互不影响。
     - 定义规则：英文小写。尽量不要使用特殊字符。

   * ~~_type：类别~~

     > ~~以后的es9将彻底删除此字段，所以当前版本在不断弱化type，不需要关注。~~

   * _id：文档的唯一标识。就像表的id主键。结合索引可以标识和定义一个文档。

     * 手动生成：使用场景通常是数据从其他系统导入时，本身有唯一主键。如数据库中的图书、员工信息等。
     * 自动生成：自动id的特点是长度为20个字符，URL安全，base64编码，GUID，分布式生成不冲突

3. _source字段

   * 插入数据时的所有字段和值。在get获取数据时，在_source字段中原样返回。

   * 可以通过类型下面的语法操作来指定返回_source字段中的指定值

     ~~~
     GET /book/_doc/1?__source_includes=name,price
     ~~~

4. 使用脚本更新

   官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-using.html

   es可以内置脚本执行复杂操作。例如painless脚本。

   > 注意：groovy脚本在es6以后就不支持了。原因是耗内存，不安全远程注入漏洞。

5. es基于_version乐观锁的控制

   **es对于文档的增删改都是基于版本号。**

6. es内部并发控制

   **es内部主从同步时，是多线程异步。乐观锁机制。**

#### DSL

Elasticsearch提供了基于JSON的DSL（[Domain Specific Language](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)）来定义查询。常见的查询类型包括：

* 查询所有：查询出所有数据，一般测试用。例如：match_all

* 全文检索（full text）查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：match_query、multi_match_query

* 精确查询：根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如：ids、range、term

* 地理（geo）查询：根据经纬度查询。例如：geo_distance、geo_bounding_box

* 复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：bool、function_score。

  * fuction score：算分函数查询，可以控制文档相关性算分，控制文档排名。当我们利用match查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。
    $$
    TF(词条频率)=\frac{词条出现次数}{文档中词条总数}
    $$

    $$
    IDF(逆文档频率)=Log(\frac{文档总数}{包含词条的文档总数})\\
    score=\sum_i^n TF(词条频率)*IDF(逆文档频率) \tag{TF-IDF算法}
    $$

    $$
    Score(Q,d) = ∑_𝑖^𝑛log⁡(1+ (𝑁 −𝑛+0.5)/(𝑛+0.5))*  (𝑓_𝑖  )/(𝑓_𝑖+ 𝑘_(1 )  * (1 −𝑏+  𝑏 * 𝑑𝑙/𝑎𝑣𝑔𝑑𝑙)) \tag{DM25算法}
    $$

![image-20231006222255180](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202310062223895.png)

通过查询获取到数据后，需要对搜索结果进行处理，es支持一下操作：

1. 排序

   elasticsearch支持对搜索[结果排序](https://www.elastic.co/guide/en/elasticsearch/reference/current/sort-search-results.html)，默认是根据相关度算分（_score）来排序。可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等。

2. 分页

   elasticsearch 默认情况下只返回top10的数据。而如果要查询更多数据就需要修改分页参数了。elasticsearch中通过修改from、size参数来控制要返回的分页结果。

   ES是分布式的，所以会面临**深度分页**问题。如果搜索页数过深，或者结果集（from + size）越大，对内存和CPU的消耗也越高。因此ES设定结果集查询的上限是10000。针对深度分页，ES提供了两种解决方案，[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html)：

   * search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。
   * scroll：原理将排序数据形成快照，保存在内存。官方已经不推荐使用。

3. 高亮：即在搜索结果中把搜索关键字突出显示。

   高亮的原理是将搜索结果中的关键字用标签标记出来，在页面中给标签添加css样式。默认情况下，ES搜索字段必须与高亮字段一致。

DSL查询示例：

~~~
// 基本语法
GET /indexName/_search
{
  "query": {
    "查询类型": {
      "查询条件": "条件值"
    }
  }
}

# 查询所有
GET /hotel/_search
{
  "query": {
    "match_all": {}
  }
}

# match
GET /hotel/_search
{
  "query": {
    "match": {
      "name": "连锁"
    }
  }
}

# multi_match
GET /hotel/_search
{
  "query": {
    "multi_match": {
      "query": "7天连锁",
      "fields": ["brand","name","business"]
    }
  }
}

# match：根据一个字段查询，multi_match：根据多个字段查询，参与查询字段越多，查询性能越差

// 语法：term查询
GET /indexName/_search
{
  "query": {
    "term": {
      "FIELD": {
        "value": "VALUE"
      }
    }
  }
}

// range查询
GET /indexName/_search
{
  "query": {
    "range": {
      "FIELD": {
        "gte": 10,
        "lte": 20
      }
    }
  }
}

# term查询
GET /hotel/_search
{
  "query": {
    "term": {
      "city": {
        "value": "上海"
      }
    }
  }
}

# range查询,gte为大于等于，gt为大于
GET /hotel/_search
{
  "query": {
    "range": {
      "price": {
        "gte": 200,
        "lte": 500
      }
    }
  }
}

# distance查询
GET /hotel/_search
{
  "query": {
    "geo_distance":{
      "distance":"15km",
      "location":"31.21, 121.5"
    }
  }
}

# boolean query
# must：必须匹配每个子查询，类似“与”
# should：选择性匹配子查询，类似“或”
# must_not：必须不匹配，不参与算分，类似“非”
# filter：必须匹配，不参与算分
# boolean query
GET /hotel/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "term": {
            "city": "上海"
          }
        }
      ],
      "should": [
        {
          "term": {
            "brand": "皇冠假日"
          }
        },
        {
          "term": {
            "brand": "华美达"
          }
        }
      ],
      "must_not": [
        {
          "range": {
            "price": {
              "lte": 500
            }
          }
        }
      ],
      "filter": [
        {
          "range": {
            "score": {
              "gte": 45
            }
          }
        }
      ]
    }
  },
  "sort": [
    {
      "score": {
        "order": "desc"
      }
    }
  ],
  "from": 5,
  "size": 20
}

# 高亮显示
GET /hotel/_search
{
  "query": {
    "match": {
      "name": "上海"
    }
  },
  "highlight": {
    "fields":{ 
      "name": {
        "require_field_match": "true", 
        "pre_tags": "<em>",
        "post_tags": "</em>"
      }
    }
  }
}
~~~

#### ES客户端

官方文档：https://www.elastic.co/guide/en/elasticsearch/client/index.html

ES官方提供了各种不同语言的客户端，用来操作ES。这些客户端的本质就是组装DSL语句，通过http请求发送给ES.

#### java客户端

JavaAPI文档：https://www.elastic.co/guide/en/elasticsearch/client/java-rest/7.3/java-rest-overview.html

导入依赖：

~~~xml
    <dependency>
      <groupId>org.elasticsearch.client</groupId>
      <artifactId>elasticsearch-rest-high-level-client</artifactId>
      <version>7.10.1</version>
      <exclusions>
        <exclusion>
          <groupId>org.elasticsearch</groupId>
          <artifactId>elasticsearch</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.elasticsearch</groupId>
      <artifactId>elasticsearch</artifactId>
      <version>7.10.1</version>
    </dependency>
~~~

初始化RestHighLevelClient：

```java
RestHighLevelClient client = new RestHighLevelClient(RestClient.builder(
        HttpHost.create("https://es-imv6dsro.public.tencentelasticsearch.com:9200"))
);
```

操作索引库：

```java
@Test
void testCreateHotelIndex() throws IOException {
    // 创建请求
    CreateIndexRequest indexRequest = new CreateIndexRequest("hotel");
    // 组织请求参数
    indexRequest.source(HotelConstants.MAPPING_TEMPLATE, XContentType.JSON);
    // 发起请求
    client.indices()
          .create(indexRequest, RequestOptions.DEFAULT);
}
/**
     * 删除索引库
     */
    @Test
    void testDeleteHotelIndex() throws IOException {
        DeleteIndexRequest indexRequest = new DeleteIndexRequest("hotel");
        AcknowledgedResponse acknowledgedResponse = client.indices()
                                                          .delete(indexRequest, RequestOptions.DEFAULT);
        log.info(JSON.toJSONString(acknowledgedResponse));
    }

    /**
     * 判断索引库是否存在
     * @throws IOException
     */
    @Test
    void testExistHotelIndex() throws IOException {
        GetIndexRequest indexRequest = new GetIndexRequest("hotel");
        GetIndexResponse getIndexResponse = client.indices()
                                                  .get(indexRequest, RequestOptions.DEFAULT);
        log.info(JSON.toJSONString(getIndexResponse));
    }
```

操作Document：

```java
/**
 * 创建Document
 */
@Test
void testCreateDocument() {
    // 获取数据库数据
    List<Hotel> hotelList = hotelService.list();
    hotelList.forEach(hotel -> {
        // 创建请求
        IndexRequest indexRequest = new IndexRequest("hotel").id(hotel.getId().toString());
        // 准备json数据
        Map<String, Object> source = BeanUtil.beanToMap(new HotelDoc(hotel));
        indexRequest.source(source,XContentType.JSON);
        // 发起请求
        IndexResponse response = null;
        try {
            response = client.index(indexRequest, RequestOptions.DEFAULT);
        } catch (IOException e) {
            e.printStackTrace();
        }
        log.info(JSON.toJSONString(response));
    });
}

    /**
     * 批量导入数据到es
     */
    @Test
    void testBulk() throws IOException {
        List<Hotel> hotelList = hotelService.list();
        BulkRequest bulkRequest = new BulkRequest();
        hotelList.forEach(hotel -> {
            bulkRequest.add(new IndexRequest().index("hotel").source(BeanUtil.beanToMap(new HotelDoc(hotel))).id(hotel.getId().toString()));
        });
        client.bulk(bulkRequest,RequestOptions.DEFAULT);
    }

/**
 * 查询Document
 */
@Test
void testGetDocument() throws IOException {
    GetRequest getRequest = new GetRequest("hotel", "47066");
    GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT);
    log.info(JSON.toJSONString(getResponse));
    String source = getResponse.getSourceAsString();
    log.info("{}",JSON.parseObject(source));
}

/**
 * 更新Document
 */
@Test
void testUpdateDocument() throws IOException {
    UpdateRequest updateRequest = new UpdateRequest("hotel", "47066");
    updateRequest.doc("price",500);
    client.update(updateRequest,RequestOptions.DEFAULT);
}

/**
 * 删除Document
 */
@Test
void testDeleteDocument() throws IOException {
    DeleteRequest deleteRequest = new DeleteRequest("hotel", "47066");
    client.delete(deleteRequest,RequestOptions.DEFAULT);
}
```

查询Document：

#### Python客户端

### Kibana

官方文档：https://www.elastic.co/guide/en/kibana/7.6/release-notes-7.6.1.html

# 分布式任务调度

## Cron

工具：

* [Cron - 在线Cron表达式生成器](https://cron.ciding.cc/)

## xxl-job

xxl社区：[XXL开源社区 | 首页 (xuxueli.com)](https://www.xuxueli.com/index.html)

xxl-job：[分布式任务调度平台XXL-JOB (xuxueli.com)](https://www.xuxueli.com/xxl-job/#《分布式任务调度平台XXL-JOB》)

gitee：[xxl-job: 一个分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。 (gitee.com)](https://gitee.com/xuxueli0323/xxl-job)

github：[GitHub - xuxueli/xxl-job: A distributed task scheduling framework.（分布式任务调度平台XXL-JOB）](https://github.com/xuxueli/xxl-job)

### 快速入门

* [Spring Boot 集成 XXL-JOB 任务调度平台]([Spring Boot 集成 XXL-JOB 任务调度平台 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/349195503))
## Elastic-Job

# 监控和日志

## SpringBoot Admin

## APM

应用性能管理（Application Performance Management）：这是一种软件工具或解决方案，用于监测、管理和优化应用程序的性能及可用性。APM工具提供实时的、端到端的性能监控，帮助开发人员和运维团队识别并解决性能问题，提高应用程序的性能、可靠性和用户体验。它通常包括性能监控、故障追踪、事务分析、用户行为分析等功能。

## Arthas

官网：[arthas (aliyun.com)](https://arthas.aliyun.com/)

# RPC

参考：https://www.bilibili.com/video/BV11i4y1N7LQ/?spm_id_from=333.337.search-card.all.click&vd_source=fabefd3fabfadb9324761989b55c26ea

## Remoting协议

Remoting协议是一种用于分布式系统中的远程过程调用（RPC）的通信协议。它允许不同计算机之间的应用程序通过网络进行通信，以便调用和执行远程计算机上的方法或函数。

Remoting协议的主要目标是使远程调用的过程像本地调用一样简单和透明。它隐藏了底层网络通信的细节，使开发者能够以类似于本地方法调用的方式编写代码。

1. 主要特点：
   * 远程调用透明性：Remoting协议使得远程调用过程对开发者来说是透明的。开发者可以像调用本地方法一样调用远程方法，不需要关注底层的网络通信和序列化过程。
   * 语言无关性：Remoting协议不依赖于特定的编程语言。它可以用于支持多种编程语言之间的远程通信，例如Java、C#、Python等。
   * 传输方式灵活性：Remoting协议支持多种传输方式，如TCP、HTTP等。开发者可以根据需求选择合适的传输方式。
   * 序列化和反序列化支持：Remoting协议提供了序列化和反序列化的支持，用于将方法参数和返回值在不同计算机之间进行传输和还原。这使得对象的跨网络传输变得简单和高效。
   * 异常处理：Remoting协议能够处理远程调用中的异常情况，并将异常信息传递给调用方。这样，开发者可以在远程调用过程中处理异常，确保系统的稳定性和可靠性。
   * Remoting协议通常需要使用专门的框架或库来实现，如Java的RMI（Remote Method Invocation）和.NET的Remoting框架。

## gRPC协议

文档： https://grpc.io/

gRPC（全称为Google Remote Procedure Call）是一种远程过程调用协议，由Google开发并于2015年对外发布。它基于HTTP/2协议，并使用Protocol Buffers作为数据序列化和接口定义语言。

gRPC旨在简化分布式系统间的通信，它支持多种编程语言（如C++, Java, Python等），并提供了强大的功能和性能优势。

1. 主要特点：
   * 高性能：gRPC使用二进制数据格式（Protocol Buffers）和基于HTTP/2的传输协议，具有较低的序列化和网络开销，以及高效的多路复用和流控制机制。这使得gRPC在性能方面比传统的文本协议（如JSON或XML）更加高效。
   * 强大的接口定义和代码生成：gRPC使用基于IDL（Interface Definition Language）的Protocol Buffers来定义服务接口和消息格式。通过定义清晰的接口规范，它能够自动生成跨多种编程语言的客户端和服务器端代码，简化了开发者的工作量。
   * 支持多种通信模式：gRPC支持四种类型的RPC（Remote Procedure Call）方法调用，包括简单的单向调用、服务端流式调用、客户端流式调用和双向流式调用。这使得开发者能够根据具体的需求选择适当的通信模式，实现灵活的数据交互。
   * 提供拦截器和中间件：gRPC支持拦截器和中间件机制，使开发者能够在请求和响应的处理过程中进行自定义操作。这让开发者可以方便地实现认证、日志记录、错误处理等功能，提高代码的可重用性和可维护性。
   * 可扩展性：gRPC提供了扩展能力，允许开发者根据需要添加新的功能和协议扩展。例如，可以通过自定义插件扩展其认证和授权机制，或者添加基于底层传输协议的自定义功能。

# 网关

## apisix

官网：https://apisix.apache.org/zh/

参考：

* [【云原生网关】apisix使用详解](http://www.rply.cn/news/71253.html)

# 认证授权

参考：

* https://www.bilibili.com/video/BV1VE411h7aL/?spm_id_from=333.976.0.0&vd_source=fabefd3fabfadb9324761989b55c26ea

## 基本概念

一般指根据系统设置的安全规则或者安全策略，用户可以访问而且只能访问自己被授权的资源。权限管理几乎出现在任何系统里面，前提是需要有用户和密码认证的系统。

1. 重要概念

   * 认证：通过用户名和密码成功登陆系统后，让系统得到当前用户的角色身份。认证是为了保护系统的隐私数据与资源,户的身份合法访可访问该系统的资源。目前常见的用户身份认证方式有：**用户名密码登录**，**二维码登录**，**手机短信登录**，**指纹认证**等方式。

   * 授权：系统根据当前用户的角色，给其授予对应可以操作的权限资源。**如何授权即如何控制用户对资源的访问进行控制**。授权的数据模型：

     Who ,即主体( Subject) , 主体一般是指用户, 也可以是程序,需要访问系统中的资源。
     What ,即资源( Resource) , 如系统菜单、页面、 按钮、代码方法、系统商品信息、系统订单信息等。系统菜单、页面、按钮、代码方法都属于系统功能资源,对于web系统每个功能资源通常对应一个URL ;系统商品信息、系统订单信息都属于实体资源(数据资源) , 实体资源由资源类型和资源实例组成,比如商品信息为资源类型,商品编号为001的商品为资源实例。
     How ,权限/许可( Permission) , 规定了用户对资源的操作许可,权限离开资源没有意义,如用户查询权限、用户添加权限、某个代码方法的调用权限、编号为001的用户的修改权限等,通过权限可知用户对哪些资源都有哪此操作许可。

   * 会话：在Web开发中，会话是指在客户端和服务器之间跟踪和存储用户信息的机制，**用于跟踪和存储用户的状态信息**。在一个会话中，服务器会为每个用户分配一个唯一的会话标识符（Session ID），该标识符通常通过Cookie或URL参数传递给客户端。通过会话，用户可以在不同页面间保持状态，并在登录状态下访问受限资源。

   **认证是为了保证用户身份的合法性，授权则是为了更细粒度的对隐私数据进行划分，授权是在认证通过后发生的，控制不同的用户能够访问不同的资源。**

   ![image-20230827223459026](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308272235454.png)

2. 权限管理三要素

   * 用户：主要包含用户名，密码和当前用户的角色信息，可实现认证操作。
   * 角色：主要包含角色名称，角色描述和当前角色拥有的权限信息，可实现授权操作。
   * 权限：权限也可以称为菜单，主要包含当前权限名称，url地址等信息，可实现动态展示菜单。

   > 用户与角色是多对多的关系，角色与权限是多对多的关系，用户与权限没有直接关系，二者是通过角色来建立关联关系的。
   
3. 授权实现：RBAC

   * RBAC基于角色授权（Role-Based Access Control）：系统扩展性差

   * **RBAC基于资源授权**（Resoure-Based Access Control）：

## 会话技术

参考：

* [基于Token的身份验证的原理_token验证原理-CSDN博客](https://blog.csdn.net/wnvalentin/article/details/89854980)

用户认证通过后,为了避免用户的每次操作都进行认证可将用户的信息保存在会话中。**会话就是系统为了保持当前用户的登录状态所提供的机制**，常见的有**基于session方式**、**基于token方式**等。两者的区别在于基于session的方式要求sessionId存储在Cookie中，而基于token的方式不要求存储位置，只需要每次请求时带上token就可以

会话技术的存在有以下几个主要原因：

1. 跨请求的状态管理：Web是一种无状态的协议，每个HTTP请求都是独立的，服务器无法直接识别两个不同请求之间的关联。为了跟踪用户的状态，需要使用会话技术来存储和管理用户的信息，以便在不同请求之间保持状态的连续性。
2. 用户认证和权限控制：会话技术可以用于验证用户的身份并管理用户的访问权限。通过会话，用户可以在登录后访问受限资源，并且只需要进行一次登录验证，而不需要在每次请求中重新验证用户的身份。
3. 数据共享：会话技术允许在多个页面或请求之间共享数据。通过会话，应用程序可以在不同页面间传递数据，从而实现用户操作的连续性和数据的一致性。

会话技术的实现：

1. 会话标识符（Session ID）的生成和传递：当用户登录到Web应用程序时，服务器为该用户创建一个唯一的会话标识符（通常是一个长随机字符串），并将其发送给客户端。这通常通过在Cookie中设置会话ID或将其作为URL参数附加到链接中来实现。
2. 服务器端的会话存储：服务器接收到带有会话ID的请求后，会根据该ID检索或创建一个与该会话相关联的数据存储区域（通常是内存或数据库）。服务器使用会话ID来识别客户端，并在会话存储中保存和更新与该标识符相关的状态和数据。
3. 会话数据的读写和管理：在会话期间，服务器和应用程序可以向会话存储中读取和写入数据。例如，可以将用户的身份验证状态、所选语言、购物车内容等信息存储在会话数据中。应用程序可以根据需要从会话存储中读取数据，也可以更新或删除数据。
4. 会话过期和销毁：会话通常具有一定的生命周期，可以根据需求进行配置。当会话过期或用户注销时，服务器会将会话从存储中删除，清除与该用户相关的状态信息。

会话安全性问题：

- 会话劫持（Session Hijacking）：攻击者获取合法用户的会话ID并冒充用户。
- 会话固定（Session Fixation）：攻击者通过在用户会话之前操纵会话ID，使得用户登录后的会话被攻击者控制。
- 会话泄露（Session Leakage）：会话ID被无意间泄露给其他人，使得其他人可以冒充用户。

为了避免这些安全问题，应该使用安全的会话管理技术，如使用加密的会话ID、定期更换会话ID、确保会话存储区域的安全等。

### 基于session的认证机制

基于Session的认证机制由Servlet规范定制, Servlet容器已实现,用户通过HttpSession的操作方法即可实现，如下是HttpSession相关的操作API。

1. 存在的问题
   * 当访问用户数量大时，服务器压力巨大，需要存储所有用户的sessionId
   * 分布式系统中，sessionId不易共享

### 基于token的认证机制

#### JWT

## 分布式系统认证

### 分布式认证需求

分布式系统的每个服务都会有认证、授权的需求。如果每个服务都实现一套认证授权逻辑会非常冗余,考虑分布式系统**共享性**的特点，需要由独立的认证服务处理系统认证授权的请求;考虑分布式系统**开放性**的特点，不仅对系统内部服务提供认证，对第三方系统也要提供认证。分布式认证的需求总结如下：

1. 统一认证授权：提供独立的认证服务，统一处理认证授权。无论是不同类型的用户，还是不同种类的客户端(web端，H5、APP)，均采用一致的认证、权限、会话机制，实现统一认证授权。要实现统一则认证方式必须可扩展，支持各种认证需求，比如:用户名密码认证、短信验证码、二维码、人脸识别等认证方式，并可以非常灵活的切换。
2. 应用接入认证：应提供扩展和开放能力，提供安全的系统对接机制，并可开放部分API给接入第三方使用，一方应用(内部系统服务)和三方应用(第三方应用)均采用统一机制接入。

### 方案选型

1. 基于session的方式

   总体来讲，基于session认证的认证方式，可以更好的在服务端对会话进行控制，且安全性较高。但是，session机制方式基于cookie,在复杂多样的移动客户端上不能有效的使用,并且无法跨域，另外随着系统的扩展需提高session的复制、黏贴及存储的容错性。

2. 基于token的方式

   基于token的认证方式，服务端不用存储认证数据,易维护扩展性强，客户端可以把token 存在任意地方，并且可以实现web和app统一认证机制。其缺点也很明显，token由于自包含信息，因此一般数据量较大，而且每次请求都需要传递，因此比较占带宽。另外，token的签名验签操作也会给cpu带来额外的处理负担。

   ![image-20240430224541435](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202404302245801.png)

## OAuth2.0

参考：

* https://oauth.net/
* https://zhuanlan.zhihu.com/p/509212673
* https://datatracker.ietf.org/doc/html/rfc6749

1. 简介

   OAuth(开放授权)是一个开放标准，**允许用户授权第三方应用访问他们存储在另外的服务提供者上的信息而不需要将用户名和密码提供给第三方应用或分享他们数据的所有内容**。OAuth2.0是OAuth协议的延续版息本，但不向后兼容OAuth 1.0即完全废止了OAuth1.0。很多大公司如Google,Yahoo，Microsoft等都提供了OAUTH认证服务，这些都足以说明OAUTH标准逐渐成为开放资源授权的标准。举例：

   用户借助微信认证登录黑马程序员网站，用户就不用单独在黑马程序员注册用户,怎么样算认证成功吗?黑马程序员网站需要成功从微信获取用户的身份信息则认为用户认证成功，那如何从微信获取用户的身份信息?用户信息的拥有者是用户本人，微信需要经过用户的同意方可为黑马程序员网站生成令牌,黑马程序员网站拿此令牌方可从微信获取用户的信息。

   ![image-20240501160745056](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202405011607224.png)

2. 模式类型

   * 授权码（Authorization Code）：OAuth2.0标准授权步骤，Server端向Client端下放Code码，Client端再用Code码换取授权Token
   * 隐藏式（Implicit）：无法使用授权码模式时的备用选择，Server端使用URL重定向方式直接将Token下放到Client端页面
   * 密码式（Password）：Client直接拿着用户的账号密码换取授权Token
   * 客户端凭证（Client Credentials）：Server端针对Client级别的Token，代表应用自身的资源授权

## 统一单点登录（SSO）

常见的经典统一单点登录(SSO)实现方案有以下几种：

1. 基于代理服务器的SSO： 该方案使用一个专门的代理服务器，作为用户与应用系统之间的中介。当用户访问一个需要验证的应用系统时，代理服务器会负责接收用户的凭据并进行身份验证，然后将令牌传递给应用系统进行授权。代理服务器会为每个用户生成唯一的会话标识，并通过Cookie或请求参数的方式在用户浏览器中保存该会话标识。在用户访问其他应用系统时，代理服务器会验证会话标识，以确定用户是否已经通过身份验证。
2. 基于令牌的SSO（Token-based SSO）： 这种方案使用令牌机制来实现SSO。当用户通过身份认证后，认证中心会颁发一个令牌给用户。令牌包含用户的身份信息和权限，通常是一个加密的字符串。在用户访问其他应用系统时，他们需要将令牌发送给该系统进行验证。这种方案可以使用JSON Web Token（JWT）或Security Assertion Markup Language（SAML）等标准来实现令牌的生成和验证。
3. 基于身份提供商的SSO（Identity Provider-based SSO）： 这种方案将身份验证和授权的责任交给一个专门的身份提供商（IdP）。用户首先通过身份提供商进行身份验证，并获取一个身份令牌。然后，用户可以使用该令牌访问其他应用系统，而无需再次提供凭据。这种方案的一个典型示例是使用OpenID Connect或OAuth 2.0协议，其中身份提供商充当认证服务器并颁发访问令牌。
4. 基于统一目录的SSO： 这种方案使用一个集中式的用户目录（如LDAP或Active Directory）来管理用户身份和权限信息。用户只需要在该目录中进行一次身份验证，然后可以访问其他应用系统。其他应用系统会与统一目录进行集成，以验证用户的身份和权限。

## Spring Security

参考：

* http://www.imooc.com/wiki/securitylesson/springsecurityintro.html
* https://www.bilibili.com/list/watchlater?oid=1555320361&bvid=BV1Z1421C7DM&spm_id_from=333.1245.top_right_bar_window_view_later.content.click&p=2

### 简介

Spring Security 是 Spring 家族的中提供**认证**、**授权**和**攻击防护**功能的一套安全框架。Spring Security 支持命令式和响应式两种开发模式，它也是 Spring 应用在安全框架方面的公认标准。Spring Security 的前身是 Acegi security。Acegi security 在 1.0.7 版本之后便不再跟新，转而以 Spring Security 2.0 的身份出现在 Spring 大家庭中。**常规攻击防范**在 Spring Security 安全框架中是默认开启的，常见的威胁抵御方式有：

- 防止伪造跨站请求（CSRF）
- 安全响应头（HTTP Response headers）
- HTTP 通讯安全

#### 功能模块

Spring Security 包含的功能模块如下：

- **Core**

  核心模块，包含认证、访问控制、集成支持、配置接口等，所有 Spring Security 项目都需要依赖它。

  对应的 Jar 文件：spring-security-core.jar。

- **Remoting**

  Spring security 中的 Remoting 模块提供了与 Spring Remoting 集成的能力。当我们要开发远程客户端的时候需要用到此模块。

  对应的 Jar 文件：spring-security-remoting.jar。

- **Web**

  Spring security 中的 Web 模块，提供了接口过滤器和 Web 安全的基础代码。例如 Servlet 应用接口。如果我们开发的是基于 Web 认证的服务，或者是基于 URL 的访问控制时，将需要用到此模块。

  对应的 Jar 文件：spring-security-web.jar

- **Config**

  Spring security 中的 Config 模块，包含了安全框架命名空间的解析功能与提供了 Java 配置代码。当我们需要使用 XML 方式或者 Java 配置方式时，需要用到此模块。

  对应的 Jar 文件：spring-security-config.jar

- **LDAP**

  Spring security 中的 Ldap 模块，提供了对 Ldap 认证的支持，当我们使用 Ldap 认证时，需要用到此模块。

  对应的 Jar 文件：spring-security-ldap.jar

- **OAuth 2.0 相关模块**

  Spring security 提供了对 OAuth 2.0 的支持，具体分为以下几个模块。

  - **OAuth 2.0 Core**

    OAuth 2.0 Core 模块是 Spring security 安全框架中，对 OAuth 2.0 支持的核心模块，包含了认证功能与 OpenID 的基本支持。

    对应的 Jar 文件：spring-security-oauth2-core.jar

  - **OAuth 2.0 Client**

    OAuth 2.0 Client 模块是 OAuth 2.0 客户端认证授权基础，当我们需要在客户端实现 OAuth 2.0 登录功能时，需要添加此模块。

    对应的 Jar 文件：spring-security-oauth2-client.jar

  - **OAuth 2.0 JOSE**

    OAuth 2.0 JOSE （Javascript Object Signing and Encryption）模块，提供了基于 JS 对象的认证与加解密功能，核心目标是实现 JS 安全传输能力。主要功能有：JWT、 JWS、JWE、JWK。

    对应的 Jar 文件：spring-security-oauth2-jose.jar

  - **OAuth 2.0 Resource Server**

    OAuth 2.0 resource server 模块，提供了 OAuth 2.0 资源服务的基本功能，也就是对资源的访问控制。

    对应的 Jar 文件：spring-security-oauth2-resource-server.jar

- **ACL**

  ACL 模块提供了基于域对象的访问控制。

  对应的 Jar 文件：spring-security-acl.jar

- **CAS**

  CAS 模块适用于需要使用 CAS 单点登录的系统，可以用于单点登录客户端的集成。

  对应的 Jar 文件：spring-security-cas.jar

- **OpenID**

  OpenID 模块适用于需要集成外部 OpenID 的认证系统。使用该模块功能同时还需要依赖 OpenID4Java 。

  对应的 Jar 文件：spring-security-openid.jar

- **Test**

  Test 模块提供了对 Spring security 进行单元测试的能力。

  对应的 Jar 文件：spring-security-test.jar

#### 前置知识

> JavaWeb中Servlet API三大组件Servlet，Filter和Listener，其中理解Filter对于学习Spring Security有着非常重要的意义。具体参考：[java.md](./java.md#Filter和Listener)

### Cargo

官网：https://codehaus-cargo.github.io/cargo/Home.html

>Apache Maven 官方插件用于运行Java EE项目

### 快速入门

> 以springboot项目为示例

1. 依赖导入

   spring项目

   ~~~xml
           <dependency>
               <groupId>org.springframework.security</groupId>
               <artifactId>spring-security-web</artifactId>
               <version>5.5.8</version>
           </dependency>
           <dependency>
               <groupId>org.springframework.security</groupId>
               <artifactId>spring-security-config</artifactId>
               <version>5.5.8</version>
           </dependency>
   ~~~

   spingboot项目

   ~~~xml
           <dependency>
               <groupId>org.springframework.boot</groupId>
               <artifactId>spring-boot-starter-security</artifactId>
               <version>2.5.14</version>
           </dependency>
   ~~~

2. 启动项目并测试（不进行自定义配置，全部使用默认配置）

   在未进行任何的配置默认情况下所有请求都会被拦截，且会跳转到Spring Security默认提供的登录页。 项目在默认配置下，会自动生成一个名为「user」的用户，并在控制台的日志信息中打印生成一个随机密码用于登录该账户。SpringSecurity默认开启一系列基于 springSecurityFilterChain 的 Servlet 过滤器，包含了几乎所有的安全功能，例如：保护系统 URL、验证用户名、密码表单、重定向到登录界面等；创建 UserDetailsService 实例，并生成随机密码，用于获取登录用户的信息详情；将安全过滤器应用到每一个请求上。

### 原理解析

#### 架构设计

**SpringSecurity主要是通过Servlet 的过滤器机制来实现安全逻辑的。**

* `DelegatingFilterProxy`：这个过滤器的作用是连接 Servlet 项目中 Servlet 容器和 Spring 项目的核心上下文对象（ApplicationContext）。Servlet 容器允许对其过滤器做自定义的扩展，DelegatingFilterProxy 将 Spring 的 Bean 过滤器（Bean Filter）插入到 Servlet 的过滤器链中执行。

* `FilterChainProxy`：核心过滤器，负责管理和调度一系列子过滤器

* `SecurityFilterChain`：在 Spring Security 各个模块中，内置已实现了一系列的「安全过滤器」，可以满足常见的认证、鉴权等功能需求。

  通过`HttpSecurity`类可以使用SecurityFilterChain和在该链中增减过滤器。然后链中的过滤器顺序由`org.springframework.security.config.annotation.web.builders.FilterComparator`类来实现。在 Spring Security 5.3.2 中，共内置了 33 个安全过滤器，如下表所示：

  | 顺序号 | 过滤器名称                               | 简述                                                       |
  | :----- | :--------------------------------------- | :--------------------------------------------------------- |
  | 1      | ChannelProcessingFilter                  | 检查 web 请求通道，如：http、https                         |
  | 2      | ConcurrentSessionFilter                  | 检查 Session 状态，更新 Session 最后访问时间               |
  | 3      | WebAsyncManagerIntegrationFilter         | 关联 Spring Web 上下文和 Spring Security 上下文            |
  | 4      | SecurityContextPersistenceFilter         | 从 Session 构建 SecurityContext                            |
  | 5      | HeaderWriterFilter                       | 往请求头或响应头里写入信息                                 |
  | 6      | CorsFilter                               | 跨域请求头                                                 |
  | 7      | CsrfFilter                               | 跨站请求伪造                                               |
  | 8      | LogoutFilter                             | 注销过滤器                                                 |
  | 9      | OAuth2AuthorizationRequestRedirectFilter | OAuth2 请求重定向                                          |
  | 10     | Saml2WebSsoAuthenticationRequestFilter   | SAML2 单点登录认证请求过滤器                               |
  | 11     | X509AuthenticationFilter                 | X509 认证过滤器                                            |
  | 12     | AbstractPreAuthenticatedProcessingFilter | 预认证处理                                                 |
  | 13     | CasAuthenticationFilter                  | 单点认证过滤器                                             |
  | 14     | OAuth2LoginAuthenticationFilter          | OAuth2 认证过滤器                                          |
  | 15     | Saml2WebSsoAuthenticationFilter          | SAML2 单点登录认证过滤器                                   |
  | 16     | UsernamePasswordAuthenticationFilter     | 用户名密码认证过滤器                                       |
  | 17     | ConcurrentSessionFilter                  | 检查 Session 状态，更新 Session 最后访问时间。第二次出现。 |
  | 18     | OpenIDAuthenticationFilter               | Open ID 认证过滤器                                         |
  | 19     | DefaultLoginPageGeneratingFilter         | 生成 `/login` 页面                                         |
  | 20     | DefaultLogoutPageGeneratingFilter        | 生成 `/logout` 页面                                        |
  | 21     | DigestAuthenticationFilter               | 数字签名认证过滤器                                         |
  | 22     | BearerTokenAuthenticationFilter          | Bearer Token 认证过滤器                                    |
  | 23     | BasicAuthenticationFilter                | 基本身份认证过滤器                                         |
  | 24     | RequestCacheAwareFilter                  | 缓存请求状态过滤器                                         |
  | 25     | SecurityContextHolderAwareRequestFilter  | 安全上下文请求辅助过滤器                                   |
  | 26     | JaasApiIntegrationFilter                 | JAAS 认证授权过滤器                                        |
  | 27     | RememberMeAuthenticationFilter           | 实现记住我功能                                             |
  | 28     | AnonymousAuthenticationFilter            | 匿名认证过滤器                                             |
  | 29     | OAuth2AuthorizationCodeGrantFilter       | OAuth2 认证授权码                                          |
  | 30     | SessionManagementFilter                  | 管理 Session                                               |
  | 31     | ExceptionTranslationFilter               | 异常事件处理过滤器                                         |
  | 32     | FilterSecurityInterceptor                | 动态权限配置                                               |
  | 33     | SwitchUserFilter                         | 切换账户                                                   |

* WebSecurityConfigurerAdapter类：可以通过继承该类来自定义系统的安全配置。覆盖该类中的`configure(HttpSecurity http)`方法，可以指定URL路径和添加包括认证方式、角色授权、资源访问控制等各种安全配置

* `HttpSecurity`：主要用于配置拦截器链的关键类，通过该类可以添加各种安全配置。通过使用`addFilterAfter`、`addFilterBefore`、`addFilter`、`addFilterAt`方法来向链中指定顺序插入过滤器。

* `WebSecurity`：用于配置Spring Security的相关设置，例如是否启用CSRF保护、设置忽略URL等。

![image-20230831224330027](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308312243497.png)

![image-20230829220338611](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308292203812.png)

![image-20230829220753695](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308292207269.png)

SecurityContextPersistenceFilter：整个拦截过程的入口和出口，在请求开始时从配置好的SecurityContextRepository中获取SecurityContext ,然后把它设置给SecurityContextHolder。在请求完成后将SecurityContextHolder持有的SecurityContext再保存到配置好的SecurityContextRepository ,同时清除securityContextHolder所持有的SecurityContext ;
UsernamePasswordAuthenticationFilter：用于处理来自表单提交的认证。该表单必须提供对应的用户名和密码,其内部还有登录成功或失败后进行处理的AuthenticationSuccessHandler和AuthenticationFailureHandler ,这些都可以根据需求做相关改变;
FilterSecurityInterceptor：用于保护web资源的,使用AccessDecisionManager对当前用户进行授权访问。
ExceptionTranslationFilter：能够捕获来自FilterChain所有的异常,并进行处理。但是它只会处理两类异
常: AuthenticationException和AccessDeniedException ,其它的异常它会继续抛出。

#### 异常回收机制

#### 认证流程

![image-20230829225101910](https://whymechen.oss-cn-chengdu.aliyuncs.com/image/202308292251183.png)

#### 授权流程

### 源码分析

## Shiro

参考：

* https://www.bilibili.com/video/BV1j54y1t7jM/?spm_id_from=333.999.0.0&vd_source=fabefd3fabfadb9324761989b55c26ea

## Sa-token

文档：https://sa-token.cc

## JustAuth

* 项目地址（gitee）：https://gitee.com/yadong.zhang/JustAuth
* 文档：https://www.justauth.cn/

钉钉登录：[实现第三方应用钉钉扫码登录](https://blog.csdn.net/weixin_43260238/article/details/126855205)
